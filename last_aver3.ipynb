{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddd107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 03:47:02.722883: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-26 03:47:03.396363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - PyTorch version: 2.4.0\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Seeded everything with seed 42\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Device: cuda\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Using AMP: True\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Number of workers for DataLoader: 6\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Outputs will be saved to: training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Saved run configuration to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/config_summary.txt\n",
      "2025-05-26 03:47:04 - WARNING - 3473208690 - Stratification by sex/age should be handled during the preprocessing step that creates the .pt files.\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - --- Processing Fold 1/51 ---\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_0/fold_0_preprocessed_data.pt for train split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Loaded 281 samples for train split.\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_0/fold_0_preprocessed_data.pt for val split.\n",
      "2025-05-26 03:47:04 - INFO - 3473208690 - Loaded 71 samples for val split.\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:47:05 - INFO - 3473208690 - Fold 1 VAE Epoch 1/150 | β: 0.000 | Train Loss: 1.2687 (MSE: 1.2687, KLD: 2.3561) | Val Loss: 1.1106 (MSE: 1.1106, KLD: 6.6167)\n",
      "2025-05-26 03:47:05 - INFO - 3473208690 - Validation metric improved (1.110559 --> 1.110559). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:06 - INFO - 3473208690 - Fold 1 VAE Epoch 2/150 | β: 0.016 | Train Loss: 1.1356 (MSE: 1.0748, KLD: 3.7956) | Val Loss: 1.0597 (MSE: 1.0501, KLD: 0.6035)\n",
      "2025-05-26 03:47:06 - INFO - 3473208690 - Validation metric improved (1.050091 --> 1.050091). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:07 - INFO - 3473208690 - Fold 1 VAE Epoch 3/150 | β: 0.032 | Train Loss: 1.0592 (MSE: 1.0410, KLD: 0.5683) | Val Loss: 1.0260 (MSE: 1.0035, KLD: 0.7018)\n",
      "2025-05-26 03:47:07 - INFO - 3473208690 - Validation metric improved (1.003508 --> 1.003508). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:08 - INFO - 3473208690 - Fold 1 VAE Epoch 4/150 | β: 0.048 | Train Loss: 1.0294 (MSE: 1.0084, KLD: 0.4382) | Val Loss: 1.0064 (MSE: 0.9866, KLD: 0.4131)\n",
      "2025-05-26 03:47:08 - INFO - 3473208690 - Validation metric improved (0.986568 --> 0.986568). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:09 - INFO - 3473208690 - Fold 1 VAE Epoch 5/150 | β: 0.064 | Train Loss: 1.0087 (MSE: 0.9888, KLD: 0.3111) | Val Loss: 0.9916 (MSE: 0.9709, KLD: 0.3235)\n",
      "2025-05-26 03:47:09 - INFO - 3473208690 - Validation metric improved (0.970900 --> 0.970900). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:10 - INFO - 3473208690 - Fold 1 VAE Epoch 6/150 | β: 0.080 | Train Loss: 0.9938 (MSE: 0.9746, KLD: 0.2391) | Val Loss: 0.9791 (MSE: 0.9600, KLD: 0.2390)\n",
      "2025-05-26 03:47:10 - INFO - 3473208690 - Validation metric improved (0.959965 --> 0.959965). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:10 - INFO - 3473208690 - Fold 1 VAE Epoch 7/150 | β: 0.096 | Train Loss: 0.9831 (MSE: 0.9647, KLD: 0.1916) | Val Loss: 0.9680 (MSE: 0.9527, KLD: 0.1586)\n",
      "2025-05-26 03:47:10 - INFO - 3473208690 - Validation metric improved (0.952724 --> 0.952724). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:11 - INFO - 3473208690 - Fold 1 VAE Epoch 8/150 | β: 0.112 | Train Loss: 0.9723 (MSE: 0.9550, KLD: 0.1547) | Val Loss: 0.9573 (MSE: 0.9410, KLD: 0.1452)\n",
      "2025-05-26 03:47:11 - INFO - 3473208690 - Validation metric improved (0.941048 --> 0.941048). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:12 - INFO - 3473208690 - Fold 1 VAE Epoch 9/150 | β: 0.128 | Train Loss: 0.9574 (MSE: 0.9399, KLD: 0.1361) | Val Loss: 0.9470 (MSE: 0.9311, KLD: 0.1242)\n",
      "2025-05-26 03:47:12 - INFO - 3473208690 - Validation metric improved (0.931086 --> 0.931086). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:13 - INFO - 3473208690 - Fold 1 VAE Epoch 10/150 | β: 0.144 | Train Loss: 0.9499 (MSE: 0.9336, KLD: 0.1130) | Val Loss: 0.9387 (MSE: 0.9229, KLD: 0.1093)\n",
      "2025-05-26 03:47:13 - INFO - 3473208690 - Validation metric improved (0.922940 --> 0.922940). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:14 - INFO - 3473208690 - Fold 1 VAE Epoch 11/150 | β: 0.160 | Train Loss: 0.9400 (MSE: 0.9227, KLD: 0.1085) | Val Loss: 0.9304 (MSE: 0.9173, KLD: 0.0819)\n",
      "2025-05-26 03:47:14 - INFO - 3473208690 - Validation metric improved (0.917291 --> 0.917291). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:15 - INFO - 3473208690 - Fold 1 VAE Epoch 12/150 | β: 0.176 | Train Loss: 0.9323 (MSE: 0.9163, KLD: 0.0910) | Val Loss: 0.9228 (MSE: 0.9062, KLD: 0.0948)\n",
      "2025-05-26 03:47:15 - INFO - 3473208690 - Validation metric improved (0.906152 --> 0.906152). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:15 - INFO - 3473208690 - Fold 1 VAE Epoch 13/150 | β: 0.192 | Train Loss: 0.9247 (MSE: 0.9082, KLD: 0.0855) | Val Loss: 0.9168 (MSE: 0.9024, KLD: 0.0751)\n",
      "2025-05-26 03:47:15 - INFO - 3473208690 - Validation metric improved (0.902394 --> 0.902394). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:16 - INFO - 3473208690 - Fold 1 VAE Epoch 14/150 | β: 0.208 | Train Loss: 0.9173 (MSE: 0.9007, KLD: 0.0798) | Val Loss: 0.9105 (MSE: 0.8925, KLD: 0.0867)\n",
      "2025-05-26 03:47:16 - INFO - 3473208690 - Validation metric improved (0.892501 --> 0.892501). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:17 - INFO - 3473208690 - Fold 1 VAE Epoch 15/150 | β: 0.224 | Train Loss: 0.9152 (MSE: 0.8979, KLD: 0.0775) | Val Loss: 0.9076 (MSE: 0.8835, KLD: 0.1077)\n",
      "2025-05-26 03:47:17 - INFO - 3473208690 - Validation metric improved (0.883505 --> 0.883505). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:18 - INFO - 3473208690 - Fold 1 VAE Epoch 16/150 | β: 0.240 | Train Loss: 0.9092 (MSE: 0.8906, KLD: 0.0775) | Val Loss: 0.9013 (MSE: 0.8845, KLD: 0.0698)\n",
      "2025-05-26 03:47:18 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.883505|Current: 0.884533)\n",
      "2025-05-26 03:47:18 - INFO - 3473208690 - Fold 1 VAE Epoch 17/150 | β: 0.256 | Train Loss: 0.9022 (MSE: 0.8835, KLD: 0.0728) | Val Loss: 0.8934 (MSE: 0.8793, KLD: 0.0551)\n",
      "2025-05-26 03:47:18 - INFO - 3473208690 - Validation metric improved (0.879289 --> 0.879289). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:19 - INFO - 3473208690 - Fold 1 VAE Epoch 18/150 | β: 0.272 | Train Loss: 0.8956 (MSE: 0.8773, KLD: 0.0671) | Val Loss: 0.8872 (MSE: 0.8680, KLD: 0.0708)\n",
      "2025-05-26 03:47:19 - INFO - 3473208690 - Validation metric improved (0.867986 --> 0.867986). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:20 - INFO - 3473208690 - Fold 1 VAE Epoch 19/150 | β: 0.288 | Train Loss: 0.8924 (MSE: 0.8716, KLD: 0.0719) | Val Loss: 0.8841 (MSE: 0.8614, KLD: 0.0788)\n",
      "2025-05-26 03:47:20 - INFO - 3473208690 - Validation metric improved (0.861430 --> 0.861430). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:21 - INFO - 3473208690 - Fold 1 VAE Epoch 20/150 | β: 0.304 | Train Loss: 0.8867 (MSE: 0.8657, KLD: 0.0689) | Val Loss: 0.8783 (MSE: 0.8585, KLD: 0.0654)\n",
      "2025-05-26 03:47:21 - INFO - 3473208690 - Validation metric improved (0.858475 --> 0.858475). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:22 - INFO - 3473208690 - Fold 1 VAE Epoch 21/150 | β: 0.320 | Train Loss: 0.8797 (MSE: 0.8576, KLD: 0.0689) | Val Loss: 0.8711 (MSE: 0.8492, KLD: 0.0683)\n",
      "2025-05-26 03:47:22 - INFO - 3473208690 - Validation metric improved (0.849179 --> 0.849179). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:23 - INFO - 3473208690 - Fold 1 VAE Epoch 22/150 | β: 0.336 | Train Loss: 0.8735 (MSE: 0.8508, KLD: 0.0676) | Val Loss: 0.8639 (MSE: 0.8431, KLD: 0.0622)\n",
      "2025-05-26 03:47:23 - INFO - 3473208690 - Validation metric improved (0.843057 --> 0.843057). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:23 - INFO - 3473208690 - Fold 1 VAE Epoch 23/150 | β: 0.352 | Train Loss: 0.8699 (MSE: 0.8466, KLD: 0.0660) | Val Loss: 0.8614 (MSE: 0.8400, KLD: 0.0607)\n",
      "2025-05-26 03:47:23 - INFO - 3473208690 - Validation metric improved (0.840011 --> 0.840011). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:24 - INFO - 3473208690 - Fold 1 VAE Epoch 24/150 | β: 0.368 | Train Loss: 0.8637 (MSE: 0.8402, KLD: 0.0639) | Val Loss: 0.8553 (MSE: 0.8329, KLD: 0.0609)\n",
      "2025-05-26 03:47:24 - INFO - 3473208690 - Validation metric improved (0.832897 --> 0.832897). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:25 - INFO - 3473208690 - Fold 1 VAE Epoch 25/150 | β: 0.384 | Train Loss: 0.8613 (MSE: 0.8378, KLD: 0.0611) | Val Loss: 0.8532 (MSE: 0.8301, KLD: 0.0601)\n",
      "2025-05-26 03:47:25 - INFO - 3473208690 - Validation metric improved (0.830077 --> 0.830077). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:26 - INFO - 3473208690 - Fold 1 VAE Epoch 26/150 | β: 0.400 | Train Loss: 0.8594 (MSE: 0.8341, KLD: 0.0632) | Val Loss: 0.8486 (MSE: 0.8257, KLD: 0.0572)\n",
      "2025-05-26 03:47:26 - INFO - 3473208690 - Validation metric improved (0.825690 --> 0.825690). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:27 - INFO - 3473208690 - Fold 1 VAE Epoch 27/150 | β: 0.416 | Train Loss: 0.8545 (MSE: 0.8304, KLD: 0.0580) | Val Loss: 0.8501 (MSE: 0.8250, KLD: 0.0604)\n",
      "2025-05-26 03:47:27 - INFO - 3473208690 - Validation metric improved (0.824955 --> 0.824955). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:28 - INFO - 3473208690 - Fold 1 VAE Epoch 28/150 | β: 0.432 | Train Loss: 0.8567 (MSE: 0.8321, KLD: 0.0570) | Val Loss: 0.8484 (MSE: 0.8250, KLD: 0.0542)\n",
      "2025-05-26 03:47:28 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.824955|Current: 0.825007)\n",
      "2025-05-26 03:47:28 - INFO - 3473208690 - Fold 1 VAE Epoch 29/150 | β: 0.448 | Train Loss: 0.8547 (MSE: 0.8294, KLD: 0.0566) | Val Loss: 0.8468 (MSE: 0.8220, KLD: 0.0554)\n",
      "2025-05-26 03:47:28 - INFO - 3473208690 - Validation metric improved (0.821988 --> 0.821988). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:31 - INFO - 3473208690 - Fold 1 VAE Epoch 30/150 | β: 0.464 | Train Loss: 0.8525 (MSE: 0.8266, KLD: 0.0558) | Val Loss: 0.8484 (MSE: 0.8223, KLD: 0.0562)\n",
      "2025-05-26 03:47:31 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.821988|Current: 0.822350)\n",
      "2025-05-26 03:47:32 - INFO - 3473208690 - Fold 1 VAE Epoch 31/150 | β: 0.480 | Train Loss: 0.8536 (MSE: 0.8282, KLD: 0.0529) | Val Loss: 0.8423 (MSE: 0.8173, KLD: 0.0521)\n",
      "2025-05-26 03:47:32 - INFO - 3473208690 - Validation metric improved (0.817307 --> 0.817307). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:34 - INFO - 3473208690 - Fold 1 VAE Epoch 32/150 | β: 0.496 | Train Loss: 0.8530 (MSE: 0.8265, KLD: 0.0534) | Val Loss: 0.8446 (MSE: 0.8193, KLD: 0.0509)\n",
      "2025-05-26 03:47:34 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.817307|Current: 0.819340)\n",
      "2025-05-26 03:47:35 - INFO - 3473208690 - Fold 1 VAE Epoch 33/150 | β: 0.512 | Train Loss: 0.8516 (MSE: 0.8250, KLD: 0.0518) | Val Loss: 0.8454 (MSE: 0.8197, KLD: 0.0502)\n",
      "2025-05-26 03:47:35 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.817307|Current: 0.819657)\n",
      "2025-05-26 03:47:35 - INFO - 3473208690 - Fold 1 VAE Epoch 34/150 | β: 0.528 | Train Loss: 0.8538 (MSE: 0.8271, KLD: 0.0505) | Val Loss: 0.8464 (MSE: 0.8194, KLD: 0.0511)\n",
      "2025-05-26 03:47:35 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.817307|Current: 0.819402)\n",
      "2025-05-26 03:47:36 - INFO - 3473208690 - Fold 1 VAE Epoch 35/150 | β: 0.544 | Train Loss: 0.8537 (MSE: 0.8262, KLD: 0.0506) | Val Loss: 0.8454 (MSE: 0.8191, KLD: 0.0483)\n",
      "2025-05-26 03:47:36 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.817307|Current: 0.819140)\n",
      "2025-05-26 03:47:37 - INFO - 3473208690 - Fold 1 VAE Epoch 36/150 | β: 0.560 | Train Loss: 0.8541 (MSE: 0.8268, KLD: 0.0487) | Val Loss: 0.8476 (MSE: 0.8204, KLD: 0.0485)\n",
      "2025-05-26 03:47:37 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.817307|Current: 0.820412)\n",
      "2025-05-26 03:47:37 - INFO - 3473208690 - Fold 1 VAE Epoch 37/150 | β: 0.576 | Train Loss: 0.8548 (MSE: 0.8264, KLD: 0.0494) | Val Loss: 0.8499 (MSE: 0.8216, KLD: 0.0492)\n",
      "2025-05-26 03:47:37 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.817307|Current: 0.821596)\n",
      "2025-05-26 03:47:38 - INFO - 3473208690 - Fold 1 VAE Epoch 38/150 | β: 0.592 | Train Loss: 0.8610 (MSE: 0.8269, KLD: 0.0575) | Val Loss: 0.8501 (MSE: 0.8106, KLD: 0.0668)\n",
      "2025-05-26 03:47:38 - INFO - 3473208690 - Validation metric improved (0.810596 --> 0.810596). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:41 - INFO - 3473208690 - Fold 1 VAE Epoch 39/150 | β: 0.608 | Train Loss: 0.8639 (MSE: 0.8197, KLD: 0.0726) | Val Loss: 0.8464 (MSE: 0.8174, KLD: 0.0478)\n",
      "2025-05-26 03:47:41 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.810596|Current: 0.817367)\n",
      "2025-05-26 03:47:41 - INFO - 3473208690 - Fold 1 VAE Epoch 40/150 | β: 0.624 | Train Loss: 0.8495 (MSE: 0.8136, KLD: 0.0575) | Val Loss: 0.8319 (MSE: 0.8015, KLD: 0.0487)\n",
      "2025-05-26 03:47:41 - INFO - 3473208690 - Validation metric improved (0.801530 --> 0.801530). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:45 - INFO - 3473208690 - Fold 1 VAE Epoch 41/150 | β: 0.640 | Train Loss: 0.8421 (MSE: 0.8085, KLD: 0.0524) | Val Loss: 0.8454 (MSE: 0.8025, KLD: 0.0669)\n",
      "2025-05-26 03:47:45 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.801530|Current: 0.802543)\n",
      "2025-05-26 03:47:45 - INFO - 3473208690 - Fold 1 VAE Epoch 42/150 | β: 0.656 | Train Loss: 0.8392 (MSE: 0.8040, KLD: 0.0537) | Val Loss: 0.8238 (MSE: 0.7992, KLD: 0.0376)\n",
      "2025-05-26 03:47:45 - INFO - 3473208690 - Validation metric improved (0.799160 --> 0.799160). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:48 - INFO - 3473208690 - Fold 1 VAE Epoch 43/150 | β: 0.672 | Train Loss: 0.8375 (MSE: 0.7992, KLD: 0.0569) | Val Loss: 0.8274 (MSE: 0.7868, KLD: 0.0604)\n",
      "2025-05-26 03:47:48 - INFO - 3473208690 - Validation metric improved (0.786794 --> 0.786794). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:52 - INFO - 3473208690 - Fold 1 VAE Epoch 44/150 | β: 0.688 | Train Loss: 0.8305 (MSE: 0.7951, KLD: 0.0515) | Val Loss: 0.8187 (MSE: 0.7959, KLD: 0.0332)\n",
      "2025-05-26 03:47:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.786794|Current: 0.795882)\n",
      "2025-05-26 03:47:52 - INFO - 3473208690 - Fold 1 VAE Epoch 45/150 | β: 0.704 | Train Loss: 0.8274 (MSE: 0.7947, KLD: 0.0464) | Val Loss: 0.8257 (MSE: 0.7800, KLD: 0.0649)\n",
      "2025-05-26 03:47:52 - INFO - 3473208690 - Validation metric improved (0.780041 --> 0.780041). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:56 - INFO - 3473208690 - Fold 1 VAE Epoch 46/150 | β: 0.720 | Train Loss: 0.8247 (MSE: 0.7859, KLD: 0.0539) | Val Loss: 0.8171 (MSE: 0.7846, KLD: 0.0452)\n",
      "2025-05-26 03:47:56 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.780041|Current: 0.784569)\n",
      "2025-05-26 03:47:57 - INFO - 3473208690 - Fold 1 VAE Epoch 47/150 | β: 0.736 | Train Loss: 0.8168 (MSE: 0.7826, KLD: 0.0464) | Val Loss: 0.8022 (MSE: 0.7738, KLD: 0.0386)\n",
      "2025-05-26 03:47:57 - INFO - 3473208690 - Validation metric improved (0.773813 --> 0.773813). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:58 - INFO - 3473208690 - Fold 1 VAE Epoch 48/150 | β: 0.752 | Train Loss: 0.8105 (MSE: 0.7798, KLD: 0.0408) | Val Loss: 0.7961 (MSE: 0.7674, KLD: 0.0381)\n",
      "2025-05-26 03:47:58 - INFO - 3473208690 - Validation metric improved (0.767421 --> 0.767421). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:59 - INFO - 3473208690 - Fold 1 VAE Epoch 49/150 | β: 0.768 | Train Loss: 0.8126 (MSE: 0.7808, KLD: 0.0414) | Val Loss: 0.8004 (MSE: 0.7641, KLD: 0.0474)\n",
      "2025-05-26 03:47:59 - INFO - 3473208690 - Validation metric improved (0.764053 --> 0.764053). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:47:59 - INFO - 3473208690 - Fold 1 VAE Epoch 50/150 | β: 0.784 | Train Loss: 0.8099 (MSE: 0.7747, KLD: 0.0450) | Val Loss: 0.7990 (MSE: 0.7735, KLD: 0.0325)\n",
      "2025-05-26 03:47:59 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.764053|Current: 0.773531)\n",
      "2025-05-26 03:48:00 - INFO - 3473208690 - Fold 1 VAE Epoch 51/150 | β: 0.800 | Train Loss: 0.8082 (MSE: 0.7750, KLD: 0.0414) | Val Loss: 0.7962 (MSE: 0.7574, KLD: 0.0486)\n",
      "2025-05-26 03:48:00 - INFO - 3473208690 - Validation metric improved (0.757399 --> 0.757399). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:01 - INFO - 3473208690 - Fold 1 VAE Epoch 52/150 | β: 0.800 | Train Loss: 0.8042 (MSE: 0.7698, KLD: 0.0430) | Val Loss: 0.8010 (MSE: 0.7602, KLD: 0.0510)\n",
      "2025-05-26 03:48:01 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.757399|Current: 0.760223)\n",
      "2025-05-26 03:48:02 - INFO - 3473208690 - Fold 1 VAE Epoch 53/150 | β: 0.800 | Train Loss: 0.8041 (MSE: 0.7718, KLD: 0.0404) | Val Loss: 0.7956 (MSE: 0.7623, KLD: 0.0417)\n",
      "2025-05-26 03:48:02 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.757399|Current: 0.762263)\n",
      "2025-05-26 03:48:02 - INFO - 3473208690 - Fold 1 VAE Epoch 54/150 | β: 0.800 | Train Loss: 0.8031 (MSE: 0.7694, KLD: 0.0421) | Val Loss: 0.7858 (MSE: 0.7508, KLD: 0.0438)\n",
      "2025-05-26 03:48:02 - INFO - 3473208690 - Validation metric improved (0.750840 --> 0.750840). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:03 - INFO - 3473208690 - Fold 1 VAE Epoch 55/150 | β: 0.800 | Train Loss: 0.8003 (MSE: 0.7698, KLD: 0.0382) | Val Loss: 0.7890 (MSE: 0.7541, KLD: 0.0436)\n",
      "2025-05-26 03:48:03 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.750840|Current: 0.754138)\n",
      "2025-05-26 03:48:04 - INFO - 3473208690 - Fold 1 VAE Epoch 56/150 | β: 0.800 | Train Loss: 0.7941 (MSE: 0.7641, KLD: 0.0376) | Val Loss: 0.7836 (MSE: 0.7535, KLD: 0.0376)\n",
      "2025-05-26 03:48:04 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.750840|Current: 0.753507)\n",
      "2025-05-26 03:48:04 - INFO - 3473208690 - Fold 1 VAE Epoch 57/150 | β: 0.800 | Train Loss: 0.7945 (MSE: 0.7639, KLD: 0.0382) | Val Loss: 0.7831 (MSE: 0.7542, KLD: 0.0361)\n",
      "2025-05-26 03:48:04 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.750840|Current: 0.754203)\n",
      "2025-05-26 03:48:05 - INFO - 3473208690 - Fold 1 VAE Epoch 58/150 | β: 0.800 | Train Loss: 0.7919 (MSE: 0.7610, KLD: 0.0386) | Val Loss: 0.7782 (MSE: 0.7513, KLD: 0.0336)\n",
      "2025-05-26 03:48:05 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.750840|Current: 0.751288)\n",
      "2025-05-26 03:48:06 - INFO - 3473208690 - Fold 1 VAE Epoch 59/150 | β: 0.800 | Train Loss: 0.7948 (MSE: 0.7643, KLD: 0.0382) | Val Loss: 0.7809 (MSE: 0.7503, KLD: 0.0382)\n",
      "2025-05-26 03:48:06 - INFO - 3473208690 - Validation metric improved (0.750310 --> 0.750310). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:07 - INFO - 3473208690 - Fold 1 VAE Epoch 60/150 | β: 0.800 | Train Loss: 0.7933 (MSE: 0.7631, KLD: 0.0377) | Val Loss: 0.7884 (MSE: 0.7550, KLD: 0.0419)\n",
      "2025-05-26 03:48:07 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.750310|Current: 0.754963)\n",
      "2025-05-26 03:48:08 - INFO - 3473208690 - Fold 1 VAE Epoch 61/150 | β: 0.800 | Train Loss: 0.7961 (MSE: 0.7639, KLD: 0.0403) | Val Loss: 0.7753 (MSE: 0.7487, KLD: 0.0333)\n",
      "2025-05-26 03:48:08 - INFO - 3473208690 - Validation metric improved (0.748653 --> 0.748653). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:10 - INFO - 3473208690 - Fold 1 VAE Epoch 62/150 | β: 0.800 | Train Loss: 0.7879 (MSE: 0.7577, KLD: 0.0378) | Val Loss: 0.7785 (MSE: 0.7482, KLD: 0.0378)\n",
      "2025-05-26 03:48:10 - INFO - 3473208690 - Validation metric improved (0.748212 --> 0.748212). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:12 - INFO - 3473208690 - Fold 1 VAE Epoch 63/150 | β: 0.800 | Train Loss: 0.7859 (MSE: 0.7570, KLD: 0.0362) | Val Loss: 0.7783 (MSE: 0.7500, KLD: 0.0354)\n",
      "2025-05-26 03:48:12 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.748212|Current: 0.749989)\n",
      "2025-05-26 03:48:13 - INFO - 3473208690 - Fold 1 VAE Epoch 64/150 | β: 0.800 | Train Loss: 0.7872 (MSE: 0.7585, KLD: 0.0358) | Val Loss: 0.7772 (MSE: 0.7455, KLD: 0.0397)\n",
      "2025-05-26 03:48:13 - INFO - 3473208690 - Validation metric improved (0.745460 --> 0.745460). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:15 - INFO - 3473208690 - Fold 1 VAE Epoch 65/150 | β: 0.800 | Train Loss: 0.7877 (MSE: 0.7587, KLD: 0.0363) | Val Loss: 0.7742 (MSE: 0.7478, KLD: 0.0330)\n",
      "2025-05-26 03:48:15 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.745460|Current: 0.747824)\n",
      "2025-05-26 03:48:16 - INFO - 3473208690 - Fold 1 VAE Epoch 66/150 | β: 0.800 | Train Loss: 0.7879 (MSE: 0.7573, KLD: 0.0383) | Val Loss: 0.7737 (MSE: 0.7458, KLD: 0.0350)\n",
      "2025-05-26 03:48:16 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.745460|Current: 0.745765)\n",
      "2025-05-26 03:48:16 - INFO - 3473208690 - Fold 1 VAE Epoch 67/150 | β: 0.800 | Train Loss: 0.7875 (MSE: 0.7602, KLD: 0.0341) | Val Loss: 0.7831 (MSE: 0.7546, KLD: 0.0357)\n",
      "2025-05-26 03:48:16 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.745460|Current: 0.754554)\n",
      "2025-05-26 03:48:17 - INFO - 3473208690 - Fold 1 VAE Epoch 68/150 | β: 0.800 | Train Loss: 0.7855 (MSE: 0.7554, KLD: 0.0376) | Val Loss: 0.7795 (MSE: 0.7515, KLD: 0.0350)\n",
      "2025-05-26 03:48:17 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.745460|Current: 0.751493)\n",
      "2025-05-26 03:48:18 - INFO - 3473208690 - Fold 1 VAE Epoch 69/150 | β: 0.800 | Train Loss: 0.7853 (MSE: 0.7563, KLD: 0.0363) | Val Loss: 0.7729 (MSE: 0.7450, KLD: 0.0349)\n",
      "2025-05-26 03:48:18 - INFO - 3473208690 - Validation metric improved (0.744976 --> 0.744976). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:20 - INFO - 3473208690 - Fold 1 VAE Epoch 70/150 | β: 0.800 | Train Loss: 0.7848 (MSE: 0.7560, KLD: 0.0360) | Val Loss: 0.7723 (MSE: 0.7440, KLD: 0.0354)\n",
      "2025-05-26 03:48:20 - INFO - 3473208690 - Validation metric improved (0.743963 --> 0.743963). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:22 - INFO - 3473208690 - Fold 1 VAE Epoch 71/150 | β: 0.800 | Train Loss: 0.7860 (MSE: 0.7564, KLD: 0.0370) | Val Loss: 0.7696 (MSE: 0.7410, KLD: 0.0358)\n",
      "2025-05-26 03:48:22 - INFO - 3473208690 - Validation metric improved (0.740958 --> 0.740958). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:24 - INFO - 3473208690 - Fold 1 VAE Epoch 72/150 | β: 0.800 | Train Loss: 0.7849 (MSE: 0.7556, KLD: 0.0366) | Val Loss: 0.7722 (MSE: 0.7441, KLD: 0.0351)\n",
      "2025-05-26 03:48:24 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.740958|Current: 0.744101)\n",
      "2025-05-26 03:48:25 - INFO - 3473208690 - Fold 1 VAE Epoch 73/150 | β: 0.800 | Train Loss: 0.7846 (MSE: 0.7557, KLD: 0.0361) | Val Loss: 0.7683 (MSE: 0.7404, KLD: 0.0350)\n",
      "2025-05-26 03:48:25 - INFO - 3473208690 - Validation metric improved (0.740366 --> 0.740366). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:27 - INFO - 3473208690 - Fold 1 VAE Epoch 74/150 | β: 0.800 | Train Loss: 0.7865 (MSE: 0.7576, KLD: 0.0361) | Val Loss: 0.7743 (MSE: 0.7462, KLD: 0.0351)\n",
      "2025-05-26 03:48:27 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.740366|Current: 0.746197)\n",
      "2025-05-26 03:48:28 - INFO - 3473208690 - Fold 1 VAE Epoch 75/150 | β: 0.800 | Train Loss: 0.7925 (MSE: 0.7593, KLD: 0.0414) | Val Loss: 0.7851 (MSE: 0.7484, KLD: 0.0459)\n",
      "2025-05-26 03:48:28 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.740366|Current: 0.748356)\n",
      "2025-05-26 03:48:28 - INFO - 3473208690 - Fold 1 VAE Epoch 76/150 | β: 0.800 | Train Loss: 0.7881 (MSE: 0.7533, KLD: 0.0435) | Val Loss: 0.7824 (MSE: 0.7402, KLD: 0.0527)\n",
      "2025-05-26 03:48:28 - INFO - 3473208690 - Validation metric improved (0.740232 --> 0.740232). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:32 - INFO - 3473208690 - Fold 1 VAE Epoch 77/150 | β: 0.800 | Train Loss: 0.7924 (MSE: 0.7569, KLD: 0.0443) | Val Loss: 0.7773 (MSE: 0.7451, KLD: 0.0402)\n",
      "2025-05-26 03:48:32 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.740232|Current: 0.745124)\n",
      "2025-05-26 03:48:32 - INFO - 3473208690 - Fold 1 VAE Epoch 78/150 | β: 0.800 | Train Loss: 0.7881 (MSE: 0.7528, KLD: 0.0441) | Val Loss: 0.7788 (MSE: 0.7477, KLD: 0.0389)\n",
      "2025-05-26 03:48:32 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.740232|Current: 0.747652)\n",
      "2025-05-26 03:48:33 - INFO - 3473208690 - Fold 1 VAE Epoch 79/150 | β: 0.800 | Train Loss: 0.7842 (MSE: 0.7508, KLD: 0.0418) | Val Loss: 0.7878 (MSE: 0.7488, KLD: 0.0488)\n",
      "2025-05-26 03:48:33 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.740232|Current: 0.748766)\n",
      "2025-05-26 03:48:33 - INFO - 3473208690 - Fold 1 VAE Epoch 80/150 | β: 0.800 | Train Loss: 0.7868 (MSE: 0.7526, KLD: 0.0427) | Val Loss: 0.7732 (MSE: 0.7450, KLD: 0.0352)\n",
      "2025-05-26 03:48:33 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.740232|Current: 0.744991)\n",
      "2025-05-26 03:48:34 - INFO - 3473208690 - Fold 1 VAE Epoch 81/150 | β: 0.800 | Train Loss: 0.7819 (MSE: 0.7494, KLD: 0.0407) | Val Loss: 0.7688 (MSE: 0.7384, KLD: 0.0380)\n",
      "2025-05-26 03:48:34 - INFO - 3473208690 - Validation metric improved (0.738363 --> 0.738363). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:35 - INFO - 3473208690 - Fold 1 VAE Epoch 82/150 | β: 0.800 | Train Loss: 0.7784 (MSE: 0.7469, KLD: 0.0394) | Val Loss: 0.7725 (MSE: 0.7338, KLD: 0.0484)\n",
      "2025-05-26 03:48:35 - INFO - 3473208690 - Validation metric improved (0.733757 --> 0.733757). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:36 - INFO - 3473208690 - Fold 1 VAE Epoch 83/150 | β: 0.800 | Train Loss: 0.7789 (MSE: 0.7464, KLD: 0.0406) | Val Loss: 0.7676 (MSE: 0.7363, KLD: 0.0392)\n",
      "2025-05-26 03:48:36 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.733757|Current: 0.736269)\n",
      "2025-05-26 03:48:36 - INFO - 3473208690 - Fold 1 VAE Epoch 84/150 | β: 0.800 | Train Loss: 0.7740 (MSE: 0.7422, KLD: 0.0397) | Val Loss: 0.7584 (MSE: 0.7296, KLD: 0.0361)\n",
      "2025-05-26 03:48:36 - INFO - 3473208690 - Validation metric improved (0.729575 --> 0.729575). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:37 - INFO - 3473208690 - Fold 1 VAE Epoch 85/150 | β: 0.800 | Train Loss: 0.7733 (MSE: 0.7433, KLD: 0.0375) | Val Loss: 0.7642 (MSE: 0.7376, KLD: 0.0332)\n",
      "2025-05-26 03:48:37 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.729575|Current: 0.737590)\n",
      "2025-05-26 03:48:38 - INFO - 3473208690 - Fold 1 VAE Epoch 86/150 | β: 0.800 | Train Loss: 0.7755 (MSE: 0.7423, KLD: 0.0415) | Val Loss: 0.7679 (MSE: 0.7359, KLD: 0.0400)\n",
      "2025-05-26 03:48:38 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.729575|Current: 0.735941)\n",
      "2025-05-26 03:48:38 - INFO - 3473208690 - Fold 1 VAE Epoch 87/150 | β: 0.800 | Train Loss: 0.7740 (MSE: 0.7426, KLD: 0.0392) | Val Loss: 0.7573 (MSE: 0.7242, KLD: 0.0414)\n",
      "2025-05-26 03:48:38 - INFO - 3473208690 - Validation metric improved (0.724198 --> 0.724198). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:39 - INFO - 3473208690 - Fold 1 VAE Epoch 88/150 | β: 0.800 | Train Loss: 0.7719 (MSE: 0.7387, KLD: 0.0414) | Val Loss: 0.7612 (MSE: 0.7243, KLD: 0.0461)\n",
      "2025-05-26 03:48:39 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.724198|Current: 0.724289)\n",
      "2025-05-26 03:48:40 - INFO - 3473208690 - Fold 1 VAE Epoch 89/150 | β: 0.800 | Train Loss: 0.7702 (MSE: 0.7383, KLD: 0.0400) | Val Loss: 0.7644 (MSE: 0.7278, KLD: 0.0457)\n",
      "2025-05-26 03:48:40 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.724198|Current: 0.727829)\n",
      "2025-05-26 03:48:40 - INFO - 3473208690 - Fold 1 VAE Epoch 90/150 | β: 0.800 | Train Loss: 0.7723 (MSE: 0.7393, KLD: 0.0413) | Val Loss: 0.7610 (MSE: 0.7369, KLD: 0.0302)\n",
      "2025-05-26 03:48:40 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.724198|Current: 0.736892)\n",
      "2025-05-26 03:48:41 - INFO - 3473208690 - Fold 1 VAE Epoch 91/150 | β: 0.800 | Train Loss: 0.7656 (MSE: 0.7380, KLD: 0.0346) | Val Loss: 0.7602 (MSE: 0.7308, KLD: 0.0368)\n",
      "2025-05-26 03:48:41 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.724198|Current: 0.730792)\n",
      "2025-05-26 03:48:42 - INFO - 3473208690 - Fold 1 VAE Epoch 92/150 | β: 0.800 | Train Loss: 0.7663 (MSE: 0.7365, KLD: 0.0373) | Val Loss: 0.7477 (MSE: 0.7177, KLD: 0.0376)\n",
      "2025-05-26 03:48:42 - INFO - 3473208690 - Validation metric improved (0.717675 --> 0.717675). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:42 - INFO - 3473208690 - Fold 1 VAE Epoch 93/150 | β: 0.800 | Train Loss: 0.7689 (MSE: 0.7367, KLD: 0.0402) | Val Loss: 0.7487 (MSE: 0.7191, KLD: 0.0370)\n",
      "2025-05-26 03:48:42 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.717675|Current: 0.719128)\n",
      "2025-05-26 03:48:43 - INFO - 3473208690 - Fold 1 VAE Epoch 94/150 | β: 0.800 | Train Loss: 0.7627 (MSE: 0.7342, KLD: 0.0357) | Val Loss: 0.7516 (MSE: 0.7225, KLD: 0.0365)\n",
      "2025-05-26 03:48:43 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.717675|Current: 0.722453)\n",
      "2025-05-26 03:48:44 - INFO - 3473208690 - Fold 1 VAE Epoch 95/150 | β: 0.800 | Train Loss: 0.7648 (MSE: 0.7342, KLD: 0.0382) | Val Loss: 0.7578 (MSE: 0.7254, KLD: 0.0405)\n",
      "2025-05-26 03:48:44 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.717675|Current: 0.725376)\n",
      "2025-05-26 03:48:44 - INFO - 3473208690 - Fold 1 VAE Epoch 96/150 | β: 0.800 | Train Loss: 0.7644 (MSE: 0.7339, KLD: 0.0381) | Val Loss: 0.7537 (MSE: 0.7211, KLD: 0.0408)\n",
      "2025-05-26 03:48:44 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.717675|Current: 0.721062)\n",
      "2025-05-26 03:48:45 - INFO - 3473208690 - Fold 1 VAE Epoch 97/150 | β: 0.800 | Train Loss: 0.7660 (MSE: 0.7341, KLD: 0.0398) | Val Loss: 0.7490 (MSE: 0.7180, KLD: 0.0386)\n",
      "2025-05-26 03:48:45 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.717675|Current: 0.718044)\n",
      "2025-05-26 03:48:46 - INFO - 3473208690 - Fold 1 VAE Epoch 98/150 | β: 0.800 | Train Loss: 0.7649 (MSE: 0.7313, KLD: 0.0420) | Val Loss: 0.7524 (MSE: 0.7268, KLD: 0.0320)\n",
      "2025-05-26 03:48:46 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.717675|Current: 0.726847)\n",
      "2025-05-26 03:48:46 - INFO - 3473208690 - Fold 1 VAE Epoch 99/150 | β: 0.800 | Train Loss: 0.7614 (MSE: 0.7316, KLD: 0.0372) | Val Loss: 0.7600 (MSE: 0.7307, KLD: 0.0366)\n",
      "2025-05-26 03:48:46 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.717675|Current: 0.730716)\n",
      "2025-05-26 03:48:47 - INFO - 3473208690 - Fold 1 VAE Epoch 100/150 | β: 0.800 | Train Loss: 0.7604 (MSE: 0.7328, KLD: 0.0344) | Val Loss: 0.7547 (MSE: 0.7226, KLD: 0.0402)\n",
      "2025-05-26 03:48:47 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.717675|Current: 0.722554)\n",
      "2025-05-26 03:48:48 - INFO - 3473208690 - Fold 1 VAE Epoch 101/150 | β: 0.800 | Train Loss: 0.7608 (MSE: 0.7302, KLD: 0.0382) | Val Loss: 0.7475 (MSE: 0.7230, KLD: 0.0305)\n",
      "2025-05-26 03:48:48 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.717675|Current: 0.723038)\n",
      "2025-05-26 03:48:48 - INFO - 3473208690 - Fold 1 VAE Epoch 102/150 | β: 0.800 | Train Loss: 0.7612 (MSE: 0.7337, KLD: 0.0344) | Val Loss: 0.7524 (MSE: 0.7229, KLD: 0.0369)\n",
      "2025-05-26 03:48:48 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.717675|Current: 0.722880)\n",
      "2025-05-26 03:48:49 - INFO - 3473208690 - Fold 1 VAE Epoch 103/150 | β: 0.800 | Train Loss: 0.7599 (MSE: 0.7306, KLD: 0.0366) | Val Loss: 0.7519 (MSE: 0.7247, KLD: 0.0340)\n",
      "2025-05-26 03:48:49 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.717675|Current: 0.724700)\n",
      "2025-05-26 03:48:50 - INFO - 3473208690 - Fold 1 VAE Epoch 104/150 | β: 0.800 | Train Loss: 0.7620 (MSE: 0.7330, KLD: 0.0363) | Val Loss: 0.7545 (MSE: 0.7258, KLD: 0.0359)\n",
      "2025-05-26 03:48:50 - INFO - 3473208690 - EarlyStopping counter: 12 out of 15 (Best: 0.717675|Current: 0.725819)\n",
      "2025-05-26 03:48:50 - INFO - 3473208690 - Fold 1 VAE Epoch 105/150 | β: 0.800 | Train Loss: 0.7585 (MSE: 0.7294, KLD: 0.0364) | Val Loss: 0.7482 (MSE: 0.7205, KLD: 0.0345)\n",
      "2025-05-26 03:48:50 - INFO - 3473208690 - EarlyStopping counter: 13 out of 15 (Best: 0.717675|Current: 0.720531)\n",
      "2025-05-26 03:48:51 - INFO - 3473208690 - Fold 1 VAE Epoch 106/150 | β: 0.800 | Train Loss: 0.7607 (MSE: 0.7315, KLD: 0.0365) | Val Loss: 0.7465 (MSE: 0.7177, KLD: 0.0359)\n",
      "2025-05-26 03:48:51 - INFO - 3473208690 - EarlyStopping counter: 14 out of 15 (Best: 0.717675|Current: 0.717727)\n",
      "2025-05-26 03:48:51 - INFO - 3473208690 - Fold 1 VAE Epoch 107/150 | β: 0.800 | Train Loss: 0.7600 (MSE: 0.7307, KLD: 0.0367) | Val Loss: 0.7438 (MSE: 0.7163, KLD: 0.0343)\n",
      "2025-05-26 03:48:51 - INFO - 3473208690 - Validation metric improved (0.716333 --> 0.716333). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:48:52 - INFO - 3473208690 - Fold 1 VAE Epoch 108/150 | β: 0.800 | Train Loss: 0.7602 (MSE: 0.7322, KLD: 0.0350) | Val Loss: 0.7509 (MSE: 0.7240, KLD: 0.0336)\n",
      "2025-05-26 03:48:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.716333|Current: 0.723989)\n",
      "2025-05-26 03:48:53 - INFO - 3473208690 - Fold 1 VAE Epoch 109/150 | β: 0.800 | Train Loss: 0.7590 (MSE: 0.7307, KLD: 0.0354) | Val Loss: 0.7461 (MSE: 0.7187, KLD: 0.0342)\n",
      "2025-05-26 03:48:53 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.716333|Current: 0.718661)\n",
      "2025-05-26 03:48:54 - INFO - 3473208690 - Fold 1 VAE Epoch 110/150 | β: 0.800 | Train Loss: 0.7581 (MSE: 0.7298, KLD: 0.0354) | Val Loss: 0.7483 (MSE: 0.7212, KLD: 0.0338)\n",
      "2025-05-26 03:48:54 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.716333|Current: 0.721204)\n",
      "2025-05-26 03:48:54 - INFO - 3473208690 - Fold 1 VAE Epoch 111/150 | β: 0.800 | Train Loss: 0.7569 (MSE: 0.7287, KLD: 0.0353) | Val Loss: 0.7458 (MSE: 0.7188, KLD: 0.0338)\n",
      "2025-05-26 03:48:54 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.716333|Current: 0.718845)\n",
      "2025-05-26 03:48:55 - INFO - 3473208690 - Fold 1 VAE Epoch 112/150 | β: 0.800 | Train Loss: 0.7658 (MSE: 0.7343, KLD: 0.0395) | Val Loss: 0.7500 (MSE: 0.7181, KLD: 0.0399)\n",
      "2025-05-26 03:48:55 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.716333|Current: 0.718146)\n",
      "2025-05-26 03:48:55 - INFO - 3473208690 - Fold 1 VAE Epoch 113/150 | β: 0.800 | Train Loss: 0.7625 (MSE: 0.7317, KLD: 0.0386) | Val Loss: 0.7539 (MSE: 0.7217, KLD: 0.0403)\n",
      "2025-05-26 03:48:55 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.716333|Current: 0.721664)\n",
      "2025-05-26 03:48:56 - INFO - 3473208690 - Fold 1 VAE Epoch 114/150 | β: 0.800 | Train Loss: 0.7662 (MSE: 0.7326, KLD: 0.0419) | Val Loss: 0.7488 (MSE: 0.7181, KLD: 0.0384)\n",
      "2025-05-26 03:48:56 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.716333|Current: 0.718116)\n",
      "2025-05-26 03:48:57 - INFO - 3473208690 - Fold 1 VAE Epoch 115/150 | β: 0.800 | Train Loss: 0.7627 (MSE: 0.7280, KLD: 0.0433) | Val Loss: 0.7520 (MSE: 0.7265, KLD: 0.0318)\n",
      "2025-05-26 03:48:57 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.716333|Current: 0.726521)\n",
      "2025-05-26 03:48:57 - INFO - 3473208690 - Fold 1 VAE Epoch 116/150 | β: 0.800 | Train Loss: 0.7678 (MSE: 0.7350, KLD: 0.0410) | Val Loss: 0.7625 (MSE: 0.7206, KLD: 0.0523)\n",
      "2025-05-26 03:48:57 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.716333|Current: 0.720643)\n",
      "2025-05-26 03:48:58 - INFO - 3473208690 - Fold 1 VAE Epoch 117/150 | β: 0.800 | Train Loss: 0.7627 (MSE: 0.7272, KLD: 0.0444) | Val Loss: 0.7472 (MSE: 0.7183, KLD: 0.0361)\n",
      "2025-05-26 03:48:58 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.716333|Current: 0.718297)\n",
      "2025-05-26 03:48:58 - INFO - 3473208690 - Fold 1 VAE Epoch 118/150 | β: 0.800 | Train Loss: 0.7617 (MSE: 0.7308, KLD: 0.0386) | Val Loss: 0.7640 (MSE: 0.7395, KLD: 0.0306)\n",
      "2025-05-26 03:48:58 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.716333|Current: 0.739511)\n",
      "2025-05-26 03:48:59 - INFO - 3473208690 - Fold 1 VAE Epoch 119/150 | β: 0.800 | Train Loss: 0.7602 (MSE: 0.7282, KLD: 0.0400) | Val Loss: 0.7547 (MSE: 0.7137, KLD: 0.0513)\n",
      "2025-05-26 03:48:59 - INFO - 3473208690 - Validation metric improved (0.713656 --> 0.713656). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:00 - INFO - 3473208690 - Fold 1 VAE Epoch 120/150 | β: 0.800 | Train Loss: 0.7596 (MSE: 0.7270, KLD: 0.0407) | Val Loss: 0.7462 (MSE: 0.7151, KLD: 0.0389)\n",
      "2025-05-26 03:49:00 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.713656|Current: 0.715087)\n",
      "2025-05-26 03:49:01 - INFO - 3473208690 - Fold 1 VAE Epoch 121/150 | β: 0.800 | Train Loss: 0.7545 (MSE: 0.7232, KLD: 0.0392) | Val Loss: 0.7511 (MSE: 0.7216, KLD: 0.0369)\n",
      "2025-05-26 03:49:01 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.713656|Current: 0.721629)\n",
      "2025-05-26 03:49:01 - INFO - 3473208690 - Fold 1 VAE Epoch 122/150 | β: 0.800 | Train Loss: 0.7552 (MSE: 0.7225, KLD: 0.0408) | Val Loss: 0.7498 (MSE: 0.7230, KLD: 0.0335)\n",
      "2025-05-26 03:49:01 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.713656|Current: 0.723006)\n",
      "2025-05-26 03:49:02 - INFO - 3473208690 - Fold 1 VAE Epoch 123/150 | β: 0.800 | Train Loss: 0.7541 (MSE: 0.7237, KLD: 0.0380) | Val Loss: 0.7496 (MSE: 0.7235, KLD: 0.0326)\n",
      "2025-05-26 03:49:02 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.713656|Current: 0.723511)\n",
      "2025-05-26 03:49:02 - INFO - 3473208690 - Fold 1 VAE Epoch 124/150 | β: 0.800 | Train Loss: 0.7577 (MSE: 0.7234, KLD: 0.0429) | Val Loss: 0.7406 (MSE: 0.7148, KLD: 0.0323)\n",
      "2025-05-26 03:49:02 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.713656|Current: 0.714788)\n",
      "2025-05-26 03:49:03 - INFO - 3473208690 - Fold 1 VAE Epoch 125/150 | β: 0.800 | Train Loss: 0.7640 (MSE: 0.7280, KLD: 0.0450) | Val Loss: 0.7570 (MSE: 0.7353, KLD: 0.0272)\n",
      "2025-05-26 03:49:03 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.713656|Current: 0.735271)\n",
      "2025-05-26 03:49:04 - INFO - 3473208690 - Fold 1 VAE Epoch 126/150 | β: 0.800 | Train Loss: 0.7679 (MSE: 0.7286, KLD: 0.0491) | Val Loss: 0.7423 (MSE: 0.7180, KLD: 0.0303)\n",
      "2025-05-26 03:49:04 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.713656|Current: 0.718011)\n",
      "2025-05-26 03:49:04 - INFO - 3473208690 - Fold 1 VAE Epoch 127/150 | β: 0.800 | Train Loss: 0.7560 (MSE: 0.7251, KLD: 0.0385) | Val Loss: 0.7508 (MSE: 0.7214, KLD: 0.0368)\n",
      "2025-05-26 03:49:04 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.713656|Current: 0.721367)\n",
      "2025-05-26 03:49:05 - INFO - 3473208690 - Fold 1 VAE Epoch 128/150 | β: 0.800 | Train Loss: 0.7499 (MSE: 0.7207, KLD: 0.0365) | Val Loss: 0.7376 (MSE: 0.7079, KLD: 0.0371)\n",
      "2025-05-26 03:49:05 - INFO - 3473208690 - Validation metric improved (0.707854 --> 0.707854). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:06 - INFO - 3473208690 - Fold 1 VAE Epoch 129/150 | β: 0.800 | Train Loss: 0.7493 (MSE: 0.7210, KLD: 0.0353) | Val Loss: 0.7423 (MSE: 0.7116, KLD: 0.0384)\n",
      "2025-05-26 03:49:06 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.707854|Current: 0.711581)\n",
      "2025-05-26 03:49:07 - INFO - 3473208690 - Fold 1 VAE Epoch 130/150 | β: 0.800 | Train Loss: 0.7495 (MSE: 0.7198, KLD: 0.0371) | Val Loss: 0.7342 (MSE: 0.7052, KLD: 0.0363)\n",
      "2025-05-26 03:49:07 - INFO - 3473208690 - Validation metric improved (0.705168 --> 0.705168). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:07 - INFO - 3473208690 - Fold 1 VAE Epoch 131/150 | β: 0.800 | Train Loss: 0.7512 (MSE: 0.7200, KLD: 0.0390) | Val Loss: 0.7446 (MSE: 0.7146, KLD: 0.0375)\n",
      "2025-05-26 03:49:07 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.705168|Current: 0.714579)\n",
      "2025-05-26 03:49:08 - INFO - 3473208690 - Fold 1 VAE Epoch 132/150 | β: 0.800 | Train Loss: 0.7484 (MSE: 0.7196, KLD: 0.0361) | Val Loss: 0.7337 (MSE: 0.7021, KLD: 0.0395)\n",
      "2025-05-26 03:49:08 - INFO - 3473208690 - Validation metric improved (0.702062 --> 0.702062). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:09 - INFO - 3473208690 - Fold 1 VAE Epoch 133/150 | β: 0.800 | Train Loss: 0.7483 (MSE: 0.7180, KLD: 0.0378) | Val Loss: 0.7365 (MSE: 0.7101, KLD: 0.0330)\n",
      "2025-05-26 03:49:09 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.702062|Current: 0.710075)\n",
      "2025-05-26 03:49:10 - INFO - 3473208690 - Fold 1 VAE Epoch 134/150 | β: 0.800 | Train Loss: 0.7467 (MSE: 0.7177, KLD: 0.0363) | Val Loss: 0.7311 (MSE: 0.7016, KLD: 0.0368)\n",
      "2025-05-26 03:49:10 - INFO - 3473208690 - Validation metric improved (0.701586 --> 0.701586). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:10 - INFO - 3473208690 - Fold 1 VAE Epoch 135/150 | β: 0.800 | Train Loss: 0.7449 (MSE: 0.7152, KLD: 0.0370) | Val Loss: 0.7361 (MSE: 0.7091, KLD: 0.0338)\n",
      "2025-05-26 03:49:10 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.701586|Current: 0.709071)\n",
      "2025-05-26 03:49:11 - INFO - 3473208690 - Fold 1 VAE Epoch 136/150 | β: 0.800 | Train Loss: 0.7464 (MSE: 0.7165, KLD: 0.0374) | Val Loss: 0.7369 (MSE: 0.7113, KLD: 0.0320)\n",
      "2025-05-26 03:49:11 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.701586|Current: 0.711252)\n",
      "2025-05-26 03:49:12 - INFO - 3473208690 - Fold 1 VAE Epoch 137/150 | β: 0.800 | Train Loss: 0.7503 (MSE: 0.7219, KLD: 0.0355) | Val Loss: 0.7398 (MSE: 0.7060, KLD: 0.0423)\n",
      "2025-05-26 03:49:12 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.701586|Current: 0.705961)\n",
      "2025-05-26 03:49:12 - INFO - 3473208690 - Fold 1 VAE Epoch 138/150 | β: 0.800 | Train Loss: 0.7444 (MSE: 0.7143, KLD: 0.0376) | Val Loss: 0.7259 (MSE: 0.7007, KLD: 0.0315)\n",
      "2025-05-26 03:49:12 - INFO - 3473208690 - Validation metric improved (0.700701 --> 0.700701). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt ...\n",
      "2025-05-26 03:49:13 - INFO - 3473208690 - Fold 1 VAE Epoch 139/150 | β: 0.800 | Train Loss: 0.7447 (MSE: 0.7159, KLD: 0.0360) | Val Loss: 0.7303 (MSE: 0.7026, KLD: 0.0347)\n",
      "2025-05-26 03:49:13 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.700701|Current: 0.702601)\n",
      "2025-05-26 03:49:14 - INFO - 3473208690 - Fold 1 VAE Epoch 140/150 | β: 0.800 | Train Loss: 0.7405 (MSE: 0.7136, KLD: 0.0336) | Val Loss: 0.7310 (MSE: 0.7058, KLD: 0.0315)\n",
      "2025-05-26 03:49:14 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.700701|Current: 0.705809)\n",
      "2025-05-26 03:49:14 - INFO - 3473208690 - Fold 1 VAE Epoch 141/150 | β: 0.800 | Train Loss: 0.7467 (MSE: 0.7184, KLD: 0.0354) | Val Loss: 0.7365 (MSE: 0.7075, KLD: 0.0363)\n",
      "2025-05-26 03:49:14 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.700701|Current: 0.707480)\n",
      "2025-05-26 03:49:15 - INFO - 3473208690 - Fold 1 VAE Epoch 142/150 | β: 0.800 | Train Loss: 0.7472 (MSE: 0.7167, KLD: 0.0382) | Val Loss: 0.7345 (MSE: 0.7060, KLD: 0.0357)\n",
      "2025-05-26 03:49:15 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.700701|Current: 0.705960)\n",
      "2025-05-26 03:49:16 - INFO - 3473208690 - Fold 1 VAE Epoch 143/150 | β: 0.800 | Train Loss: 0.7452 (MSE: 0.7167, KLD: 0.0356) | Val Loss: 0.7367 (MSE: 0.7106, KLD: 0.0325)\n",
      "2025-05-26 03:49:16 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.700701|Current: 0.710625)\n",
      "2025-05-26 03:49:16 - INFO - 3473208690 - Fold 1 VAE Epoch 144/150 | β: 0.800 | Train Loss: 0.7446 (MSE: 0.7165, KLD: 0.0351) | Val Loss: 0.7301 (MSE: 0.7025, KLD: 0.0345)\n",
      "2025-05-26 03:49:16 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.700701|Current: 0.702480)\n",
      "2025-05-26 03:49:17 - INFO - 3473208690 - Fold 1 VAE Epoch 145/150 | β: 0.800 | Train Loss: 0.7451 (MSE: 0.7161, KLD: 0.0362) | Val Loss: 0.7344 (MSE: 0.7065, KLD: 0.0348)\n",
      "2025-05-26 03:49:17 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.700701|Current: 0.706549)\n",
      "2025-05-26 03:49:18 - INFO - 3473208690 - Fold 1 VAE Epoch 146/150 | β: 0.800 | Train Loss: 0.7436 (MSE: 0.7145, KLD: 0.0364) | Val Loss: 0.7307 (MSE: 0.7030, KLD: 0.0345)\n",
      "2025-05-26 03:49:18 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.700701|Current: 0.703030)\n",
      "2025-05-26 03:49:18 - INFO - 3473208690 - Fold 1 VAE Epoch 147/150 | β: 0.800 | Train Loss: 0.7438 (MSE: 0.7152, KLD: 0.0358) | Val Loss: 0.7328 (MSE: 0.7056, KLD: 0.0340)\n",
      "2025-05-26 03:49:18 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.700701|Current: 0.705610)\n",
      "2025-05-26 03:49:19 - INFO - 3473208690 - Fold 1 VAE Epoch 148/150 | β: 0.800 | Train Loss: 0.7437 (MSE: 0.7155, KLD: 0.0353) | Val Loss: 0.7302 (MSE: 0.7032, KLD: 0.0337)\n",
      "2025-05-26 03:49:19 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.700701|Current: 0.703179)\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - Fold 1 VAE Epoch 149/150 | β: 0.800 | Train Loss: 0.7567 (MSE: 0.7237, KLD: 0.0413) | Val Loss: 0.7684 (MSE: 0.7454, KLD: 0.0287)\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.700701|Current: 0.745445)\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - Fold 1 VAE Epoch 150/150 | β: 0.800 | Train Loss: 0.7544 (MSE: 0.7190, KLD: 0.0442) | Val Loss: 0.7382 (MSE: 0.7056, KLD: 0.0407)\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - EarlyStopping counter: 12 out of 15 (Best: 0.700701|Current: 0.705619)\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - Loaded best VAE model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_vae_model.pt\n",
      "2025-05-26 03:49:20 - INFO - 3473208690 - --- Extracting Latent Features (mu only) for Train, Val, Test ---\n",
      "2025-05-26 03:49:21 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_0/fold_0_preprocessed_data.pt for test split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:49:21 - WARNING - 3473208690 - Test split keys not found in preprocessed_connectomes_for_dl/fold_0/fold_0_preprocessed_data.pt. Test set will be empty.\n",
      "2025-05-26 03:49:21 - INFO - 3473208690 - Loaded 0 samples for test split.\n",
      "2025-05-26 03:49:21 - WARNING - 3473208690 - Fold 1: Test dataset is empty. Skipping test set evaluation for this fold.\n",
      "2025-05-26 03:49:21 - INFO - 3473208690 - --- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\n",
      "2025-05-26 03:49:21 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha: [1.0352112  0.96710527]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "2025-05-26 03:49:21 - INFO - 3473208690 - Validation metric improved (0.704678 --> 0.704678). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:49:22 - INFO - 3473208690 - Validation metric improved (0.706140 --> 0.706140). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:49:22 - INFO - 3473208690 - Validation metric improved (0.755848 --> 0.755848). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:49:23 - INFO - 3473208690 - Validation metric improved (0.770468 --> 0.770468). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:49:23 - INFO - 3473208690 - Validation metric improved (0.817251 --> 0.817251). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:49:24 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.817251|Current: 0.780702)\n",
      "2025-05-26 03:49:24 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.817251|Current: 0.782164)\n",
      "2025-05-26 03:49:25 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.817251|Current: 0.771930)\n",
      "2025-05-26 03:49:25 - INFO - 3473208690 - EarlyStopping counter: 4 out of 10 (Best: 0.817251|Current: 0.747076)\n",
      "2025-05-26 03:49:26 - INFO - 3473208690 - EarlyStopping counter: 5 out of 10 (Best: 0.817251|Current: 0.760234)\n",
      "2025-05-26 03:49:26 - INFO - 3473208690 - EarlyStopping counter: 6 out of 10 (Best: 0.817251|Current: 0.739766)\n",
      "2025-05-26 03:49:27 - INFO - 3473208690 - EarlyStopping counter: 7 out of 10 (Best: 0.817251|Current: 0.736842)\n",
      "2025-05-26 03:49:27 - INFO - 3473208690 - EarlyStopping counter: 8 out of 10 (Best: 0.817251|Current: 0.710526)\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - EarlyStopping counter: 9 out of 10 (Best: 0.817251|Current: 0.722222)\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - EarlyStopping counter: 10 out of 10 (Best: 0.817251|Current: 0.716374)\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - Early stopping initial classifier training.\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - Loaded best initial classifier model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/best_initial_classifier_model.pt.\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - Fold 1 Initial Best Classifier Val Metrics: Acc: 0.5135, AUC: 0.8173, F1: 0.6786\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - --- Classifier Re-training Phase (CN vs AD) on Train+Val ---\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha for retraining: [1.0337079 0.9684211]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:49:28 - INFO - 3473208690 - Re-training classifier on combined train+val data for 30 epochs.\n",
      "2025-05-26 03:49:30 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 5/30 | Train Loss: 0.2399, Acc: 0.5652\n",
      "2025-05-26 03:49:31 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 10/30 | Train Loss: 0.2159, Acc: 0.5380\n",
      "2025-05-26 03:49:32 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 15/30 | Train Loss: 0.2193, Acc: 0.5109\n",
      "2025-05-26 03:49:34 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 20/30 | Train Loss: 0.1918, Acc: 0.5543\n",
      "2025-05-26 03:49:35 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 25/30 | Train Loss: 0.1932, Acc: 0.5761\n",
      "2025-05-26 03:49:36 - INFO - 3473208690 - Fold 1 CLF Re-train Epoch 30/30 | Train Loss: 0.1973, Acc: 0.5924\n",
      "2025-05-26 03:49:36 - INFO - 3473208690 - Saved final classifier model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_0/final_classifier_model.pt\n",
      "2025-05-26 03:49:36 - WARNING - 3473208690 - Fold 1: Test data latent features are empty. Skipping test set evaluation.\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - --- Processing Fold 2/51 ---\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_1/fold_1_preprocessed_data.pt for train split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Loaded 281 samples for train split.\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_1/fold_1_preprocessed_data.pt for val split.\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Loaded 71 samples for val split.\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Fold 2 VAE Epoch 1/150 | β: 0.000 | Train Loss: 1.2352 (MSE: 1.2352, KLD: 2.1446) | Val Loss: 1.0668 (MSE: 1.0668, KLD: 6.1186)\n",
      "2025-05-26 03:49:37 - INFO - 3473208690 - Validation metric improved (1.066750 --> 1.066750). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:38 - INFO - 3473208690 - Fold 2 VAE Epoch 2/150 | β: 0.016 | Train Loss: 1.1383 (MSE: 1.0809, KLD: 3.5870) | Val Loss: 1.0271 (MSE: 1.0169, KLD: 0.6370)\n",
      "2025-05-26 03:49:38 - INFO - 3473208690 - Validation metric improved (1.016928 --> 1.016928). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:39 - INFO - 3473208690 - Fold 2 VAE Epoch 3/150 | β: 0.032 | Train Loss: 1.0611 (MSE: 1.0421, KLD: 0.5925) | Val Loss: 0.9984 (MSE: 0.9765, KLD: 0.6839)\n",
      "2025-05-26 03:49:39 - INFO - 3473208690 - Validation metric improved (0.976550 --> 0.976550). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:40 - INFO - 3473208690 - Fold 2 VAE Epoch 4/150 | β: 0.048 | Train Loss: 1.0329 (MSE: 1.0114, KLD: 0.4478) | Val Loss: 0.9808 (MSE: 0.9616, KLD: 0.3997)\n",
      "2025-05-26 03:49:40 - INFO - 3473208690 - Validation metric improved (0.961643 --> 0.961643). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:41 - INFO - 3473208690 - Fold 2 VAE Epoch 5/150 | β: 0.064 | Train Loss: 1.0119 (MSE: 0.9922, KLD: 0.3083) | Val Loss: 0.9687 (MSE: 0.9485, KLD: 0.3159)\n",
      "2025-05-26 03:49:41 - INFO - 3473208690 - Validation metric improved (0.948460 --> 0.948460). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:42 - INFO - 3473208690 - Fold 2 VAE Epoch 6/150 | β: 0.080 | Train Loss: 0.9970 (MSE: 0.9782, KLD: 0.2356) | Val Loss: 0.9555 (MSE: 0.9366, KLD: 0.2369)\n",
      "2025-05-26 03:49:42 - INFO - 3473208690 - Validation metric improved (0.936568 --> 0.936568). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:43 - INFO - 3473208690 - Fold 2 VAE Epoch 7/150 | β: 0.096 | Train Loss: 0.9860 (MSE: 0.9682, KLD: 0.1848) | Val Loss: 0.9459 (MSE: 0.9308, KLD: 0.1568)\n",
      "2025-05-26 03:49:43 - INFO - 3473208690 - Validation metric improved (0.930832 --> 0.930832). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:44 - INFO - 3473208690 - Fold 2 VAE Epoch 8/150 | β: 0.112 | Train Loss: 0.9756 (MSE: 0.9588, KLD: 0.1505) | Val Loss: 0.9359 (MSE: 0.9210, KLD: 0.1330)\n",
      "2025-05-26 03:49:44 - INFO - 3473208690 - Validation metric improved (0.920974 --> 0.920974). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:44 - INFO - 3473208690 - Fold 2 VAE Epoch 9/150 | β: 0.128 | Train Loss: 0.9672 (MSE: 0.9510, KLD: 0.1265) | Val Loss: 0.9256 (MSE: 0.9107, KLD: 0.1162)\n",
      "2025-05-26 03:49:44 - INFO - 3473208690 - Validation metric improved (0.910745 --> 0.910745). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:45 - INFO - 3473208690 - Fold 2 VAE Epoch 10/150 | β: 0.144 | Train Loss: 0.9579 (MSE: 0.9422, KLD: 0.1092) | Val Loss: 0.9189 (MSE: 0.9042, KLD: 0.1018)\n",
      "2025-05-26 03:49:45 - INFO - 3473208690 - Validation metric improved (0.904216 --> 0.904216). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:46 - INFO - 3473208690 - Fold 2 VAE Epoch 11/150 | β: 0.160 | Train Loss: 0.9496 (MSE: 0.9337, KLD: 0.0995) | Val Loss: 0.9091 (MSE: 0.8939, KLD: 0.0951)\n",
      "2025-05-26 03:49:46 - INFO - 3473208690 - Validation metric improved (0.893860 --> 0.893860). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:47 - INFO - 3473208690 - Fold 2 VAE Epoch 12/150 | β: 0.176 | Train Loss: 0.9420 (MSE: 0.9269, KLD: 0.0856) | Val Loss: 0.9034 (MSE: 0.8882, KLD: 0.0867)\n",
      "2025-05-26 03:49:47 - INFO - 3473208690 - Validation metric improved (0.888180 --> 0.888180). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:48 - INFO - 3473208690 - Fold 2 VAE Epoch 13/150 | β: 0.192 | Train Loss: 0.9329 (MSE: 0.9176, KLD: 0.0796) | Val Loss: 0.8973 (MSE: 0.8807, KLD: 0.0865)\n",
      "2025-05-26 03:49:48 - INFO - 3473208690 - Validation metric improved (0.880674 --> 0.880674). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:49 - INFO - 3473208690 - Fold 2 VAE Epoch 14/150 | β: 0.208 | Train Loss: 0.9291 (MSE: 0.9139, KLD: 0.0734) | Val Loss: 0.8932 (MSE: 0.8793, KLD: 0.0671)\n",
      "2025-05-26 03:49:49 - INFO - 3473208690 - Validation metric improved (0.879273 --> 0.879273). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:50 - INFO - 3473208690 - Fold 2 VAE Epoch 15/150 | β: 0.224 | Train Loss: 0.9250 (MSE: 0.9097, KLD: 0.0684) | Val Loss: 0.8883 (MSE: 0.8712, KLD: 0.0764)\n",
      "2025-05-26 03:49:50 - INFO - 3473208690 - Validation metric improved (0.871245 --> 0.871245). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:51 - INFO - 3473208690 - Fold 2 VAE Epoch 16/150 | β: 0.240 | Train Loss: 0.9203 (MSE: 0.9054, KLD: 0.0624) | Val Loss: 0.8836 (MSE: 0.8651, KLD: 0.0769)\n",
      "2025-05-26 03:49:51 - INFO - 3473208690 - Validation metric improved (0.865116 --> 0.865116). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:52 - INFO - 3473208690 - Fold 2 VAE Epoch 17/150 | β: 0.256 | Train Loss: 0.9168 (MSE: 0.9002, KLD: 0.0649) | Val Loss: 0.8811 (MSE: 0.8681, KLD: 0.0506)\n",
      "2025-05-26 03:49:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.865116|Current: 0.868135)\n",
      "2025-05-26 03:49:53 - INFO - 3473208690 - Fold 2 VAE Epoch 18/150 | β: 0.272 | Train Loss: 0.9126 (MSE: 0.8966, KLD: 0.0589) | Val Loss: 0.8771 (MSE: 0.8578, KLD: 0.0708)\n",
      "2025-05-26 03:49:53 - INFO - 3473208690 - Validation metric improved (0.857811 --> 0.857811). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:55 - INFO - 3473208690 - Fold 2 VAE Epoch 19/150 | β: 0.288 | Train Loss: 0.9103 (MSE: 0.8939, KLD: 0.0569) | Val Loss: 0.8752 (MSE: 0.8611, KLD: 0.0490)\n",
      "2025-05-26 03:49:55 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.857811|Current: 0.861102)\n",
      "2025-05-26 03:49:56 - INFO - 3473208690 - Fold 2 VAE Epoch 20/150 | β: 0.304 | Train Loss: 0.9060 (MSE: 0.8898, KLD: 0.0533) | Val Loss: 0.8746 (MSE: 0.8560, KLD: 0.0610)\n",
      "2025-05-26 03:49:56 - INFO - 3473208690 - Validation metric improved (0.856015 --> 0.856015). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:49:59 - INFO - 3473208690 - Fold 2 VAE Epoch 21/150 | β: 0.320 | Train Loss: 0.9043 (MSE: 0.8867, KLD: 0.0549) | Val Loss: 0.8673 (MSE: 0.8513, KLD: 0.0500)\n",
      "2025-05-26 03:49:59 - INFO - 3473208690 - Validation metric improved (0.851348 --> 0.851348). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:01 - INFO - 3473208690 - Fold 2 VAE Epoch 22/150 | β: 0.336 | Train Loss: 0.9020 (MSE: 0.8848, KLD: 0.0514) | Val Loss: 0.8684 (MSE: 0.8554, KLD: 0.0388)\n",
      "2025-05-26 03:50:01 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.851348|Current: 0.855378)\n",
      "2025-05-26 03:50:02 - INFO - 3473208690 - Fold 2 VAE Epoch 23/150 | β: 0.352 | Train Loss: 0.8990 (MSE: 0.8807, KLD: 0.0519) | Val Loss: 0.8665 (MSE: 0.8487, KLD: 0.0504)\n",
      "2025-05-26 03:50:02 - INFO - 3473208690 - Validation metric improved (0.848718 --> 0.848718). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:04 - INFO - 3473208690 - Fold 2 VAE Epoch 24/150 | β: 0.368 | Train Loss: 0.8986 (MSE: 0.8814, KLD: 0.0467) | Val Loss: 0.8641 (MSE: 0.8458, KLD: 0.0496)\n",
      "2025-05-26 03:50:04 - INFO - 3473208690 - Validation metric improved (0.845808 --> 0.845808). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:07 - INFO - 3473208690 - Fold 2 VAE Epoch 25/150 | β: 0.384 | Train Loss: 0.8948 (MSE: 0.8775, KLD: 0.0449) | Val Loss: 0.8619 (MSE: 0.8433, KLD: 0.0485)\n",
      "2025-05-26 03:50:07 - INFO - 3473208690 - Validation metric improved (0.843316 --> 0.843316). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:10 - INFO - 3473208690 - Fold 2 VAE Epoch 26/150 | β: 0.400 | Train Loss: 0.8932 (MSE: 0.8752, KLD: 0.0450) | Val Loss: 0.8632 (MSE: 0.8451, KLD: 0.0450)\n",
      "2025-05-26 03:50:10 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.843316|Current: 0.845141)\n",
      "2025-05-26 03:50:10 - INFO - 3473208690 - Fold 2 VAE Epoch 27/150 | β: 0.416 | Train Loss: 0.8918 (MSE: 0.8734, KLD: 0.0442) | Val Loss: 0.8580 (MSE: 0.8399, KLD: 0.0435)\n",
      "2025-05-26 03:50:10 - INFO - 3473208690 - Validation metric improved (0.839864 --> 0.839864). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:13 - INFO - 3473208690 - Fold 2 VAE Epoch 28/150 | β: 0.432 | Train Loss: 0.8908 (MSE: 0.8713, KLD: 0.0451) | Val Loss: 0.8643 (MSE: 0.8453, KLD: 0.0439)\n",
      "2025-05-26 03:50:13 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.839864|Current: 0.845297)\n",
      "2025-05-26 03:50:14 - INFO - 3473208690 - Fold 2 VAE Epoch 29/150 | β: 0.448 | Train Loss: 0.8908 (MSE: 0.8721, KLD: 0.0417) | Val Loss: 0.8592 (MSE: 0.8381, KLD: 0.0472)\n",
      "2025-05-26 03:50:14 - INFO - 3473208690 - Validation metric improved (0.838081 --> 0.838081). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:16 - INFO - 3473208690 - Fold 2 VAE Epoch 30/150 | β: 0.464 | Train Loss: 0.8924 (MSE: 0.8730, KLD: 0.0419) | Val Loss: 0.8594 (MSE: 0.8398, KLD: 0.0422)\n",
      "2025-05-26 03:50:16 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.838081|Current: 0.839813)\n",
      "2025-05-26 03:50:17 - INFO - 3473208690 - Fold 2 VAE Epoch 31/150 | β: 0.480 | Train Loss: 0.8911 (MSE: 0.8686, KLD: 0.0469) | Val Loss: 0.8584 (MSE: 0.8401, KLD: 0.0381)\n",
      "2025-05-26 03:50:17 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.838081|Current: 0.840125)\n",
      "2025-05-26 03:50:18 - INFO - 3473208690 - Fold 2 VAE Epoch 32/150 | β: 0.496 | Train Loss: 0.8898 (MSE: 0.8706, KLD: 0.0387) | Val Loss: 0.8594 (MSE: 0.8386, KLD: 0.0420)\n",
      "2025-05-26 03:50:18 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.838081|Current: 0.838605)\n",
      "2025-05-26 03:50:18 - INFO - 3473208690 - Fold 2 VAE Epoch 33/150 | β: 0.512 | Train Loss: 0.8890 (MSE: 0.8678, KLD: 0.0414) | Val Loss: 0.8589 (MSE: 0.8390, KLD: 0.0388)\n",
      "2025-05-26 03:50:18 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.838081|Current: 0.838996)\n",
      "2025-05-26 03:50:19 - INFO - 3473208690 - Fold 2 VAE Epoch 34/150 | β: 0.528 | Train Loss: 0.8918 (MSE: 0.8712, KLD: 0.0391) | Val Loss: 0.8585 (MSE: 0.8376, KLD: 0.0396)\n",
      "2025-05-26 03:50:19 - INFO - 3473208690 - Validation metric improved (0.837556 --> 0.837556). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:20 - INFO - 3473208690 - Fold 2 VAE Epoch 35/150 | β: 0.544 | Train Loss: 0.8953 (MSE: 0.8742, KLD: 0.0388) | Val Loss: 0.8605 (MSE: 0.8397, KLD: 0.0383)\n",
      "2025-05-26 03:50:20 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.837556|Current: 0.839658)\n",
      "2025-05-26 03:50:21 - INFO - 3473208690 - Fold 2 VAE Epoch 36/150 | β: 0.560 | Train Loss: 0.8905 (MSE: 0.8692, KLD: 0.0380) | Val Loss: 0.8598 (MSE: 0.8385, KLD: 0.0379)\n",
      "2025-05-26 03:50:21 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.837556|Current: 0.838550)\n",
      "2025-05-26 03:50:21 - INFO - 3473208690 - Fold 2 VAE Epoch 37/150 | β: 0.576 | Train Loss: 0.8923 (MSE: 0.8706, KLD: 0.0378) | Val Loss: 0.8607 (MSE: 0.8389, KLD: 0.0378)\n",
      "2025-05-26 03:50:21 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.837556|Current: 0.838929)\n",
      "2025-05-26 03:50:22 - INFO - 3473208690 - Fold 2 VAE Epoch 38/150 | β: 0.592 | Train Loss: 0.8993 (MSE: 0.8718, KLD: 0.0465) | Val Loss: 0.8742 (MSE: 0.8267, KLD: 0.0801)\n",
      "2025-05-26 03:50:22 - INFO - 3473208690 - Validation metric improved (0.826722 --> 0.826722). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:23 - INFO - 3473208690 - Fold 2 VAE Epoch 39/150 | β: 0.608 | Train Loss: 0.9031 (MSE: 0.8608, KLD: 0.0697) | Val Loss: 0.8717 (MSE: 0.8579, KLD: 0.0227)\n",
      "2025-05-26 03:50:23 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.826722|Current: 0.857859)\n",
      "2025-05-26 03:50:23 - INFO - 3473208690 - Fold 2 VAE Epoch 40/150 | β: 0.624 | Train Loss: 0.8862 (MSE: 0.8552, KLD: 0.0497) | Val Loss: 0.8506 (MSE: 0.8102, KLD: 0.0647)\n",
      "2025-05-26 03:50:23 - INFO - 3473208690 - Validation metric improved (0.810236 --> 0.810236). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:24 - INFO - 3473208690 - Fold 2 VAE Epoch 41/150 | β: 0.640 | Train Loss: 0.8691 (MSE: 0.8391, KLD: 0.0469) | Val Loss: 0.8288 (MSE: 0.8089, KLD: 0.0311)\n",
      "2025-05-26 03:50:24 - INFO - 3473208690 - Validation metric improved (0.808859 --> 0.808859). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:25 - INFO - 3473208690 - Fold 2 VAE Epoch 42/150 | β: 0.656 | Train Loss: 0.8586 (MSE: 0.8279, KLD: 0.0467) | Val Loss: 0.8220 (MSE: 0.7852, KLD: 0.0560)\n",
      "2025-05-26 03:50:25 - INFO - 3473208690 - Validation metric improved (0.785223 --> 0.785223). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:26 - INFO - 3473208690 - Fold 2 VAE Epoch 43/150 | β: 0.672 | Train Loss: 0.8478 (MSE: 0.8162, KLD: 0.0470) | Val Loss: 0.8097 (MSE: 0.7835, KLD: 0.0389)\n",
      "2025-05-26 03:50:26 - INFO - 3473208690 - Validation metric improved (0.783523 --> 0.783523). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:27 - INFO - 3473208690 - Fold 2 VAE Epoch 44/150 | β: 0.688 | Train Loss: 0.8406 (MSE: 0.8079, KLD: 0.0476) | Val Loss: 0.8096 (MSE: 0.7729, KLD: 0.0534)\n",
      "2025-05-26 03:50:27 - INFO - 3473208690 - Validation metric improved (0.772855 --> 0.772855). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:28 - INFO - 3473208690 - Fold 2 VAE Epoch 45/150 | β: 0.704 | Train Loss: 0.8463 (MSE: 0.8113, KLD: 0.0497) | Val Loss: 0.8091 (MSE: 0.7773, KLD: 0.0452)\n",
      "2025-05-26 03:50:28 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.772855|Current: 0.777311)\n",
      "2025-05-26 03:50:29 - INFO - 3473208690 - Fold 2 VAE Epoch 46/150 | β: 0.720 | Train Loss: 0.8338 (MSE: 0.7978, KLD: 0.0500) | Val Loss: 0.7999 (MSE: 0.7677, KLD: 0.0447)\n",
      "2025-05-26 03:50:29 - INFO - 3473208690 - Validation metric improved (0.767655 --> 0.767655). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:31 - INFO - 3473208690 - Fold 2 VAE Epoch 47/150 | β: 0.736 | Train Loss: 0.8253 (MSE: 0.7938, KLD: 0.0428) | Val Loss: 0.7975 (MSE: 0.7599, KLD: 0.0511)\n",
      "2025-05-26 03:50:31 - INFO - 3473208690 - Validation metric improved (0.759905 --> 0.759905). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:33 - INFO - 3473208690 - Fold 2 VAE Epoch 48/150 | β: 0.752 | Train Loss: 0.8217 (MSE: 0.7890, KLD: 0.0435) | Val Loss: 0.7855 (MSE: 0.7526, KLD: 0.0438)\n",
      "2025-05-26 03:50:33 - INFO - 3473208690 - Validation metric improved (0.752591 --> 0.752591). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:36 - INFO - 3473208690 - Fold 2 VAE Epoch 49/150 | β: 0.768 | Train Loss: 0.8138 (MSE: 0.7818, KLD: 0.0416) | Val Loss: 0.7839 (MSE: 0.7590, KLD: 0.0324)\n",
      "2025-05-26 03:50:36 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.752591|Current: 0.758988)\n",
      "2025-05-26 03:50:36 - INFO - 3473208690 - Fold 2 VAE Epoch 50/150 | β: 0.784 | Train Loss: 0.8118 (MSE: 0.7817, KLD: 0.0384) | Val Loss: 0.7831 (MSE: 0.7598, KLD: 0.0298)\n",
      "2025-05-26 03:50:36 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.752591|Current: 0.759784)\n",
      "2025-05-26 03:50:37 - INFO - 3473208690 - Fold 2 VAE Epoch 51/150 | β: 0.800 | Train Loss: 0.8097 (MSE: 0.7782, KLD: 0.0394) | Val Loss: 0.7831 (MSE: 0.7585, KLD: 0.0308)\n",
      "2025-05-26 03:50:37 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.752591|Current: 0.758485)\n",
      "2025-05-26 03:50:38 - INFO - 3473208690 - Fold 2 VAE Epoch 52/150 | β: 0.800 | Train Loss: 0.8064 (MSE: 0.7759, KLD: 0.0381) | Val Loss: 0.7780 (MSE: 0.7482, KLD: 0.0373)\n",
      "2025-05-26 03:50:38 - INFO - 3473208690 - Validation metric improved (0.748238 --> 0.748238). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:40 - INFO - 3473208690 - Fold 2 VAE Epoch 53/150 | β: 0.800 | Train Loss: 0.8045 (MSE: 0.7742, KLD: 0.0379) | Val Loss: 0.7789 (MSE: 0.7459, KLD: 0.0413)\n",
      "2025-05-26 03:50:40 - INFO - 3473208690 - Validation metric improved (0.745920 --> 0.745920). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:43 - INFO - 3473208690 - Fold 2 VAE Epoch 54/150 | β: 0.800 | Train Loss: 0.8003 (MSE: 0.7690, KLD: 0.0391) | Val Loss: 0.7726 (MSE: 0.7426, KLD: 0.0374)\n",
      "2025-05-26 03:50:43 - INFO - 3473208690 - Validation metric improved (0.742620 --> 0.742620). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:46 - INFO - 3473208690 - Fold 2 VAE Epoch 55/150 | β: 0.800 | Train Loss: 0.8008 (MSE: 0.7706, KLD: 0.0377) | Val Loss: 0.7712 (MSE: 0.7429, KLD: 0.0353)\n",
      "2025-05-26 03:50:46 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.742620|Current: 0.742920)\n",
      "2025-05-26 03:50:46 - INFO - 3473208690 - Fold 2 VAE Epoch 56/150 | β: 0.800 | Train Loss: 0.7992 (MSE: 0.7693, KLD: 0.0373) | Val Loss: 0.7757 (MSE: 0.7463, KLD: 0.0367)\n",
      "2025-05-26 03:50:46 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.742620|Current: 0.746316)\n",
      "2025-05-26 03:50:47 - INFO - 3473208690 - Fold 2 VAE Epoch 57/150 | β: 0.800 | Train Loss: 0.7992 (MSE: 0.7671, KLD: 0.0401) | Val Loss: 0.7755 (MSE: 0.7433, KLD: 0.0403)\n",
      "2025-05-26 03:50:47 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.742620|Current: 0.743315)\n",
      "2025-05-26 03:50:48 - INFO - 3473208690 - Fold 2 VAE Epoch 58/150 | β: 0.800 | Train Loss: 0.7971 (MSE: 0.7661, KLD: 0.0386) | Val Loss: 0.7686 (MSE: 0.7360, KLD: 0.0406)\n",
      "2025-05-26 03:50:48 - INFO - 3473208690 - Validation metric improved (0.736044 --> 0.736044). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:50 - INFO - 3473208690 - Fold 2 VAE Epoch 59/150 | β: 0.800 | Train Loss: 0.7959 (MSE: 0.7658, KLD: 0.0376) | Val Loss: 0.7693 (MSE: 0.7361, KLD: 0.0415)\n",
      "2025-05-26 03:50:50 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.736044|Current: 0.736123)\n",
      "2025-05-26 03:50:51 - INFO - 3473208690 - Fold 2 VAE Epoch 60/150 | β: 0.800 | Train Loss: 0.7945 (MSE: 0.7648, KLD: 0.0371) | Val Loss: 0.7662 (MSE: 0.7342, KLD: 0.0400)\n",
      "2025-05-26 03:50:51 - INFO - 3473208690 - Validation metric improved (0.734156 --> 0.734156). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:53 - INFO - 3473208690 - Fold 2 VAE Epoch 61/150 | β: 0.800 | Train Loss: 0.7935 (MSE: 0.7638, KLD: 0.0371) | Val Loss: 0.7634 (MSE: 0.7359, KLD: 0.0344)\n",
      "2025-05-26 03:50:53 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.734156|Current: 0.735909)\n",
      "2025-05-26 03:50:54 - INFO - 3473208690 - Fold 2 VAE Epoch 62/150 | β: 0.800 | Train Loss: 0.7899 (MSE: 0.7619, KLD: 0.0351) | Val Loss: 0.7707 (MSE: 0.7420, KLD: 0.0359)\n",
      "2025-05-26 03:50:54 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.734156|Current: 0.741987)\n",
      "2025-05-26 03:50:55 - INFO - 3473208690 - Fold 2 VAE Epoch 63/150 | β: 0.800 | Train Loss: 0.7890 (MSE: 0.7596, KLD: 0.0367) | Val Loss: 0.7631 (MSE: 0.7377, KLD: 0.0317)\n",
      "2025-05-26 03:50:55 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.734156|Current: 0.737678)\n",
      "2025-05-26 03:50:55 - INFO - 3473208690 - Fold 2 VAE Epoch 64/150 | β: 0.800 | Train Loss: 0.7896 (MSE: 0.7612, KLD: 0.0355) | Val Loss: 0.7596 (MSE: 0.7306, KLD: 0.0362)\n",
      "2025-05-26 03:50:55 - INFO - 3473208690 - Validation metric improved (0.730561 --> 0.730561). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:56 - INFO - 3473208690 - Fold 2 VAE Epoch 65/150 | β: 0.800 | Train Loss: 0.7870 (MSE: 0.7589, KLD: 0.0351) | Val Loss: 0.7612 (MSE: 0.7319, KLD: 0.0365)\n",
      "2025-05-26 03:50:56 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.730561|Current: 0.731938)\n",
      "2025-05-26 03:50:57 - INFO - 3473208690 - Fold 2 VAE Epoch 66/150 | β: 0.800 | Train Loss: 0.7869 (MSE: 0.7586, KLD: 0.0354) | Val Loss: 0.7594 (MSE: 0.7358, KLD: 0.0295)\n",
      "2025-05-26 03:50:57 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.730561|Current: 0.735814)\n",
      "2025-05-26 03:50:58 - INFO - 3473208690 - Fold 2 VAE Epoch 67/150 | β: 0.800 | Train Loss: 0.7896 (MSE: 0.7617, KLD: 0.0348) | Val Loss: 0.7597 (MSE: 0.7290, KLD: 0.0383)\n",
      "2025-05-26 03:50:58 - INFO - 3473208690 - Validation metric improved (0.729030 --> 0.729030). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:50:58 - INFO - 3473208690 - Fold 2 VAE Epoch 68/150 | β: 0.800 | Train Loss: 0.7878 (MSE: 0.7567, KLD: 0.0389) | Val Loss: 0.7605 (MSE: 0.7351, KLD: 0.0317)\n",
      "2025-05-26 03:50:58 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.729030|Current: 0.735127)\n",
      "2025-05-26 03:50:59 - INFO - 3473208690 - Fold 2 VAE Epoch 69/150 | β: 0.800 | Train Loss: 0.7856 (MSE: 0.7598, KLD: 0.0323) | Val Loss: 0.7652 (MSE: 0.7400, KLD: 0.0315)\n",
      "2025-05-26 03:50:59 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.729030|Current: 0.740018)\n",
      "2025-05-26 03:51:00 - INFO - 3473208690 - Fold 2 VAE Epoch 70/150 | β: 0.800 | Train Loss: 0.7846 (MSE: 0.7567, KLD: 0.0348) | Val Loss: 0.7596 (MSE: 0.7318, KLD: 0.0347)\n",
      "2025-05-26 03:51:00 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.729030|Current: 0.731817)\n",
      "2025-05-26 03:51:00 - INFO - 3473208690 - Fold 2 VAE Epoch 71/150 | β: 0.800 | Train Loss: 0.7842 (MSE: 0.7553, KLD: 0.0362) | Val Loss: 0.7545 (MSE: 0.7273, KLD: 0.0340)\n",
      "2025-05-26 03:51:00 - INFO - 3473208690 - Validation metric improved (0.727335 --> 0.727335). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:01 - INFO - 3473208690 - Fold 2 VAE Epoch 72/150 | β: 0.800 | Train Loss: 0.7865 (MSE: 0.7584, KLD: 0.0351) | Val Loss: 0.7570 (MSE: 0.7308, KLD: 0.0328)\n",
      "2025-05-26 03:51:01 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.727335|Current: 0.730764)\n",
      "2025-05-26 03:51:02 - INFO - 3473208690 - Fold 2 VAE Epoch 73/150 | β: 0.800 | Train Loss: 0.7867 (MSE: 0.7590, KLD: 0.0346) | Val Loss: 0.7586 (MSE: 0.7325, KLD: 0.0326)\n",
      "2025-05-26 03:51:02 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.727335|Current: 0.732470)\n",
      "2025-05-26 03:51:03 - INFO - 3473208690 - Fold 2 VAE Epoch 74/150 | β: 0.800 | Train Loss: 0.7868 (MSE: 0.7593, KLD: 0.0345) | Val Loss: 0.7651 (MSE: 0.7389, KLD: 0.0326)\n",
      "2025-05-26 03:51:03 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.727335|Current: 0.738950)\n",
      "2025-05-26 03:51:03 - INFO - 3473208690 - Fold 2 VAE Epoch 75/150 | β: 0.800 | Train Loss: 0.7870 (MSE: 0.7550, KLD: 0.0399) | Val Loss: 0.7618 (MSE: 0.7373, KLD: 0.0306)\n",
      "2025-05-26 03:51:03 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.727335|Current: 0.737341)\n",
      "2025-05-26 03:51:04 - INFO - 3473208690 - Fold 2 VAE Epoch 76/150 | β: 0.800 | Train Loss: 0.7880 (MSE: 0.7567, KLD: 0.0391) | Val Loss: 0.7592 (MSE: 0.7293, KLD: 0.0374)\n",
      "2025-05-26 03:51:04 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.727335|Current: 0.729289)\n",
      "2025-05-26 03:51:05 - INFO - 3473208690 - Fold 2 VAE Epoch 77/150 | β: 0.800 | Train Loss: 0.7871 (MSE: 0.7566, KLD: 0.0381) | Val Loss: 0.7713 (MSE: 0.7309, KLD: 0.0505)\n",
      "2025-05-26 03:51:05 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.727335|Current: 0.730935)\n",
      "2025-05-26 03:51:05 - INFO - 3473208690 - Fold 2 VAE Epoch 78/150 | β: 0.800 | Train Loss: 0.7952 (MSE: 0.7585, KLD: 0.0458) | Val Loss: 0.7625 (MSE: 0.7241, KLD: 0.0481)\n",
      "2025-05-26 03:51:05 - INFO - 3473208690 - Validation metric improved (0.724066 --> 0.724066). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:06 - INFO - 3473208690 - Fold 2 VAE Epoch 79/150 | β: 0.800 | Train Loss: 0.7860 (MSE: 0.7514, KLD: 0.0432) | Val Loss: 0.7591 (MSE: 0.7360, KLD: 0.0289)\n",
      "2025-05-26 03:51:06 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.724066|Current: 0.735989)\n",
      "2025-05-26 03:51:07 - INFO - 3473208690 - Fold 2 VAE Epoch 80/150 | β: 0.800 | Train Loss: 0.7819 (MSE: 0.7510, KLD: 0.0385) | Val Loss: 0.7608 (MSE: 0.7209, KLD: 0.0499)\n",
      "2025-05-26 03:51:07 - INFO - 3473208690 - Validation metric improved (0.720863 --> 0.720863). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:08 - INFO - 3473208690 - Fold 2 VAE Epoch 81/150 | β: 0.800 | Train Loss: 0.7796 (MSE: 0.7457, KLD: 0.0424) | Val Loss: 0.7561 (MSE: 0.7240, KLD: 0.0401)\n",
      "2025-05-26 03:51:08 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.720863|Current: 0.723993)\n",
      "2025-05-26 03:51:08 - INFO - 3473208690 - Fold 2 VAE Epoch 82/150 | β: 0.800 | Train Loss: 0.7777 (MSE: 0.7484, KLD: 0.0365) | Val Loss: 0.7512 (MSE: 0.7237, KLD: 0.0344)\n",
      "2025-05-26 03:51:08 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.720863|Current: 0.723701)\n",
      "2025-05-26 03:51:09 - INFO - 3473208690 - Fold 2 VAE Epoch 83/150 | β: 0.800 | Train Loss: 0.7817 (MSE: 0.7500, KLD: 0.0396) | Val Loss: 0.7585 (MSE: 0.7282, KLD: 0.0379)\n",
      "2025-05-26 03:51:09 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.720863|Current: 0.728156)\n",
      "2025-05-26 03:51:10 - INFO - 3473208690 - Fold 2 VAE Epoch 84/150 | β: 0.800 | Train Loss: 0.7795 (MSE: 0.7475, KLD: 0.0401) | Val Loss: 0.7579 (MSE: 0.7332, KLD: 0.0309)\n",
      "2025-05-26 03:51:10 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.720863|Current: 0.733207)\n",
      "2025-05-26 03:51:10 - INFO - 3473208690 - Fold 2 VAE Epoch 85/150 | β: 0.800 | Train Loss: 0.7840 (MSE: 0.7502, KLD: 0.0422) | Val Loss: 0.7704 (MSE: 0.7214, KLD: 0.0613)\n",
      "2025-05-26 03:51:10 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.720863|Current: 0.721435)\n",
      "2025-05-26 03:51:11 - INFO - 3473208690 - Fold 2 VAE Epoch 86/150 | β: 0.800 | Train Loss: 0.7839 (MSE: 0.7451, KLD: 0.0486) | Val Loss: 0.7694 (MSE: 0.7230, KLD: 0.0581)\n",
      "2025-05-26 03:51:11 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.720863|Current: 0.722987)\n",
      "2025-05-26 03:51:12 - INFO - 3473208690 - Fold 2 VAE Epoch 87/150 | β: 0.800 | Train Loss: 0.7823 (MSE: 0.7437, KLD: 0.0482) | Val Loss: 0.7586 (MSE: 0.7106, KLD: 0.0601)\n",
      "2025-05-26 03:51:12 - INFO - 3473208690 - Validation metric improved (0.710578 --> 0.710578). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:13 - INFO - 3473208690 - Fold 2 VAE Epoch 88/150 | β: 0.800 | Train Loss: 0.7767 (MSE: 0.7412, KLD: 0.0443) | Val Loss: 0.7453 (MSE: 0.7102, KLD: 0.0440)\n",
      "2025-05-26 03:51:13 - INFO - 3473208690 - Validation metric improved (0.710156 --> 0.710156). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:14 - INFO - 3473208690 - Fold 2 VAE Epoch 89/150 | β: 0.800 | Train Loss: 0.7703 (MSE: 0.7403, KLD: 0.0375) | Val Loss: 0.7402 (MSE: 0.7086, KLD: 0.0395)\n",
      "2025-05-26 03:51:14 - INFO - 3473208690 - Validation metric improved (0.708601 --> 0.708601). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:14 - INFO - 3473208690 - Fold 2 VAE Epoch 90/150 | β: 0.800 | Train Loss: 0.7659 (MSE: 0.7362, KLD: 0.0371) | Val Loss: 0.7537 (MSE: 0.7240, KLD: 0.0372)\n",
      "2025-05-26 03:51:14 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.708601|Current: 0.723962)\n",
      "2025-05-26 03:51:15 - INFO - 3473208690 - Fold 2 VAE Epoch 91/150 | β: 0.800 | Train Loss: 0.7674 (MSE: 0.7384, KLD: 0.0361) | Val Loss: 0.7460 (MSE: 0.7171, KLD: 0.0361)\n",
      "2025-05-26 03:51:15 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.708601|Current: 0.717140)\n",
      "2025-05-26 03:51:16 - INFO - 3473208690 - Fold 2 VAE Epoch 92/150 | β: 0.800 | Train Loss: 0.7682 (MSE: 0.7374, KLD: 0.0385) | Val Loss: 0.7382 (MSE: 0.7135, KLD: 0.0309)\n",
      "2025-05-26 03:51:16 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.708601|Current: 0.713516)\n",
      "2025-05-26 03:51:16 - INFO - 3473208690 - Fold 2 VAE Epoch 93/150 | β: 0.800 | Train Loss: 0.7634 (MSE: 0.7340, KLD: 0.0368) | Val Loss: 0.7394 (MSE: 0.7104, KLD: 0.0362)\n",
      "2025-05-26 03:51:16 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.708601|Current: 0.710357)\n",
      "2025-05-26 03:51:17 - INFO - 3473208690 - Fold 2 VAE Epoch 94/150 | β: 0.800 | Train Loss: 0.7602 (MSE: 0.7329, KLD: 0.0341) | Val Loss: 0.7408 (MSE: 0.7117, KLD: 0.0364)\n",
      "2025-05-26 03:51:17 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.708601|Current: 0.711724)\n",
      "2025-05-26 03:51:18 - INFO - 3473208690 - Fold 2 VAE Epoch 95/150 | β: 0.800 | Train Loss: 0.7614 (MSE: 0.7327, KLD: 0.0358) | Val Loss: 0.7455 (MSE: 0.7191, KLD: 0.0329)\n",
      "2025-05-26 03:51:18 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.708601|Current: 0.719150)\n",
      "2025-05-26 03:51:18 - INFO - 3473208690 - Fold 2 VAE Epoch 96/150 | β: 0.800 | Train Loss: 0.7618 (MSE: 0.7339, KLD: 0.0349) | Val Loss: 0.7435 (MSE: 0.7169, KLD: 0.0333)\n",
      "2025-05-26 03:51:18 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.708601|Current: 0.716879)\n",
      "2025-05-26 03:51:19 - INFO - 3473208690 - Fold 2 VAE Epoch 97/150 | β: 0.800 | Train Loss: 0.7623 (MSE: 0.7312, KLD: 0.0388) | Val Loss: 0.7415 (MSE: 0.7117, KLD: 0.0373)\n",
      "2025-05-26 03:51:19 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.708601|Current: 0.711716)\n",
      "2025-05-26 03:51:20 - INFO - 3473208690 - Fold 2 VAE Epoch 98/150 | β: 0.800 | Train Loss: 0.7594 (MSE: 0.7312, KLD: 0.0353) | Val Loss: 0.7452 (MSE: 0.7194, KLD: 0.0323)\n",
      "2025-05-26 03:51:20 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.708601|Current: 0.719392)\n",
      "2025-05-26 03:51:20 - INFO - 3473208690 - Fold 2 VAE Epoch 99/150 | β: 0.800 | Train Loss: 0.7591 (MSE: 0.7310, KLD: 0.0351) | Val Loss: 0.7359 (MSE: 0.7086, KLD: 0.0341)\n",
      "2025-05-26 03:51:20 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.708601|Current: 0.708624)\n",
      "2025-05-26 03:51:21 - INFO - 3473208690 - Fold 2 VAE Epoch 100/150 | β: 0.800 | Train Loss: 0.7592 (MSE: 0.7317, KLD: 0.0344) | Val Loss: 0.7351 (MSE: 0.7075, KLD: 0.0346)\n",
      "2025-05-26 03:51:21 - INFO - 3473208690 - Validation metric improved (0.707469 --> 0.707469). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:23 - INFO - 3473208690 - Fold 2 VAE Epoch 101/150 | β: 0.800 | Train Loss: 0.7600 (MSE: 0.7311, KLD: 0.0362) | Val Loss: 0.7376 (MSE: 0.7106, KLD: 0.0338)\n",
      "2025-05-26 03:51:23 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.707469|Current: 0.710560)\n",
      "2025-05-26 03:51:24 - INFO - 3473208690 - Fold 2 VAE Epoch 102/150 | β: 0.800 | Train Loss: 0.7608 (MSE: 0.7314, KLD: 0.0367) | Val Loss: 0.7350 (MSE: 0.7079, KLD: 0.0338)\n",
      "2025-05-26 03:51:24 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.707469|Current: 0.707919)\n",
      "2025-05-26 03:51:25 - INFO - 3473208690 - Fold 2 VAE Epoch 103/150 | β: 0.800 | Train Loss: 0.7574 (MSE: 0.7296, KLD: 0.0347) | Val Loss: 0.7329 (MSE: 0.7088, KLD: 0.0301)\n",
      "2025-05-26 03:51:25 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.707469|Current: 0.708807)\n",
      "2025-05-26 03:51:25 - INFO - 3473208690 - Fold 2 VAE Epoch 104/150 | β: 0.800 | Train Loss: 0.7578 (MSE: 0.7312, KLD: 0.0333) | Val Loss: 0.7434 (MSE: 0.7163, KLD: 0.0338)\n",
      "2025-05-26 03:51:25 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.707469|Current: 0.716309)\n",
      "2025-05-26 03:51:26 - INFO - 3473208690 - Fold 2 VAE Epoch 105/150 | β: 0.800 | Train Loss: 0.7570 (MSE: 0.7285, KLD: 0.0356) | Val Loss: 0.7352 (MSE: 0.7089, KLD: 0.0330)\n",
      "2025-05-26 03:51:26 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.707469|Current: 0.708867)\n",
      "2025-05-26 03:51:27 - INFO - 3473208690 - Fold 2 VAE Epoch 106/150 | β: 0.800 | Train Loss: 0.7608 (MSE: 0.7320, KLD: 0.0359) | Val Loss: 0.7327 (MSE: 0.7059, KLD: 0.0335)\n",
      "2025-05-26 03:51:27 - INFO - 3473208690 - Validation metric improved (0.705928 --> 0.705928). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:29 - INFO - 3473208690 - Fold 2 VAE Epoch 107/150 | β: 0.800 | Train Loss: 0.7565 (MSE: 0.7282, KLD: 0.0353) | Val Loss: 0.7371 (MSE: 0.7110, KLD: 0.0325)\n",
      "2025-05-26 03:51:29 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.705928|Current: 0.711031)\n",
      "2025-05-26 03:51:30 - INFO - 3473208690 - Fold 2 VAE Epoch 108/150 | β: 0.800 | Train Loss: 0.7580 (MSE: 0.7302, KLD: 0.0347) | Val Loss: 0.7351 (MSE: 0.7090, KLD: 0.0327)\n",
      "2025-05-26 03:51:30 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.705928|Current: 0.708990)\n",
      "2025-05-26 03:51:31 - INFO - 3473208690 - Fold 2 VAE Epoch 109/150 | β: 0.800 | Train Loss: 0.7575 (MSE: 0.7296, KLD: 0.0348) | Val Loss: 0.7342 (MSE: 0.7085, KLD: 0.0322)\n",
      "2025-05-26 03:51:31 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.705928|Current: 0.708493)\n",
      "2025-05-26 03:51:31 - INFO - 3473208690 - Fold 2 VAE Epoch 110/150 | β: 0.800 | Train Loss: 0.7603 (MSE: 0.7328, KLD: 0.0344) | Val Loss: 0.7368 (MSE: 0.7111, KLD: 0.0321)\n",
      "2025-05-26 03:51:31 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.705928|Current: 0.711071)\n",
      "2025-05-26 03:51:32 - INFO - 3473208690 - Fold 2 VAE Epoch 111/150 | β: 0.800 | Train Loss: 0.7558 (MSE: 0.7283, KLD: 0.0344) | Val Loss: 0.7419 (MSE: 0.7161, KLD: 0.0322)\n",
      "2025-05-26 03:51:32 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.705928|Current: 0.716139)\n",
      "2025-05-26 03:51:33 - INFO - 3473208690 - Fold 2 VAE Epoch 112/150 | β: 0.800 | Train Loss: 0.7654 (MSE: 0.7342, KLD: 0.0390) | Val Loss: 0.7662 (MSE: 0.7147, KLD: 0.0645)\n",
      "2025-05-26 03:51:33 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.705928|Current: 0.714658)\n",
      "2025-05-26 03:51:33 - INFO - 3473208690 - Fold 2 VAE Epoch 113/150 | β: 0.800 | Train Loss: 0.7787 (MSE: 0.7369, KLD: 0.0522) | Val Loss: 0.7632 (MSE: 0.7148, KLD: 0.0604)\n",
      "2025-05-26 03:51:33 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.705928|Current: 0.714845)\n",
      "2025-05-26 03:51:34 - INFO - 3473208690 - Fold 2 VAE Epoch 114/150 | β: 0.800 | Train Loss: 0.7732 (MSE: 0.7339, KLD: 0.0491) | Val Loss: 0.7408 (MSE: 0.7052, KLD: 0.0444)\n",
      "2025-05-26 03:51:34 - INFO - 3473208690 - Validation metric improved (0.705224 --> 0.705224). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:36 - INFO - 3473208690 - Fold 2 VAE Epoch 115/150 | β: 0.800 | Train Loss: 0.7704 (MSE: 0.7339, KLD: 0.0456) | Val Loss: 0.7480 (MSE: 0.7237, KLD: 0.0304)\n",
      "2025-05-26 03:51:36 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.705224|Current: 0.723709)\n",
      "2025-05-26 03:51:37 - INFO - 3473208690 - Fold 2 VAE Epoch 116/150 | β: 0.800 | Train Loss: 0.7656 (MSE: 0.7310, KLD: 0.0433) | Val Loss: 0.7368 (MSE: 0.7168, KLD: 0.0250)\n",
      "2025-05-26 03:51:37 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.705224|Current: 0.716792)\n",
      "2025-05-26 03:51:38 - INFO - 3473208690 - Fold 2 VAE Epoch 117/150 | β: 0.800 | Train Loss: 0.7653 (MSE: 0.7325, KLD: 0.0410) | Val Loss: 0.7525 (MSE: 0.7313, KLD: 0.0265)\n",
      "2025-05-26 03:51:38 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.705224|Current: 0.731308)\n",
      "2025-05-26 03:51:38 - INFO - 3473208690 - Fold 2 VAE Epoch 118/150 | β: 0.800 | Train Loss: 0.7695 (MSE: 0.7321, KLD: 0.0468) | Val Loss: 0.7457 (MSE: 0.7154, KLD: 0.0378)\n",
      "2025-05-26 03:51:38 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.705224|Current: 0.715413)\n",
      "2025-05-26 03:51:39 - INFO - 3473208690 - Fold 2 VAE Epoch 119/150 | β: 0.800 | Train Loss: 0.7577 (MSE: 0.7258, KLD: 0.0399) | Val Loss: 0.7291 (MSE: 0.7011, KLD: 0.0349)\n",
      "2025-05-26 03:51:39 - INFO - 3473208690 - Validation metric improved (0.701131 --> 0.701131). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:41 - INFO - 3473208690 - Fold 2 VAE Epoch 120/150 | β: 0.800 | Train Loss: 0.7546 (MSE: 0.7256, KLD: 0.0363) | Val Loss: 0.7359 (MSE: 0.7070, KLD: 0.0362)\n",
      "2025-05-26 03:51:41 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.701131|Current: 0.706969)\n",
      "2025-05-26 03:51:42 - INFO - 3473208690 - Fold 2 VAE Epoch 121/150 | β: 0.800 | Train Loss: 0.7553 (MSE: 0.7254, KLD: 0.0373) | Val Loss: 0.7376 (MSE: 0.7041, KLD: 0.0418)\n",
      "2025-05-26 03:51:42 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.701131|Current: 0.704122)\n",
      "2025-05-26 03:51:43 - INFO - 3473208690 - Fold 2 VAE Epoch 122/150 | β: 0.800 | Train Loss: 0.7528 (MSE: 0.7221, KLD: 0.0384) | Val Loss: 0.7283 (MSE: 0.6975, KLD: 0.0385)\n",
      "2025-05-26 03:51:43 - INFO - 3473208690 - Validation metric improved (0.697493 --> 0.697493). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:43 - INFO - 3473208690 - Fold 2 VAE Epoch 123/150 | β: 0.800 | Train Loss: 0.7529 (MSE: 0.7220, KLD: 0.0386) | Val Loss: 0.7279 (MSE: 0.6946, KLD: 0.0417)\n",
      "2025-05-26 03:51:43 - INFO - 3473208690 - Validation metric improved (0.694574 --> 0.694574). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:44 - INFO - 3473208690 - Fold 2 VAE Epoch 124/150 | β: 0.800 | Train Loss: 0.7555 (MSE: 0.7243, KLD: 0.0390) | Val Loss: 0.7296 (MSE: 0.6976, KLD: 0.0400)\n",
      "2025-05-26 03:51:44 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.694574|Current: 0.697619)\n",
      "2025-05-26 03:51:45 - INFO - 3473208690 - Fold 2 VAE Epoch 125/150 | β: 0.800 | Train Loss: 0.7526 (MSE: 0.7242, KLD: 0.0354) | Val Loss: 0.7338 (MSE: 0.6959, KLD: 0.0473)\n",
      "2025-05-26 03:51:45 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.694574|Current: 0.695922)\n",
      "2025-05-26 03:51:46 - INFO - 3473208690 - Fold 2 VAE Epoch 126/150 | β: 0.800 | Train Loss: 0.7542 (MSE: 0.7203, KLD: 0.0424) | Val Loss: 0.7276 (MSE: 0.6987, KLD: 0.0362)\n",
      "2025-05-26 03:51:46 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.694574|Current: 0.698654)\n",
      "2025-05-26 03:51:46 - INFO - 3473208690 - Fold 2 VAE Epoch 127/150 | β: 0.800 | Train Loss: 0.7497 (MSE: 0.7190, KLD: 0.0384) | Val Loss: 0.7226 (MSE: 0.7010, KLD: 0.0270)\n",
      "2025-05-26 03:51:46 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.694574|Current: 0.701017)\n",
      "2025-05-26 03:51:47 - INFO - 3473208690 - Fold 2 VAE Epoch 128/150 | β: 0.800 | Train Loss: 0.7488 (MSE: 0.7217, KLD: 0.0339) | Val Loss: 0.7295 (MSE: 0.7021, KLD: 0.0342)\n",
      "2025-05-26 03:51:47 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.694574|Current: 0.702148)\n",
      "2025-05-26 03:51:48 - INFO - 3473208690 - Fold 2 VAE Epoch 129/150 | β: 0.800 | Train Loss: 0.7480 (MSE: 0.7188, KLD: 0.0365) | Val Loss: 0.7273 (MSE: 0.6975, KLD: 0.0373)\n",
      "2025-05-26 03:51:48 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.694574|Current: 0.697471)\n",
      "2025-05-26 03:51:48 - INFO - 3473208690 - Fold 2 VAE Epoch 130/150 | β: 0.800 | Train Loss: 0.7502 (MSE: 0.7214, KLD: 0.0360) | Val Loss: 0.7292 (MSE: 0.6972, KLD: 0.0400)\n",
      "2025-05-26 03:51:48 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.694574|Current: 0.697210)\n",
      "2025-05-26 03:51:49 - INFO - 3473208690 - Fold 2 VAE Epoch 131/150 | β: 0.800 | Train Loss: 0.7490 (MSE: 0.7178, KLD: 0.0390) | Val Loss: 0.7191 (MSE: 0.6922, KLD: 0.0336)\n",
      "2025-05-26 03:51:49 - INFO - 3473208690 - Validation metric improved (0.692212 --> 0.692212). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt ...\n",
      "2025-05-26 03:51:50 - INFO - 3473208690 - Fold 2 VAE Epoch 132/150 | β: 0.800 | Train Loss: 0.7481 (MSE: 0.7182, KLD: 0.0374) | Val Loss: 0.7359 (MSE: 0.7106, KLD: 0.0317)\n",
      "2025-05-26 03:51:50 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.692212|Current: 0.710599)\n",
      "2025-05-26 03:51:50 - INFO - 3473208690 - Fold 2 VAE Epoch 133/150 | β: 0.800 | Train Loss: 0.7450 (MSE: 0.7160, KLD: 0.0363) | Val Loss: 0.7252 (MSE: 0.7019, KLD: 0.0292)\n",
      "2025-05-26 03:51:50 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.692212|Current: 0.701881)\n",
      "2025-05-26 03:51:51 - INFO - 3473208690 - Fold 2 VAE Epoch 134/150 | β: 0.800 | Train Loss: 0.7425 (MSE: 0.7158, KLD: 0.0334) | Val Loss: 0.7248 (MSE: 0.6990, KLD: 0.0323)\n",
      "2025-05-26 03:51:51 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.692212|Current: 0.699001)\n",
      "2025-05-26 03:51:52 - INFO - 3473208690 - Fold 2 VAE Epoch 135/150 | β: 0.800 | Train Loss: 0.7477 (MSE: 0.7200, KLD: 0.0346) | Val Loss: 0.7281 (MSE: 0.6964, KLD: 0.0396)\n",
      "2025-05-26 03:51:52 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.692212|Current: 0.696434)\n",
      "2025-05-26 03:51:52 - INFO - 3473208690 - Fold 2 VAE Epoch 136/150 | β: 0.800 | Train Loss: 0.7470 (MSE: 0.7159, KLD: 0.0390) | Val Loss: 0.7257 (MSE: 0.7021, KLD: 0.0295)\n",
      "2025-05-26 03:51:52 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.692212|Current: 0.702084)\n",
      "2025-05-26 03:51:53 - INFO - 3473208690 - Fold 2 VAE Epoch 137/150 | β: 0.800 | Train Loss: 0.7461 (MSE: 0.7160, KLD: 0.0376) | Val Loss: 0.7237 (MSE: 0.6947, KLD: 0.0363)\n",
      "2025-05-26 03:51:53 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.692212|Current: 0.694688)\n",
      "2025-05-26 03:51:54 - INFO - 3473208690 - Fold 2 VAE Epoch 138/150 | β: 0.800 | Train Loss: 0.7444 (MSE: 0.7162, KLD: 0.0353) | Val Loss: 0.7206 (MSE: 0.6966, KLD: 0.0301)\n",
      "2025-05-26 03:51:54 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.692212|Current: 0.696555)\n",
      "2025-05-26 03:51:54 - INFO - 3473208690 - Fold 2 VAE Epoch 139/150 | β: 0.800 | Train Loss: 0.7440 (MSE: 0.7173, KLD: 0.0333) | Val Loss: 0.7226 (MSE: 0.6969, KLD: 0.0321)\n",
      "2025-05-26 03:51:54 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.692212|Current: 0.696889)\n",
      "2025-05-26 03:51:55 - INFO - 3473208690 - Fold 2 VAE Epoch 140/150 | β: 0.800 | Train Loss: 0.7431 (MSE: 0.7152, KLD: 0.0349) | Val Loss: 0.7245 (MSE: 0.7001, KLD: 0.0304)\n",
      "2025-05-26 03:51:55 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.692212|Current: 0.700130)\n",
      "2025-05-26 03:51:56 - INFO - 3473208690 - Fold 2 VAE Epoch 141/150 | β: 0.800 | Train Loss: 0.7405 (MSE: 0.7146, KLD: 0.0324) | Val Loss: 0.7258 (MSE: 0.7024, KLD: 0.0293)\n",
      "2025-05-26 03:51:56 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.692212|Current: 0.702375)\n",
      "2025-05-26 03:51:56 - INFO - 3473208690 - Fold 2 VAE Epoch 142/150 | β: 0.800 | Train Loss: 0.7424 (MSE: 0.7162, KLD: 0.0328) | Val Loss: 0.7227 (MSE: 0.6980, KLD: 0.0309)\n",
      "2025-05-26 03:51:56 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.692212|Current: 0.698040)\n",
      "2025-05-26 03:51:57 - INFO - 3473208690 - Fold 2 VAE Epoch 143/150 | β: 0.800 | Train Loss: 0.7434 (MSE: 0.7163, KLD: 0.0339) | Val Loss: 0.7214 (MSE: 0.6960, KLD: 0.0318)\n",
      "2025-05-26 03:51:57 - INFO - 3473208690 - EarlyStopping counter: 12 out of 15 (Best: 0.692212|Current: 0.695962)\n",
      "2025-05-26 03:51:58 - INFO - 3473208690 - Fold 2 VAE Epoch 144/150 | β: 0.800 | Train Loss: 0.7444 (MSE: 0.7160, KLD: 0.0356) | Val Loss: 0.7217 (MSE: 0.6955, KLD: 0.0327)\n",
      "2025-05-26 03:51:58 - INFO - 3473208690 - EarlyStopping counter: 13 out of 15 (Best: 0.692212|Current: 0.695532)\n",
      "2025-05-26 03:51:58 - INFO - 3473208690 - Fold 2 VAE Epoch 145/150 | β: 0.800 | Train Loss: 0.7458 (MSE: 0.7174, KLD: 0.0356) | Val Loss: 0.7221 (MSE: 0.6965, KLD: 0.0321)\n",
      "2025-05-26 03:51:58 - INFO - 3473208690 - EarlyStopping counter: 14 out of 15 (Best: 0.692212|Current: 0.696484)\n",
      "2025-05-26 03:51:59 - INFO - 3473208690 - Fold 2 VAE Epoch 146/150 | β: 0.800 | Train Loss: 0.7434 (MSE: 0.7156, KLD: 0.0348) | Val Loss: 0.7196 (MSE: 0.6942, KLD: 0.0318)\n",
      "2025-05-26 03:51:59 - INFO - 3473208690 - EarlyStopping counter: 15 out of 15 (Best: 0.692212|Current: 0.694181)\n",
      "2025-05-26 03:51:59 - INFO - 3473208690 - Early stopping VAE training.\n",
      "2025-05-26 03:51:59 - INFO - 3473208690 - Loaded best VAE model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_vae_model.pt\n",
      "2025-05-26 03:51:59 - INFO - 3473208690 - --- Extracting Latent Features (mu only) for Train, Val, Test ---\n",
      "2025-05-26 03:52:00 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_1/fold_1_preprocessed_data.pt for test split.\n",
      "2025-05-26 03:52:00 - WARNING - 3473208690 - Test split keys not found in preprocessed_connectomes_for_dl/fold_1/fold_1_preprocessed_data.pt. Test set will be empty.\n",
      "2025-05-26 03:52:00 - INFO - 3473208690 - Loaded 0 samples for test split.\n",
      "2025-05-26 03:52:00 - WARNING - 3473208690 - Fold 2: Test dataset is empty. Skipping test set evaluation for this fold.\n",
      "2025-05-26 03:52:00 - INFO - 3473208690 - --- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\n",
      "2025-05-26 03:52:00 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha: [1.0352112  0.96710527]\n",
      "2025-05-26 03:52:00 - INFO - 3473208690 - Validation metric improved (0.431287 --> 0.431287). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:52:01 - INFO - 3473208690 - Validation metric improved (0.507310 --> 0.507310). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:52:01 - INFO - 3473208690 - Validation metric improved (0.548246 --> 0.548246). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:52:02 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.548246|Current: 0.546784)\n",
      "2025-05-26 03:52:02 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.548246|Current: 0.533626)\n",
      "2025-05-26 03:52:03 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.548246|Current: 0.516082)\n",
      "2025-05-26 03:52:03 - INFO - 3473208690 - EarlyStopping counter: 4 out of 10 (Best: 0.548246|Current: 0.516082)\n",
      "2025-05-26 03:52:04 - INFO - 3473208690 - EarlyStopping counter: 5 out of 10 (Best: 0.548246|Current: 0.508772)\n",
      "2025-05-26 03:52:04 - INFO - 3473208690 - EarlyStopping counter: 6 out of 10 (Best: 0.548246|Current: 0.497076)\n",
      "2025-05-26 03:52:05 - INFO - 3473208690 - EarlyStopping counter: 7 out of 10 (Best: 0.548246|Current: 0.479532)\n",
      "2025-05-26 03:52:05 - INFO - 3473208690 - EarlyStopping counter: 8 out of 10 (Best: 0.548246|Current: 0.491228)\n",
      "2025-05-26 03:52:05 - INFO - 3473208690 - EarlyStopping counter: 9 out of 10 (Best: 0.548246|Current: 0.502924)\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - EarlyStopping counter: 10 out of 10 (Best: 0.548246|Current: 0.519006)\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - Early stopping initial classifier training.\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - Loaded best initial classifier model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/best_initial_classifier_model.pt.\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - Fold 2 Initial Best Classifier Val Metrics: Acc: 0.5135, AUC: 0.5482, F1: 0.4375\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - --- Classifier Re-training Phase (CN vs AD) on Train+Val ---\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha for retraining: [1.0337079 0.9684211]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:52:06 - INFO - 3473208690 - Re-training classifier on combined train+val data for 30 epochs.\n",
      "2025-05-26 03:52:08 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 5/30 | Train Loss: 0.2300, Acc: 0.4837\n",
      "2025-05-26 03:52:09 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 10/30 | Train Loss: 0.2209, Acc: 0.5543\n",
      "2025-05-26 03:52:10 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 15/30 | Train Loss: 0.1826, Acc: 0.5924\n",
      "2025-05-26 03:52:12 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 20/30 | Train Loss: 0.2151, Acc: 0.5326\n",
      "2025-05-26 03:52:13 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 25/30 | Train Loss: 0.1697, Acc: 0.6250\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Fold 2 CLF Re-train Epoch 30/30 | Train Loss: 0.1901, Acc: 0.6033\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Saved final classifier model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_1/final_classifier_model.pt\n",
      "2025-05-26 03:52:15 - WARNING - 3473208690 - Fold 2: Test data latent features are empty. Skipping test set evaluation.\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - --- Processing Fold 3/51 ---\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_2/fold_2_preprocessed_data.pt for train split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Loaded 282 samples for train split.\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_2/fold_2_preprocessed_data.pt for val split.\n",
      "2025-05-26 03:52:15 - INFO - 3473208690 - Loaded 70 samples for val split.\n",
      "2025-05-26 03:52:16 - INFO - 3473208690 - Fold 3 VAE Epoch 1/150 | β: 0.000 | Train Loss: 1.2104 (MSE: 1.2104, KLD: 2.1155) | Val Loss: 1.0677 (MSE: 1.0677, KLD: 6.0386)\n",
      "2025-05-26 03:52:16 - INFO - 3473208690 - Validation metric improved (1.067722 --> 1.067722). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:16 - INFO - 3473208690 - Fold 3 VAE Epoch 2/150 | β: 0.016 | Train Loss: 1.1039 (MSE: 1.0470, KLD: 3.5586) | Val Loss: 1.0267 (MSE: 1.0155, KLD: 0.6977)\n",
      "2025-05-26 03:52:16 - INFO - 3473208690 - Validation metric improved (1.015513 --> 1.015513). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:17 - INFO - 3473208690 - Fold 3 VAE Epoch 3/150 | β: 0.032 | Train Loss: 1.0337 (MSE: 1.0127, KLD: 0.6549) | Val Loss: 0.9963 (MSE: 0.9740, KLD: 0.6963)\n",
      "2025-05-26 03:52:17 - INFO - 3473208690 - Validation metric improved (0.973975 --> 0.973975). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:18 - INFO - 3473208690 - Fold 3 VAE Epoch 4/150 | β: 0.048 | Train Loss: 1.0051 (MSE: 0.9813, KLD: 0.4948) | Val Loss: 0.9772 (MSE: 0.9550, KLD: 0.4631)\n",
      "2025-05-26 03:52:18 - INFO - 3473208690 - Validation metric improved (0.954998 --> 0.954998). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:19 - INFO - 3473208690 - Fold 3 VAE Epoch 5/150 | β: 0.064 | Train Loss: 0.9881 (MSE: 0.9660, KLD: 0.3461) | Val Loss: 0.9623 (MSE: 0.9392, KLD: 0.3602)\n",
      "2025-05-26 03:52:19 - INFO - 3473208690 - Validation metric improved (0.939206 --> 0.939206). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:20 - INFO - 3473208690 - Fold 3 VAE Epoch 6/150 | β: 0.080 | Train Loss: 0.9752 (MSE: 0.9538, KLD: 0.2673) | Val Loss: 0.9479 (MSE: 0.9280, KLD: 0.2483)\n",
      "2025-05-26 03:52:20 - INFO - 3473208690 - Validation metric improved (0.928039 --> 0.928039). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:21 - INFO - 3473208690 - Fold 3 VAE Epoch 7/150 | β: 0.096 | Train Loss: 0.9588 (MSE: 0.9392, KLD: 0.2037) | Val Loss: 0.9371 (MSE: 0.9219, KLD: 0.1578)\n",
      "2025-05-26 03:52:21 - INFO - 3473208690 - Validation metric improved (0.921906 --> 0.921906). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:22 - INFO - 3473208690 - Fold 3 VAE Epoch 8/150 | β: 0.112 | Train Loss: 0.9499 (MSE: 0.9318, KLD: 0.1615) | Val Loss: 0.9270 (MSE: 0.9101, KLD: 0.1505)\n",
      "2025-05-26 03:52:22 - INFO - 3473208690 - Validation metric improved (0.910105 --> 0.910105). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:23 - INFO - 3473208690 - Fold 3 VAE Epoch 9/150 | β: 0.128 | Train Loss: 0.9431 (MSE: 0.9249, KLD: 0.1416) | Val Loss: 0.9181 (MSE: 0.8995, KLD: 0.1448)\n",
      "2025-05-26 03:52:23 - INFO - 3473208690 - Validation metric improved (0.899519 --> 0.899519). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:24 - INFO - 3473208690 - Fold 3 VAE Epoch 10/150 | β: 0.144 | Train Loss: 0.9326 (MSE: 0.9154, KLD: 0.1198) | Val Loss: 0.9128 (MSE: 0.8973, KLD: 0.1075)\n",
      "2025-05-26 03:52:24 - INFO - 3473208690 - Validation metric improved (0.897324 --> 0.897324). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:24 - INFO - 3473208690 - Fold 3 VAE Epoch 11/150 | β: 0.160 | Train Loss: 0.9254 (MSE: 0.9081, KLD: 0.1083) | Val Loss: 0.9048 (MSE: 0.8886, KLD: 0.1015)\n",
      "2025-05-26 03:52:24 - INFO - 3473208690 - Validation metric improved (0.888603 --> 0.888603). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:25 - INFO - 3473208690 - Fold 3 VAE Epoch 12/150 | β: 0.176 | Train Loss: 0.9199 (MSE: 0.9034, KLD: 0.0939) | Val Loss: 0.9000 (MSE: 0.8816, KLD: 0.1045)\n",
      "2025-05-26 03:52:25 - INFO - 3473208690 - Validation metric improved (0.881603 --> 0.881603). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:26 - INFO - 3473208690 - Fold 3 VAE Epoch 13/150 | β: 0.192 | Train Loss: 0.9160 (MSE: 0.8986, KLD: 0.0908) | Val Loss: 0.8971 (MSE: 0.8773, KLD: 0.1032)\n",
      "2025-05-26 03:52:26 - INFO - 3473208690 - Validation metric improved (0.877337 --> 0.877337). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:27 - INFO - 3473208690 - Fold 3 VAE Epoch 14/150 | β: 0.208 | Train Loss: 0.9120 (MSE: 0.8931, KLD: 0.0907) | Val Loss: 0.8923 (MSE: 0.8785, KLD: 0.0664)\n",
      "2025-05-26 03:52:27 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.877337|Current: 0.878496)\n",
      "2025-05-26 03:52:28 - INFO - 3473208690 - Fold 3 VAE Epoch 15/150 | β: 0.224 | Train Loss: 0.9065 (MSE: 0.8890, KLD: 0.0781) | Val Loss: 0.8883 (MSE: 0.8673, KLD: 0.0938)\n",
      "2025-05-26 03:52:28 - INFO - 3473208690 - Validation metric improved (0.867274 --> 0.867274). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:29 - INFO - 3473208690 - Fold 3 VAE Epoch 16/150 | β: 0.240 | Train Loss: 0.9029 (MSE: 0.8844, KLD: 0.0770) | Val Loss: 0.8816 (MSE: 0.8638, KLD: 0.0744)\n",
      "2025-05-26 03:52:29 - INFO - 3473208690 - Validation metric improved (0.863755 --> 0.863755). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:29 - INFO - 3473208690 - Fold 3 VAE Epoch 17/150 | β: 0.256 | Train Loss: 0.8995 (MSE: 0.8798, KLD: 0.0769) | Val Loss: 0.8784 (MSE: 0.8624, KLD: 0.0625)\n",
      "2025-05-26 03:52:29 - INFO - 3473208690 - Validation metric improved (0.862422 --> 0.862422). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:30 - INFO - 3473208690 - Fold 3 VAE Epoch 18/150 | β: 0.272 | Train Loss: 0.8930 (MSE: 0.8747, KLD: 0.0676) | Val Loss: 0.8757 (MSE: 0.8540, KLD: 0.0800)\n",
      "2025-05-26 03:52:30 - INFO - 3473208690 - Validation metric improved (0.853956 --> 0.853956). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:31 - INFO - 3473208690 - Fold 3 VAE Epoch 19/150 | β: 0.288 | Train Loss: 0.8891 (MSE: 0.8687, KLD: 0.0706) | Val Loss: 0.8730 (MSE: 0.8559, KLD: 0.0594)\n",
      "2025-05-26 03:52:31 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.853956|Current: 0.855869)\n",
      "2025-05-26 03:52:32 - INFO - 3473208690 - Fold 3 VAE Epoch 20/150 | β: 0.304 | Train Loss: 0.8881 (MSE: 0.8679, KLD: 0.0664) | Val Loss: 0.8698 (MSE: 0.8448, KLD: 0.0822)\n",
      "2025-05-26 03:52:32 - INFO - 3473208690 - Validation metric improved (0.844798 --> 0.844798). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:33 - INFO - 3473208690 - Fold 3 VAE Epoch 21/150 | β: 0.320 | Train Loss: 0.8867 (MSE: 0.8632, KLD: 0.0734) | Val Loss: 0.8665 (MSE: 0.8410, KLD: 0.0798)\n",
      "2025-05-26 03:52:33 - INFO - 3473208690 - Validation metric improved (0.841003 --> 0.841003). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:34 - INFO - 3473208690 - Fold 3 VAE Epoch 22/150 | β: 0.336 | Train Loss: 0.8805 (MSE: 0.8573, KLD: 0.0691) | Val Loss: 0.8656 (MSE: 0.8482, KLD: 0.0516)\n",
      "2025-05-26 03:52:34 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.841003|Current: 0.848226)\n",
      "2025-05-26 03:52:34 - INFO - 3473208690 - Fold 3 VAE Epoch 23/150 | β: 0.352 | Train Loss: 0.8797 (MSE: 0.8571, KLD: 0.0642) | Val Loss: 0.8637 (MSE: 0.8454, KLD: 0.0519)\n",
      "2025-05-26 03:52:34 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.841003|Current: 0.845424)\n",
      "2025-05-26 03:52:35 - INFO - 3473208690 - Fold 3 VAE Epoch 24/150 | β: 0.368 | Train Loss: 0.8744 (MSE: 0.8508, KLD: 0.0641) | Val Loss: 0.8601 (MSE: 0.8395, KLD: 0.0559)\n",
      "2025-05-26 03:52:35 - INFO - 3473208690 - Validation metric improved (0.839543 --> 0.839543). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:37 - INFO - 3473208690 - Fold 3 VAE Epoch 25/150 | β: 0.384 | Train Loss: 0.8701 (MSE: 0.8456, KLD: 0.0638) | Val Loss: 0.8559 (MSE: 0.8349, KLD: 0.0547)\n",
      "2025-05-26 03:52:37 - INFO - 3473208690 - Validation metric improved (0.834904 --> 0.834904). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:39 - INFO - 3473208690 - Fold 3 VAE Epoch 26/150 | β: 0.400 | Train Loss: 0.8671 (MSE: 0.8439, KLD: 0.0580) | Val Loss: 0.8535 (MSE: 0.8288, KLD: 0.0617)\n",
      "2025-05-26 03:52:39 - INFO - 3473208690 - Validation metric improved (0.828770 --> 0.828770). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:42 - INFO - 3473208690 - Fold 3 VAE Epoch 27/150 | β: 0.416 | Train Loss: 0.8662 (MSE: 0.8406, KLD: 0.0617) | Val Loss: 0.8549 (MSE: 0.8281, KLD: 0.0646)\n",
      "2025-05-26 03:52:42 - INFO - 3473208690 - Validation metric improved (0.828063 --> 0.828063). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:44 - INFO - 3473208690 - Fold 3 VAE Epoch 28/150 | β: 0.432 | Train Loss: 0.8664 (MSE: 0.8402, KLD: 0.0605) | Val Loss: 0.8524 (MSE: 0.8251, KLD: 0.0633)\n",
      "2025-05-26 03:52:44 - INFO - 3473208690 - Validation metric improved (0.825073 --> 0.825073). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:46 - INFO - 3473208690 - Fold 3 VAE Epoch 29/150 | β: 0.448 | Train Loss: 0.8635 (MSE: 0.8368, KLD: 0.0595) | Val Loss: 0.8522 (MSE: 0.8282, KLD: 0.0538)\n",
      "2025-05-26 03:52:46 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.825073|Current: 0.828155)\n",
      "2025-05-26 03:52:47 - INFO - 3473208690 - Fold 3 VAE Epoch 30/150 | β: 0.464 | Train Loss: 0.8615 (MSE: 0.8345, KLD: 0.0583) | Val Loss: 0.8493 (MSE: 0.8250, KLD: 0.0524)\n",
      "2025-05-26 03:52:47 - INFO - 3473208690 - Validation metric improved (0.825034 --> 0.825034). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:49 - INFO - 3473208690 - Fold 3 VAE Epoch 31/150 | β: 0.480 | Train Loss: 0.8596 (MSE: 0.8330, KLD: 0.0554) | Val Loss: 0.8506 (MSE: 0.8287, KLD: 0.0456)\n",
      "2025-05-26 03:52:49 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.825034|Current: 0.828706)\n",
      "2025-05-26 03:52:50 - INFO - 3473208690 - Fold 3 VAE Epoch 32/150 | β: 0.496 | Train Loss: 0.8603 (MSE: 0.8324, KLD: 0.0563) | Val Loss: 0.8506 (MSE: 0.8227, KLD: 0.0562)\n",
      "2025-05-26 03:52:50 - INFO - 3473208690 - Validation metric improved (0.822706 --> 0.822706). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:52 - INFO - 3473208690 - Fold 3 VAE Epoch 33/150 | β: 0.512 | Train Loss: 0.8586 (MSE: 0.8314, KLD: 0.0531) | Val Loss: 0.8465 (MSE: 0.8232, KLD: 0.0456)\n",
      "2025-05-26 03:52:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.822706|Current: 0.823173)\n",
      "2025-05-26 03:52:53 - INFO - 3473208690 - Fold 3 VAE Epoch 34/150 | β: 0.528 | Train Loss: 0.8602 (MSE: 0.8331, KLD: 0.0513) | Val Loss: 0.8498 (MSE: 0.8229, KLD: 0.0508)\n",
      "2025-05-26 03:52:53 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.822706|Current: 0.822935)\n",
      "2025-05-26 03:52:53 - INFO - 3473208690 - Fold 3 VAE Epoch 35/150 | β: 0.544 | Train Loss: 0.8626 (MSE: 0.8334, KLD: 0.0537) | Val Loss: 0.8508 (MSE: 0.8235, KLD: 0.0501)\n",
      "2025-05-26 03:52:53 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.822706|Current: 0.823499)\n",
      "2025-05-26 03:52:54 - INFO - 3473208690 - Fold 3 VAE Epoch 36/150 | β: 0.560 | Train Loss: 0.8617 (MSE: 0.8323, KLD: 0.0525) | Val Loss: 0.8563 (MSE: 0.8289, KLD: 0.0489)\n",
      "2025-05-26 03:52:54 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.822706|Current: 0.828920)\n",
      "2025-05-26 03:52:55 - INFO - 3473208690 - Fold 3 VAE Epoch 37/150 | β: 0.576 | Train Loss: 0.8621 (MSE: 0.8323, KLD: 0.0517) | Val Loss: 0.8516 (MSE: 0.8235, KLD: 0.0488)\n",
      "2025-05-26 03:52:55 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.822706|Current: 0.823522)\n",
      "2025-05-26 03:52:55 - INFO - 3473208690 - Fold 3 VAE Epoch 38/150 | β: 0.592 | Train Loss: 0.8731 (MSE: 0.8328, KLD: 0.0681) | Val Loss: 0.8637 (MSE: 0.8422, KLD: 0.0363)\n",
      "2025-05-26 03:52:55 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.822706|Current: 0.842219)\n",
      "2025-05-26 03:52:56 - INFO - 3473208690 - Fold 3 VAE Epoch 39/150 | β: 0.608 | Train Loss: 0.8595 (MSE: 0.8233, KLD: 0.0594) | Val Loss: 0.8435 (MSE: 0.8115, KLD: 0.0526)\n",
      "2025-05-26 03:52:56 - INFO - 3473208690 - Validation metric improved (0.811548 --> 0.811548). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:52:58 - INFO - 3473208690 - Fold 3 VAE Epoch 40/150 | β: 0.624 | Train Loss: 0.8479 (MSE: 0.8116, KLD: 0.0582) | Val Loss: 0.8366 (MSE: 0.7971, KLD: 0.0632)\n",
      "2025-05-26 03:52:58 - INFO - 3473208690 - Validation metric improved (0.797117 --> 0.797117). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:00 - INFO - 3473208690 - Fold 3 VAE Epoch 41/150 | β: 0.640 | Train Loss: 0.8393 (MSE: 0.8047, KLD: 0.0541) | Val Loss: 0.8359 (MSE: 0.7965, KLD: 0.0615)\n",
      "2025-05-26 03:53:00 - INFO - 3473208690 - Validation metric improved (0.796539 --> 0.796539). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:01 - INFO - 3473208690 - Fold 3 VAE Epoch 42/150 | β: 0.656 | Train Loss: 0.8319 (MSE: 0.7969, KLD: 0.0534) | Val Loss: 0.8289 (MSE: 0.7936, KLD: 0.0538)\n",
      "2025-05-26 03:53:01 - INFO - 3473208690 - Validation metric improved (0.793583 --> 0.793583). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:02 - INFO - 3473208690 - Fold 3 VAE Epoch 43/150 | β: 0.672 | Train Loss: 0.8333 (MSE: 0.7969, KLD: 0.0542) | Val Loss: 0.8232 (MSE: 0.7886, KLD: 0.0516)\n",
      "2025-05-26 03:53:02 - INFO - 3473208690 - Validation metric improved (0.788567 --> 0.788567). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:03 - INFO - 3473208690 - Fold 3 VAE Epoch 44/150 | β: 0.688 | Train Loss: 0.8231 (MSE: 0.7891, KLD: 0.0495) | Val Loss: 0.8206 (MSE: 0.7847, KLD: 0.0523)\n",
      "2025-05-26 03:53:03 - INFO - 3473208690 - Validation metric improved (0.784665 --> 0.784665). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:04 - INFO - 3473208690 - Fold 3 VAE Epoch 45/150 | β: 0.704 | Train Loss: 0.8154 (MSE: 0.7831, KLD: 0.0459) | Val Loss: 0.8156 (MSE: 0.7742, KLD: 0.0589)\n",
      "2025-05-26 03:53:04 - INFO - 3473208690 - Validation metric improved (0.774162 --> 0.774162). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:05 - INFO - 3473208690 - Fold 3 VAE Epoch 46/150 | β: 0.720 | Train Loss: 0.8155 (MSE: 0.7785, KLD: 0.0513) | Val Loss: 0.8140 (MSE: 0.7856, KLD: 0.0395)\n",
      "2025-05-26 03:53:05 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.774162|Current: 0.785633)\n",
      "2025-05-26 03:53:06 - INFO - 3473208690 - Fold 3 VAE Epoch 47/150 | β: 0.736 | Train Loss: 0.8144 (MSE: 0.7817, KLD: 0.0444) | Val Loss: 0.8125 (MSE: 0.7737, KLD: 0.0527)\n",
      "2025-05-26 03:53:06 - INFO - 3473208690 - Validation metric improved (0.773691 --> 0.773691). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:06 - INFO - 3473208690 - Fold 3 VAE Epoch 48/150 | β: 0.752 | Train Loss: 0.8098 (MSE: 0.7735, KLD: 0.0483) | Val Loss: 0.8104 (MSE: 0.7815, KLD: 0.0384)\n",
      "2025-05-26 03:53:06 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.773691|Current: 0.781479)\n",
      "2025-05-26 03:53:07 - INFO - 3473208690 - Fold 3 VAE Epoch 49/150 | β: 0.768 | Train Loss: 0.8078 (MSE: 0.7754, KLD: 0.0422) | Val Loss: 0.8154 (MSE: 0.7847, KLD: 0.0400)\n",
      "2025-05-26 03:53:07 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.773691|Current: 0.784686)\n",
      "2025-05-26 03:53:08 - INFO - 3473208690 - Fold 3 VAE Epoch 50/150 | β: 0.784 | Train Loss: 0.8065 (MSE: 0.7698, KLD: 0.0468) | Val Loss: 0.8080 (MSE: 0.7825, KLD: 0.0325)\n",
      "2025-05-26 03:53:08 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.773691|Current: 0.782504)\n",
      "2025-05-26 03:53:08 - INFO - 3473208690 - Fold 3 VAE Epoch 51/150 | β: 0.800 | Train Loss: 0.8046 (MSE: 0.7722, KLD: 0.0405) | Val Loss: 0.8014 (MSE: 0.7678, KLD: 0.0420)\n",
      "2025-05-26 03:53:08 - INFO - 3473208690 - Validation metric improved (0.767829 --> 0.767829). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:09 - INFO - 3473208690 - Fold 3 VAE Epoch 52/150 | β: 0.800 | Train Loss: 0.8006 (MSE: 0.7651, KLD: 0.0444) | Val Loss: 0.8019 (MSE: 0.7678, KLD: 0.0427)\n",
      "2025-05-26 03:53:09 - INFO - 3473208690 - Validation metric improved (0.767764 --> 0.767764). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:10 - INFO - 3473208690 - Fold 3 VAE Epoch 53/150 | β: 0.800 | Train Loss: 0.8022 (MSE: 0.7667, KLD: 0.0443) | Val Loss: 0.7971 (MSE: 0.7648, KLD: 0.0404)\n",
      "2025-05-26 03:53:10 - INFO - 3473208690 - Validation metric improved (0.764791 --> 0.764791). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:11 - INFO - 3473208690 - Fold 3 VAE Epoch 54/150 | β: 0.800 | Train Loss: 0.7944 (MSE: 0.7640, KLD: 0.0379) | Val Loss: 0.8006 (MSE: 0.7682, KLD: 0.0405)\n",
      "2025-05-26 03:53:11 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.764791|Current: 0.768153)\n",
      "2025-05-26 03:53:12 - INFO - 3473208690 - Fold 3 VAE Epoch 55/150 | β: 0.800 | Train Loss: 0.7929 (MSE: 0.7609, KLD: 0.0401) | Val Loss: 0.7940 (MSE: 0.7585, KLD: 0.0444)\n",
      "2025-05-26 03:53:12 - INFO - 3473208690 - Validation metric improved (0.758467 --> 0.758467). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:14 - INFO - 3473208690 - Fold 3 VAE Epoch 56/150 | β: 0.800 | Train Loss: 0.7925 (MSE: 0.7599, KLD: 0.0407) | Val Loss: 0.7946 (MSE: 0.7589, KLD: 0.0446)\n",
      "2025-05-26 03:53:14 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.758467|Current: 0.758910)\n",
      "2025-05-26 03:53:15 - INFO - 3473208690 - Fold 3 VAE Epoch 57/150 | β: 0.800 | Train Loss: 0.7937 (MSE: 0.7620, KLD: 0.0396) | Val Loss: 0.8007 (MSE: 0.7612, KLD: 0.0493)\n",
      "2025-05-26 03:53:15 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.758467|Current: 0.761244)\n",
      "2025-05-26 03:53:16 - INFO - 3473208690 - Fold 3 VAE Epoch 58/150 | β: 0.800 | Train Loss: 0.7913 (MSE: 0.7580, KLD: 0.0417) | Val Loss: 0.7905 (MSE: 0.7579, KLD: 0.0407)\n",
      "2025-05-26 03:53:16 - INFO - 3473208690 - Validation metric improved (0.757895 --> 0.757895). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:18 - INFO - 3473208690 - Fold 3 VAE Epoch 59/150 | β: 0.800 | Train Loss: 0.7905 (MSE: 0.7576, KLD: 0.0412) | Val Loss: 0.7988 (MSE: 0.7590, KLD: 0.0498)\n",
      "2025-05-26 03:53:18 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.757895|Current: 0.759017)\n",
      "2025-05-26 03:53:19 - INFO - 3473208690 - Fold 3 VAE Epoch 60/150 | β: 0.800 | Train Loss: 0.7875 (MSE: 0.7557, KLD: 0.0398) | Val Loss: 0.7958 (MSE: 0.7655, KLD: 0.0378)\n",
      "2025-05-26 03:53:19 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.757895|Current: 0.765531)\n",
      "2025-05-26 03:53:19 - INFO - 3473208690 - Fold 3 VAE Epoch 61/150 | β: 0.800 | Train Loss: 0.7860 (MSE: 0.7535, KLD: 0.0407) | Val Loss: 0.7906 (MSE: 0.7619, KLD: 0.0359)\n",
      "2025-05-26 03:53:19 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.757895|Current: 0.761868)\n",
      "2025-05-26 03:53:20 - INFO - 3473208690 - Fold 3 VAE Epoch 62/150 | β: 0.800 | Train Loss: 0.7849 (MSE: 0.7546, KLD: 0.0379) | Val Loss: 0.7875 (MSE: 0.7614, KLD: 0.0326)\n",
      "2025-05-26 03:53:20 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.757895|Current: 0.761415)\n",
      "2025-05-26 03:53:21 - INFO - 3473208690 - Fold 3 VAE Epoch 63/150 | β: 0.800 | Train Loss: 0.7839 (MSE: 0.7542, KLD: 0.0371) | Val Loss: 0.7862 (MSE: 0.7604, KLD: 0.0323)\n",
      "2025-05-26 03:53:21 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.757895|Current: 0.760381)\n",
      "2025-05-26 03:53:21 - INFO - 3473208690 - Fold 3 VAE Epoch 64/150 | β: 0.800 | Train Loss: 0.7845 (MSE: 0.7531, KLD: 0.0393) | Val Loss: 0.7874 (MSE: 0.7622, KLD: 0.0315)\n",
      "2025-05-26 03:53:21 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.757895|Current: 0.762162)\n",
      "2025-05-26 03:53:22 - INFO - 3473208690 - Fold 3 VAE Epoch 65/150 | β: 0.800 | Train Loss: 0.7817 (MSE: 0.7517, KLD: 0.0375) | Val Loss: 0.7855 (MSE: 0.7565, KLD: 0.0362)\n",
      "2025-05-26 03:53:22 - INFO - 3473208690 - Validation metric improved (0.756523 --> 0.756523). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:25 - INFO - 3473208690 - Fold 3 VAE Epoch 66/150 | β: 0.800 | Train Loss: 0.7827 (MSE: 0.7548, KLD: 0.0349) | Val Loss: 0.7827 (MSE: 0.7555, KLD: 0.0340)\n",
      "2025-05-26 03:53:25 - INFO - 3473208690 - Validation metric improved (0.755478 --> 0.755478). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:27 - INFO - 3473208690 - Fold 3 VAE Epoch 67/150 | β: 0.800 | Train Loss: 0.7801 (MSE: 0.7493, KLD: 0.0384) | Val Loss: 0.7870 (MSE: 0.7590, KLD: 0.0350)\n",
      "2025-05-26 03:53:27 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.755478|Current: 0.758970)\n",
      "2025-05-26 03:53:28 - INFO - 3473208690 - Fold 3 VAE Epoch 68/150 | β: 0.800 | Train Loss: 0.7827 (MSE: 0.7536, KLD: 0.0364) | Val Loss: 0.7846 (MSE: 0.7562, KLD: 0.0354)\n",
      "2025-05-26 03:53:28 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.755478|Current: 0.756235)\n",
      "2025-05-26 03:53:28 - INFO - 3473208690 - Fold 3 VAE Epoch 69/150 | β: 0.800 | Train Loss: 0.7833 (MSE: 0.7519, KLD: 0.0393) | Val Loss: 0.7843 (MSE: 0.7552, KLD: 0.0363)\n",
      "2025-05-26 03:53:28 - INFO - 3473208690 - Validation metric improved (0.755232 --> 0.755232). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:31 - INFO - 3473208690 - Fold 3 VAE Epoch 70/150 | β: 0.800 | Train Loss: 0.7799 (MSE: 0.7502, KLD: 0.0371) | Val Loss: 0.7819 (MSE: 0.7548, KLD: 0.0339)\n",
      "2025-05-26 03:53:31 - INFO - 3473208690 - Validation metric improved (0.754771 --> 0.754771). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:33 - INFO - 3473208690 - Fold 3 VAE Epoch 71/150 | β: 0.800 | Train Loss: 0.7822 (MSE: 0.7527, KLD: 0.0369) | Val Loss: 0.7851 (MSE: 0.7576, KLD: 0.0343)\n",
      "2025-05-26 03:53:33 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.754771|Current: 0.757640)\n",
      "2025-05-26 03:53:34 - INFO - 3473208690 - Fold 3 VAE Epoch 72/150 | β: 0.800 | Train Loss: 0.7795 (MSE: 0.7499, KLD: 0.0370) | Val Loss: 0.7917 (MSE: 0.7641, KLD: 0.0344)\n",
      "2025-05-26 03:53:34 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.754771|Current: 0.764149)\n",
      "2025-05-26 03:53:35 - INFO - 3473208690 - Fold 3 VAE Epoch 73/150 | β: 0.800 | Train Loss: 0.7808 (MSE: 0.7512, KLD: 0.0370) | Val Loss: 0.7897 (MSE: 0.7620, KLD: 0.0347)\n",
      "2025-05-26 03:53:35 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.754771|Current: 0.761965)\n",
      "2025-05-26 03:53:35 - INFO - 3473208690 - Fold 3 VAE Epoch 74/150 | β: 0.800 | Train Loss: 0.7775 (MSE: 0.7478, KLD: 0.0371) | Val Loss: 0.7827 (MSE: 0.7551, KLD: 0.0346)\n",
      "2025-05-26 03:53:35 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.754771|Current: 0.755053)\n",
      "2025-05-26 03:53:36 - INFO - 3473208690 - Fold 3 VAE Epoch 75/150 | β: 0.800 | Train Loss: 0.7864 (MSE: 0.7567, KLD: 0.0372) | Val Loss: 0.7938 (MSE: 0.7501, KLD: 0.0546)\n",
      "2025-05-26 03:53:36 - INFO - 3473208690 - Validation metric improved (0.750128 --> 0.750128). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:38 - INFO - 3473208690 - Fold 3 VAE Epoch 76/150 | β: 0.800 | Train Loss: 0.7881 (MSE: 0.7506, KLD: 0.0468) | Val Loss: 0.7943 (MSE: 0.7592, KLD: 0.0438)\n",
      "2025-05-26 03:53:38 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.750128|Current: 0.759233)\n",
      "2025-05-26 03:53:39 - INFO - 3473208690 - Fold 3 VAE Epoch 77/150 | β: 0.800 | Train Loss: 0.7858 (MSE: 0.7478, KLD: 0.0474) | Val Loss: 0.7843 (MSE: 0.7478, KLD: 0.0457)\n",
      "2025-05-26 03:53:39 - INFO - 3473208690 - Validation metric improved (0.747756 --> 0.747756). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:40 - INFO - 3473208690 - Fold 3 VAE Epoch 78/150 | β: 0.800 | Train Loss: 0.7857 (MSE: 0.7524, KLD: 0.0416) | Val Loss: 0.7910 (MSE: 0.7576, KLD: 0.0417)\n",
      "2025-05-26 03:53:40 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.747756|Current: 0.757611)\n",
      "2025-05-26 03:53:40 - INFO - 3473208690 - Fold 3 VAE Epoch 79/150 | β: 0.800 | Train Loss: 0.7819 (MSE: 0.7434, KLD: 0.0481) | Val Loss: 0.7819 (MSE: 0.7482, KLD: 0.0421)\n",
      "2025-05-26 03:53:40 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.747756|Current: 0.748208)\n",
      "2025-05-26 03:53:41 - INFO - 3473208690 - Fold 3 VAE Epoch 80/150 | β: 0.800 | Train Loss: 0.7785 (MSE: 0.7456, KLD: 0.0411) | Val Loss: 0.7969 (MSE: 0.7715, KLD: 0.0317)\n",
      "2025-05-26 03:53:41 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.747756|Current: 0.771517)\n",
      "2025-05-26 03:53:42 - INFO - 3473208690 - Fold 3 VAE Epoch 81/150 | β: 0.800 | Train Loss: 0.7803 (MSE: 0.7459, KLD: 0.0429) | Val Loss: 0.7857 (MSE: 0.7459, KLD: 0.0499)\n",
      "2025-05-26 03:53:42 - INFO - 3473208690 - Validation metric improved (0.745855 --> 0.745855). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:43 - INFO - 3473208690 - Fold 3 VAE Epoch 82/150 | β: 0.800 | Train Loss: 0.7828 (MSE: 0.7459, KLD: 0.0461) | Val Loss: 0.7781 (MSE: 0.7424, KLD: 0.0446)\n",
      "2025-05-26 03:53:43 - INFO - 3473208690 - Validation metric improved (0.742431 --> 0.742431). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:43 - INFO - 3473208690 - Fold 3 VAE Epoch 83/150 | β: 0.800 | Train Loss: 0.7714 (MSE: 0.7373, KLD: 0.0426) | Val Loss: 0.7816 (MSE: 0.7575, KLD: 0.0301)\n",
      "2025-05-26 03:53:43 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.742431|Current: 0.757525)\n",
      "2025-05-26 03:53:44 - INFO - 3473208690 - Fold 3 VAE Epoch 84/150 | β: 0.800 | Train Loss: 0.7716 (MSE: 0.7433, KLD: 0.0354) | Val Loss: 0.7792 (MSE: 0.7440, KLD: 0.0439)\n",
      "2025-05-26 03:53:44 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.742431|Current: 0.744038)\n",
      "2025-05-26 03:53:45 - INFO - 3473208690 - Fold 3 VAE Epoch 85/150 | β: 0.800 | Train Loss: 0.7738 (MSE: 0.7385, KLD: 0.0442) | Val Loss: 0.7839 (MSE: 0.7461, KLD: 0.0472)\n",
      "2025-05-26 03:53:45 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.742431|Current: 0.746088)\n",
      "2025-05-26 03:53:45 - INFO - 3473208690 - Fold 3 VAE Epoch 86/150 | β: 0.800 | Train Loss: 0.7715 (MSE: 0.7378, KLD: 0.0420) | Val Loss: 0.7850 (MSE: 0.7551, KLD: 0.0374)\n",
      "2025-05-26 03:53:45 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.742431|Current: 0.755144)\n",
      "2025-05-26 03:53:46 - INFO - 3473208690 - Fold 3 VAE Epoch 87/150 | β: 0.800 | Train Loss: 0.7695 (MSE: 0.7380, KLD: 0.0394) | Val Loss: 0.7715 (MSE: 0.7408, KLD: 0.0384)\n",
      "2025-05-26 03:53:46 - INFO - 3473208690 - Validation metric improved (0.740785 --> 0.740785). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:47 - INFO - 3473208690 - Fold 3 VAE Epoch 88/150 | β: 0.800 | Train Loss: 0.7688 (MSE: 0.7349, KLD: 0.0424) | Val Loss: 0.7693 (MSE: 0.7433, KLD: 0.0324)\n",
      "2025-05-26 03:53:47 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.740785|Current: 0.743315)\n",
      "2025-05-26 03:53:48 - INFO - 3473208690 - Fold 3 VAE Epoch 89/150 | β: 0.800 | Train Loss: 0.7636 (MSE: 0.7352, KLD: 0.0354) | Val Loss: 0.7684 (MSE: 0.7423, KLD: 0.0326)\n",
      "2025-05-26 03:53:48 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.740785|Current: 0.742306)\n",
      "2025-05-26 03:53:48 - INFO - 3473208690 - Fold 3 VAE Epoch 90/150 | β: 0.800 | Train Loss: 0.7640 (MSE: 0.7334, KLD: 0.0382) | Val Loss: 0.7711 (MSE: 0.7452, KLD: 0.0323)\n",
      "2025-05-26 03:53:48 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.740785|Current: 0.745242)\n",
      "2025-05-26 03:53:49 - INFO - 3473208690 - Fold 3 VAE Epoch 91/150 | β: 0.800 | Train Loss: 0.7645 (MSE: 0.7346, KLD: 0.0374) | Val Loss: 0.7707 (MSE: 0.7351, KLD: 0.0445)\n",
      "2025-05-26 03:53:49 - INFO - 3473208690 - Validation metric improved (0.735106 --> 0.735106). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:50 - INFO - 3473208690 - Fold 3 VAE Epoch 92/150 | β: 0.800 | Train Loss: 0.7610 (MSE: 0.7292, KLD: 0.0397) | Val Loss: 0.7741 (MSE: 0.7410, KLD: 0.0414)\n",
      "2025-05-26 03:53:50 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.735106|Current: 0.740979)\n",
      "2025-05-26 03:53:51 - INFO - 3473208690 - Fold 3 VAE Epoch 93/150 | β: 0.800 | Train Loss: 0.7614 (MSE: 0.7293, KLD: 0.0401) | Val Loss: 0.7688 (MSE: 0.7390, KLD: 0.0372)\n",
      "2025-05-26 03:53:51 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.735106|Current: 0.739033)\n",
      "2025-05-26 03:53:51 - INFO - 3473208690 - Fold 3 VAE Epoch 94/150 | β: 0.800 | Train Loss: 0.7639 (MSE: 0.7332, KLD: 0.0383) | Val Loss: 0.7582 (MSE: 0.7281, KLD: 0.0376)\n",
      "2025-05-26 03:53:51 - INFO - 3473208690 - Validation metric improved (0.728064 --> 0.728064). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt ...\n",
      "2025-05-26 03:53:52 - INFO - 3473208690 - Fold 3 VAE Epoch 95/150 | β: 0.800 | Train Loss: 0.7623 (MSE: 0.7307, KLD: 0.0396) | Val Loss: 0.7625 (MSE: 0.7326, KLD: 0.0374)\n",
      "2025-05-26 03:53:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.728064|Current: 0.732566)\n",
      "2025-05-26 03:53:53 - INFO - 3473208690 - Fold 3 VAE Epoch 96/150 | β: 0.800 | Train Loss: 0.7597 (MSE: 0.7287, KLD: 0.0388) | Val Loss: 0.7616 (MSE: 0.7366, KLD: 0.0313)\n",
      "2025-05-26 03:53:53 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.728064|Current: 0.736551)\n",
      "2025-05-26 03:53:54 - INFO - 3473208690 - Fold 3 VAE Epoch 97/150 | β: 0.800 | Train Loss: 0.7594 (MSE: 0.7270, KLD: 0.0405) | Val Loss: 0.7649 (MSE: 0.7421, KLD: 0.0285)\n",
      "2025-05-26 03:53:54 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.728064|Current: 0.742065)\n",
      "2025-05-26 03:53:54 - INFO - 3473208690 - Fold 3 VAE Epoch 98/150 | β: 0.800 | Train Loss: 0.7581 (MSE: 0.7292, KLD: 0.0361) | Val Loss: 0.7631 (MSE: 0.7358, KLD: 0.0341)\n",
      "2025-05-26 03:53:54 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.728064|Current: 0.735772)\n",
      "2025-05-26 03:53:55 - INFO - 3473208690 - Fold 3 VAE Epoch 99/150 | β: 0.800 | Train Loss: 0.7582 (MSE: 0.7290, KLD: 0.0365) | Val Loss: 0.7612 (MSE: 0.7323, KLD: 0.0362)\n",
      "2025-05-26 03:53:55 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.728064|Current: 0.732260)\n",
      "2025-05-26 03:53:56 - INFO - 3473208690 - Fold 3 VAE Epoch 100/150 | β: 0.800 | Train Loss: 0.7557 (MSE: 0.7259, KLD: 0.0373) | Val Loss: 0.7618 (MSE: 0.7361, KLD: 0.0322)\n",
      "2025-05-26 03:53:56 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.728064|Current: 0.736083)\n",
      "2025-05-26 03:53:56 - INFO - 3473208690 - Fold 3 VAE Epoch 101/150 | β: 0.800 | Train Loss: 0.7541 (MSE: 0.7260, KLD: 0.0351) | Val Loss: 0.7665 (MSE: 0.7401, KLD: 0.0330)\n",
      "2025-05-26 03:53:56 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.728064|Current: 0.740111)\n",
      "2025-05-26 03:53:57 - INFO - 3473208690 - Fold 3 VAE Epoch 102/150 | β: 0.800 | Train Loss: 0.7554 (MSE: 0.7269, KLD: 0.0357) | Val Loss: 0.7588 (MSE: 0.7352, KLD: 0.0296)\n",
      "2025-05-26 03:53:57 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.728064|Current: 0.735161)\n",
      "2025-05-26 03:53:58 - INFO - 3473208690 - Fold 3 VAE Epoch 103/150 | β: 0.800 | Train Loss: 0.7602 (MSE: 0.7314, KLD: 0.0360) | Val Loss: 0.7614 (MSE: 0.7317, KLD: 0.0370)\n",
      "2025-05-26 03:53:58 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.728064|Current: 0.731718)\n",
      "2025-05-26 03:53:59 - INFO - 3473208690 - Fold 3 VAE Epoch 104/150 | β: 0.800 | Train Loss: 0.7541 (MSE: 0.7255, KLD: 0.0358) | Val Loss: 0.7559 (MSE: 0.7329, KLD: 0.0287)\n",
      "2025-05-26 03:53:59 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.728064|Current: 0.732900)\n",
      "2025-05-26 03:53:59 - INFO - 3473208690 - Fold 3 VAE Epoch 105/150 | β: 0.800 | Train Loss: 0.7571 (MSE: 0.7291, KLD: 0.0350) | Val Loss: 0.7683 (MSE: 0.7390, KLD: 0.0366)\n",
      "2025-05-26 03:53:59 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.728064|Current: 0.739008)\n",
      "2025-05-26 03:54:00 - INFO - 3473208690 - Fold 3 VAE Epoch 106/150 | β: 0.800 | Train Loss: 0.7565 (MSE: 0.7250, KLD: 0.0394) | Val Loss: 0.7590 (MSE: 0.7304, KLD: 0.0357)\n",
      "2025-05-26 03:54:00 - INFO - 3473208690 - EarlyStopping counter: 12 out of 15 (Best: 0.728064|Current: 0.730426)\n",
      "2025-05-26 03:54:01 - INFO - 3473208690 - Fold 3 VAE Epoch 107/150 | β: 0.800 | Train Loss: 0.7534 (MSE: 0.7242, KLD: 0.0365) | Val Loss: 0.7605 (MSE: 0.7354, KLD: 0.0314)\n",
      "2025-05-26 03:54:01 - INFO - 3473208690 - EarlyStopping counter: 13 out of 15 (Best: 0.728064|Current: 0.735414)\n",
      "2025-05-26 03:54:01 - INFO - 3473208690 - Fold 3 VAE Epoch 108/150 | β: 0.800 | Train Loss: 0.7540 (MSE: 0.7273, KLD: 0.0334) | Val Loss: 0.7607 (MSE: 0.7357, KLD: 0.0312)\n",
      "2025-05-26 03:54:01 - INFO - 3473208690 - EarlyStopping counter: 14 out of 15 (Best: 0.728064|Current: 0.735670)\n",
      "2025-05-26 03:54:02 - INFO - 3473208690 - Fold 3 VAE Epoch 109/150 | β: 0.800 | Train Loss: 0.7558 (MSE: 0.7280, KLD: 0.0347) | Val Loss: 0.7593 (MSE: 0.7329, KLD: 0.0330)\n",
      "2025-05-26 03:54:02 - INFO - 3473208690 - EarlyStopping counter: 15 out of 15 (Best: 0.728064|Current: 0.732910)\n",
      "2025-05-26 03:54:02 - INFO - 3473208690 - Early stopping VAE training.\n",
      "2025-05-26 03:54:02 - INFO - 3473208690 - Loaded best VAE model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_vae_model.pt\n",
      "2025-05-26 03:54:02 - INFO - 3473208690 - --- Extracting Latent Features (mu only) for Train, Val, Test ---\n",
      "2025-05-26 03:54:03 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_2/fold_2_preprocessed_data.pt for test split.\n",
      "2025-05-26 03:54:03 - WARNING - 3473208690 - Test split keys not found in preprocessed_connectomes_for_dl/fold_2/fold_2_preprocessed_data.pt. Test set will be empty.\n",
      "2025-05-26 03:54:03 - INFO - 3473208690 - Loaded 0 samples for test split.\n",
      "2025-05-26 03:54:03 - WARNING - 3473208690 - Fold 3: Test dataset is empty. Skipping test set evaluation for this fold.\n",
      "2025-05-26 03:54:03 - INFO - 3473208690 - --- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\n",
      "2025-05-26 03:54:03 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha: [1.0352112  0.96710527]\n",
      "2025-05-26 03:54:03 - INFO - 3473208690 - Validation metric improved (0.491228 --> 0.491228). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:54:04 - INFO - 3473208690 - Validation metric improved (0.603801 --> 0.603801). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:54:04 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.603801|Current: 0.583333)\n",
      "2025-05-26 03:54:05 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.603801|Current: 0.554094)\n",
      "2025-05-26 03:54:05 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.603801|Current: 0.562865)\n",
      "2025-05-26 03:54:06 - INFO - 3473208690 - EarlyStopping counter: 4 out of 10 (Best: 0.603801|Current: 0.570175)\n",
      "2025-05-26 03:54:06 - INFO - 3473208690 - EarlyStopping counter: 5 out of 10 (Best: 0.603801|Current: 0.567251)\n",
      "2025-05-26 03:54:07 - INFO - 3473208690 - EarlyStopping counter: 6 out of 10 (Best: 0.603801|Current: 0.558480)\n",
      "2025-05-26 03:54:07 - INFO - 3473208690 - EarlyStopping counter: 7 out of 10 (Best: 0.603801|Current: 0.573099)\n",
      "2025-05-26 03:54:08 - INFO - 3473208690 - EarlyStopping counter: 8 out of 10 (Best: 0.603801|Current: 0.564327)\n",
      "2025-05-26 03:54:08 - INFO - 3473208690 - EarlyStopping counter: 9 out of 10 (Best: 0.603801|Current: 0.548246)\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - EarlyStopping counter: 10 out of 10 (Best: 0.603801|Current: 0.543860)\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - Early stopping initial classifier training.\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - Loaded best initial classifier model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/best_initial_classifier_model.pt.\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - Fold 3 Initial Best Classifier Val Metrics: Acc: 0.4865, AUC: 0.6038, F1: 0.2963\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - --- Classifier Re-training Phase (CN vs AD) on Train+Val ---\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha for retraining: [1.0337079 0.9684211]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:54:09 - INFO - 3473208690 - Re-training classifier on combined train+val data for 30 epochs.\n",
      "2025-05-26 03:54:10 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 5/30 | Train Loss: 0.2326, Acc: 0.4620\n",
      "2025-05-26 03:54:12 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 10/30 | Train Loss: 0.2217, Acc: 0.5163\n",
      "2025-05-26 03:54:13 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 15/30 | Train Loss: 0.1945, Acc: 0.5489\n",
      "2025-05-26 03:54:14 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 20/30 | Train Loss: 0.1787, Acc: 0.6250\n",
      "2025-05-26 03:54:16 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 25/30 | Train Loss: 0.1794, Acc: 0.5870\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Fold 3 CLF Re-train Epoch 30/30 | Train Loss: 0.1707, Acc: 0.6250\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Saved final classifier model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_2/final_classifier_model.pt\n",
      "2025-05-26 03:54:17 - WARNING - 3473208690 - Fold 3: Test data latent features are empty. Skipping test set evaluation.\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - --- Processing Fold 4/51 ---\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_3/fold_3_preprocessed_data.pt for train split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Loaded 282 samples for train split.\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_3/fold_3_preprocessed_data.pt for val split.\n",
      "2025-05-26 03:54:17 - INFO - 3473208690 - Loaded 70 samples for val split.\n",
      "2025-05-26 03:54:18 - INFO - 3473208690 - Fold 4 VAE Epoch 1/150 | β: 0.000 | Train Loss: 1.2219 (MSE: 1.2219, KLD: 2.1266) | Val Loss: 1.1193 (MSE: 1.1193, KLD: 6.2235)\n",
      "2025-05-26 03:54:18 - INFO - 3473208690 - Validation metric improved (1.119331 --> 1.119331). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:19 - INFO - 3473208690 - Fold 4 VAE Epoch 2/150 | β: 0.016 | Train Loss: 1.1216 (MSE: 1.0625, KLD: 3.6928) | Val Loss: 1.0730 (MSE: 1.0622, KLD: 0.6799)\n",
      "2025-05-26 03:54:19 - INFO - 3473208690 - Validation metric improved (1.062157 --> 1.062157). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:20 - INFO - 3473208690 - Fold 4 VAE Epoch 3/150 | β: 0.032 | Train Loss: 1.0488 (MSE: 1.0287, KLD: 0.6280) | Val Loss: 1.0403 (MSE: 1.0163, KLD: 0.7521)\n",
      "2025-05-26 03:54:20 - INFO - 3473208690 - Validation metric improved (1.016272 --> 1.016272). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:21 - INFO - 3473208690 - Fold 4 VAE Epoch 4/150 | β: 0.048 | Train Loss: 1.0198 (MSE: 0.9965, KLD: 0.4847) | Val Loss: 1.0212 (MSE: 1.0003, KLD: 0.4346)\n",
      "2025-05-26 03:54:21 - INFO - 3473208690 - Validation metric improved (1.000299 --> 1.000299). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:22 - INFO - 3473208690 - Fold 4 VAE Epoch 5/150 | β: 0.064 | Train Loss: 1.0014 (MSE: 0.9801, KLD: 0.3325) | Val Loss: 1.0053 (MSE: 0.9839, KLD: 0.3339)\n",
      "2025-05-26 03:54:22 - INFO - 3473208690 - Validation metric improved (0.983909 --> 0.983909). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:23 - INFO - 3473208690 - Fold 4 VAE Epoch 6/150 | β: 0.080 | Train Loss: 0.9874 (MSE: 0.9673, KLD: 0.2521) | Val Loss: 0.9913 (MSE: 0.9728, KLD: 0.2320)\n",
      "2025-05-26 03:54:23 - INFO - 3473208690 - Validation metric improved (0.972783 --> 0.972783). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:24 - INFO - 3473208690 - Fold 4 VAE Epoch 7/150 | β: 0.096 | Train Loss: 0.9742 (MSE: 0.9552, KLD: 0.1985) | Val Loss: 0.9791 (MSE: 0.9632, KLD: 0.1655)\n",
      "2025-05-26 03:54:24 - INFO - 3473208690 - Validation metric improved (0.963206 --> 0.963206). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:24 - INFO - 3473208690 - Fold 4 VAE Epoch 8/150 | β: 0.112 | Train Loss: 0.9618 (MSE: 0.9441, KLD: 0.1574) | Val Loss: 0.9686 (MSE: 0.9534, KLD: 0.1361)\n",
      "2025-05-26 03:54:24 - INFO - 3473208690 - Validation metric improved (0.953353 --> 0.953353). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:25 - INFO - 3473208690 - Fold 4 VAE Epoch 9/150 | β: 0.128 | Train Loss: 0.9537 (MSE: 0.9365, KLD: 0.1346) | Val Loss: 0.9593 (MSE: 0.9419, KLD: 0.1356)\n",
      "2025-05-26 03:54:25 - INFO - 3473208690 - Validation metric improved (0.941928 --> 0.941928). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:26 - INFO - 3473208690 - Fold 4 VAE Epoch 10/150 | β: 0.144 | Train Loss: 0.9423 (MSE: 0.9250, KLD: 0.1202) | Val Loss: 0.9506 (MSE: 0.9359, KLD: 0.1025)\n",
      "2025-05-26 03:54:26 - INFO - 3473208690 - Validation metric improved (0.935880 --> 0.935880). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:27 - INFO - 3473208690 - Fold 4 VAE Epoch 11/150 | β: 0.160 | Train Loss: 0.9337 (MSE: 0.9166, KLD: 0.1064) | Val Loss: 0.9433 (MSE: 0.9282, KLD: 0.0944)\n",
      "2025-05-26 03:54:27 - INFO - 3473208690 - Validation metric improved (0.928155 --> 0.928155). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:28 - INFO - 3473208690 - Fold 4 VAE Epoch 12/150 | β: 0.176 | Train Loss: 0.9276 (MSE: 0.9106, KLD: 0.0966) | Val Loss: 0.9347 (MSE: 0.9187, KLD: 0.0907)\n",
      "2025-05-26 03:54:28 - INFO - 3473208690 - Validation metric improved (0.918683 --> 0.918683). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:29 - INFO - 3473208690 - Fold 4 VAE Epoch 13/150 | β: 0.192 | Train Loss: 0.9186 (MSE: 0.9011, KLD: 0.0910) | Val Loss: 0.9289 (MSE: 0.9130, KLD: 0.0829)\n",
      "2025-05-26 03:54:29 - INFO - 3473208690 - Validation metric improved (0.913008 --> 0.913008). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:30 - INFO - 3473208690 - Fold 4 VAE Epoch 14/150 | β: 0.208 | Train Loss: 0.9117 (MSE: 0.8933, KLD: 0.0885) | Val Loss: 0.9237 (MSE: 0.9057, KLD: 0.0865)\n",
      "2025-05-26 03:54:30 - INFO - 3473208690 - Validation metric improved (0.905666 --> 0.905666). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:31 - INFO - 3473208690 - Fold 4 VAE Epoch 15/150 | β: 0.224 | Train Loss: 0.9027 (MSE: 0.8826, KLD: 0.0899) | Val Loss: 0.9157 (MSE: 0.8958, KLD: 0.0889)\n",
      "2025-05-26 03:54:31 - INFO - 3473208690 - Validation metric improved (0.895795 --> 0.895795). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:32 - INFO - 3473208690 - Fold 4 VAE Epoch 16/150 | β: 0.240 | Train Loss: 0.8951 (MSE: 0.8739, KLD: 0.0880) | Val Loss: 0.9086 (MSE: 0.8869, KLD: 0.0907)\n",
      "2025-05-26 03:54:32 - INFO - 3473208690 - Validation metric improved (0.886882 --> 0.886882). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:32 - INFO - 3473208690 - Fold 4 VAE Epoch 17/150 | β: 0.256 | Train Loss: 0.8870 (MSE: 0.8649, KLD: 0.0865) | Val Loss: 0.8998 (MSE: 0.8770, KLD: 0.0891)\n",
      "2025-05-26 03:54:32 - INFO - 3473208690 - Validation metric improved (0.876995 --> 0.876995). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:33 - INFO - 3473208690 - Fold 4 VAE Epoch 18/150 | β: 0.272 | Train Loss: 0.8783 (MSE: 0.8550, KLD: 0.0858) | Val Loss: 0.8903 (MSE: 0.8710, KLD: 0.0708)\n",
      "2025-05-26 03:54:33 - INFO - 3473208690 - Validation metric improved (0.871003 --> 0.871003). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:34 - INFO - 3473208690 - Fold 4 VAE Epoch 19/150 | β: 0.288 | Train Loss: 0.8695 (MSE: 0.8450, KLD: 0.0850) | Val Loss: 0.8842 (MSE: 0.8641, KLD: 0.0698)\n",
      "2025-05-26 03:54:34 - INFO - 3473208690 - Validation metric improved (0.864125 --> 0.864125). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:35 - INFO - 3473208690 - Fold 4 VAE Epoch 20/150 | β: 0.304 | Train Loss: 0.8637 (MSE: 0.8410, KLD: 0.0745) | Val Loss: 0.8789 (MSE: 0.8556, KLD: 0.0766)\n",
      "2025-05-26 03:54:35 - INFO - 3473208690 - Validation metric improved (0.855641 --> 0.855641). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:36 - INFO - 3473208690 - Fold 4 VAE Epoch 21/150 | β: 0.320 | Train Loss: 0.8601 (MSE: 0.8344, KLD: 0.0800) | Val Loss: 0.8762 (MSE: 0.8528, KLD: 0.0730)\n",
      "2025-05-26 03:54:36 - INFO - 3473208690 - Validation metric improved (0.852786 --> 0.852786). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:37 - INFO - 3473208690 - Fold 4 VAE Epoch 22/150 | β: 0.336 | Train Loss: 0.8542 (MSE: 0.8292, KLD: 0.0743) | Val Loss: 0.8763 (MSE: 0.8552, KLD: 0.0630)\n",
      "2025-05-26 03:54:37 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.852786|Current: 0.855161)\n",
      "2025-05-26 03:54:38 - INFO - 3473208690 - Fold 4 VAE Epoch 23/150 | β: 0.352 | Train Loss: 0.8520 (MSE: 0.8263, KLD: 0.0729) | Val Loss: 0.8691 (MSE: 0.8424, KLD: 0.0760)\n",
      "2025-05-26 03:54:38 - INFO - 3473208690 - Validation metric improved (0.842352 --> 0.842352). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:40 - INFO - 3473208690 - Fold 4 VAE Epoch 24/150 | β: 0.368 | Train Loss: 0.8505 (MSE: 0.8231, KLD: 0.0745) | Val Loss: 0.8750 (MSE: 0.8446, KLD: 0.0829)\n",
      "2025-05-26 03:54:40 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.842352|Current: 0.844550)\n",
      "2025-05-26 03:54:41 - INFO - 3473208690 - Fold 4 VAE Epoch 25/150 | β: 0.384 | Train Loss: 0.8490 (MSE: 0.8215, KLD: 0.0717) | Val Loss: 0.8677 (MSE: 0.8358, KLD: 0.0832)\n",
      "2025-05-26 03:54:41 - INFO - 3473208690 - Validation metric improved (0.835766 --> 0.835766). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:43 - INFO - 3473208690 - Fold 4 VAE Epoch 26/150 | β: 0.400 | Train Loss: 0.8450 (MSE: 0.8171, KLD: 0.0697) | Val Loss: 0.8650 (MSE: 0.8360, KLD: 0.0726)\n",
      "2025-05-26 03:54:43 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.835766|Current: 0.835986)\n",
      "2025-05-26 03:54:44 - INFO - 3473208690 - Fold 4 VAE Epoch 27/150 | β: 0.416 | Train Loss: 0.8437 (MSE: 0.8173, KLD: 0.0636) | Val Loss: 0.8628 (MSE: 0.8346, KLD: 0.0677)\n",
      "2025-05-26 03:54:44 - INFO - 3473208690 - Validation metric improved (0.834610 --> 0.834610). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:47 - INFO - 3473208690 - Fold 4 VAE Epoch 28/150 | β: 0.432 | Train Loss: 0.8408 (MSE: 0.8144, KLD: 0.0611) | Val Loss: 0.8639 (MSE: 0.8382, KLD: 0.0594)\n",
      "2025-05-26 03:54:47 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.834610|Current: 0.838223)\n",
      "2025-05-26 03:54:47 - INFO - 3473208690 - Fold 4 VAE Epoch 29/150 | β: 0.448 | Train Loss: 0.8423 (MSE: 0.8146, KLD: 0.0620) | Val Loss: 0.8622 (MSE: 0.8382, KLD: 0.0535)\n",
      "2025-05-26 03:54:47 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.834610|Current: 0.838209)\n",
      "2025-05-26 03:54:48 - INFO - 3473208690 - Fold 4 VAE Epoch 30/150 | β: 0.464 | Train Loss: 0.8420 (MSE: 0.8140, KLD: 0.0602) | Val Loss: 0.8641 (MSE: 0.8382, KLD: 0.0559)\n",
      "2025-05-26 03:54:48 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.834610|Current: 0.838167)\n",
      "2025-05-26 03:54:49 - INFO - 3473208690 - Fold 4 VAE Epoch 31/150 | β: 0.480 | Train Loss: 0.8429 (MSE: 0.8150, KLD: 0.0582) | Val Loss: 0.8618 (MSE: 0.8339, KLD: 0.0581)\n",
      "2025-05-26 03:54:49 - INFO - 3473208690 - Validation metric improved (0.833937 --> 0.833937). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:51 - INFO - 3473208690 - Fold 4 VAE Epoch 32/150 | β: 0.496 | Train Loss: 0.8410 (MSE: 0.8123, KLD: 0.0578) | Val Loss: 0.8582 (MSE: 0.8323, KLD: 0.0521)\n",
      "2025-05-26 03:54:51 - INFO - 3473208690 - Validation metric improved (0.832343 --> 0.832343). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:54:54 - INFO - 3473208690 - Fold 4 VAE Epoch 33/150 | β: 0.512 | Train Loss: 0.8410 (MSE: 0.8125, KLD: 0.0556) | Val Loss: 0.8623 (MSE: 0.8354, KLD: 0.0525)\n",
      "2025-05-26 03:54:54 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.832343|Current: 0.835400)\n",
      "2025-05-26 03:54:54 - INFO - 3473208690 - Fold 4 VAE Epoch 34/150 | β: 0.528 | Train Loss: 0.8447 (MSE: 0.8150, KLD: 0.0561) | Val Loss: 0.8612 (MSE: 0.8334, KLD: 0.0528)\n",
      "2025-05-26 03:54:54 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.832343|Current: 0.833355)\n",
      "2025-05-26 03:54:55 - INFO - 3473208690 - Fold 4 VAE Epoch 35/150 | β: 0.544 | Train Loss: 0.8427 (MSE: 0.8132, KLD: 0.0543) | Val Loss: 0.8618 (MSE: 0.8346, KLD: 0.0500)\n",
      "2025-05-26 03:54:55 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.832343|Current: 0.834606)\n",
      "2025-05-26 03:54:56 - INFO - 3473208690 - Fold 4 VAE Epoch 36/150 | β: 0.560 | Train Loss: 0.8431 (MSE: 0.8134, KLD: 0.0530) | Val Loss: 0.8637 (MSE: 0.8357, KLD: 0.0500)\n",
      "2025-05-26 03:54:56 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.832343|Current: 0.835676)\n",
      "2025-05-26 03:54:56 - INFO - 3473208690 - Fold 4 VAE Epoch 37/150 | β: 0.576 | Train Loss: 0.8455 (MSE: 0.8149, KLD: 0.0532) | Val Loss: 0.8639 (MSE: 0.8351, KLD: 0.0501)\n",
      "2025-05-26 03:54:56 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.832343|Current: 0.835076)\n",
      "2025-05-26 03:54:57 - INFO - 3473208690 - Fold 4 VAE Epoch 38/150 | β: 0.592 | Train Loss: 0.8540 (MSE: 0.8188, KLD: 0.0593) | Val Loss: 0.8690 (MSE: 0.8429, KLD: 0.0440)\n",
      "2025-05-26 03:54:57 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.832343|Current: 0.842933)\n",
      "2025-05-26 03:54:58 - INFO - 3473208690 - Fold 4 VAE Epoch 39/150 | β: 0.608 | Train Loss: 0.8494 (MSE: 0.8093, KLD: 0.0659) | Val Loss: 0.8762 (MSE: 0.8434, KLD: 0.0540)\n",
      "2025-05-26 03:54:58 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.832343|Current: 0.843353)\n",
      "2025-05-26 03:54:58 - INFO - 3473208690 - Fold 4 VAE Epoch 40/150 | β: 0.624 | Train Loss: 0.8508 (MSE: 0.8089, KLD: 0.0671) | Val Loss: 0.8570 (MSE: 0.8295, KLD: 0.0441)\n",
      "2025-05-26 03:54:58 - INFO - 3473208690 - Validation metric improved (0.829519 --> 0.829519). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:01 - INFO - 3473208690 - Fold 4 VAE Epoch 41/150 | β: 0.640 | Train Loss: 0.8440 (MSE: 0.8013, KLD: 0.0666) | Val Loss: 0.8534 (MSE: 0.8136, KLD: 0.0622)\n",
      "2025-05-26 03:55:01 - INFO - 3473208690 - Validation metric improved (0.813562 --> 0.813562). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:03 - INFO - 3473208690 - Fold 4 VAE Epoch 42/150 | β: 0.656 | Train Loss: 0.8308 (MSE: 0.7953, KLD: 0.0541) | Val Loss: 0.8430 (MSE: 0.8122, KLD: 0.0470)\n",
      "2025-05-26 03:55:03 - INFO - 3473208690 - Validation metric improved (0.812182 --> 0.812182). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:04 - INFO - 3473208690 - Fold 4 VAE Epoch 43/150 | β: 0.672 | Train Loss: 0.8244 (MSE: 0.7920, KLD: 0.0481) | Val Loss: 0.8447 (MSE: 0.8027, KLD: 0.0624)\n",
      "2025-05-26 03:55:04 - INFO - 3473208690 - Validation metric improved (0.802745 --> 0.802745). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:05 - INFO - 3473208690 - Fold 4 VAE Epoch 44/150 | β: 0.688 | Train Loss: 0.8234 (MSE: 0.7864, KLD: 0.0537) | Val Loss: 0.8369 (MSE: 0.8038, KLD: 0.0482)\n",
      "2025-05-26 03:55:05 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.802745|Current: 0.803807)\n",
      "2025-05-26 03:55:06 - INFO - 3473208690 - Fold 4 VAE Epoch 45/150 | β: 0.704 | Train Loss: 0.8172 (MSE: 0.7826, KLD: 0.0492) | Val Loss: 0.8398 (MSE: 0.8110, KLD: 0.0408)\n",
      "2025-05-26 03:55:06 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.802745|Current: 0.811021)\n",
      "2025-05-26 03:55:07 - INFO - 3473208690 - Fold 4 VAE Epoch 46/150 | β: 0.720 | Train Loss: 0.8159 (MSE: 0.7829, KLD: 0.0459) | Val Loss: 0.8326 (MSE: 0.7973, KLD: 0.0491)\n",
      "2025-05-26 03:55:07 - INFO - 3473208690 - Validation metric improved (0.797268 --> 0.797268). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:08 - INFO - 3473208690 - Fold 4 VAE Epoch 47/150 | β: 0.736 | Train Loss: 0.8130 (MSE: 0.7779, KLD: 0.0477) | Val Loss: 0.8259 (MSE: 0.7950, KLD: 0.0421)\n",
      "2025-05-26 03:55:08 - INFO - 3473208690 - Validation metric improved (0.794951 --> 0.794951). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:09 - INFO - 3473208690 - Fold 4 VAE Epoch 48/150 | β: 0.752 | Train Loss: 0.8088 (MSE: 0.7742, KLD: 0.0460) | Val Loss: 0.8272 (MSE: 0.7917, KLD: 0.0473)\n",
      "2025-05-26 03:55:09 - INFO - 3473208690 - Validation metric improved (0.791673 --> 0.791673). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:09 - INFO - 3473208690 - Fold 4 VAE Epoch 49/150 | β: 0.768 | Train Loss: 0.8033 (MSE: 0.7710, KLD: 0.0419) | Val Loss: 0.8248 (MSE: 0.7897, KLD: 0.0457)\n",
      "2025-05-26 03:55:09 - INFO - 3473208690 - Validation metric improved (0.789663 --> 0.789663). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:10 - INFO - 3473208690 - Fold 4 VAE Epoch 50/150 | β: 0.784 | Train Loss: 0.8060 (MSE: 0.7711, KLD: 0.0445) | Val Loss: 0.8294 (MSE: 0.8001, KLD: 0.0374)\n",
      "2025-05-26 03:55:10 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.789663|Current: 0.800086)\n",
      "2025-05-26 03:55:11 - INFO - 3473208690 - Fold 4 VAE Epoch 51/150 | β: 0.800 | Train Loss: 0.8026 (MSE: 0.7668, KLD: 0.0448) | Val Loss: 0.8231 (MSE: 0.7864, KLD: 0.0459)\n",
      "2025-05-26 03:55:11 - INFO - 3473208690 - Validation metric improved (0.786438 --> 0.786438). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:12 - INFO - 3473208690 - Fold 4 VAE Epoch 52/150 | β: 0.800 | Train Loss: 0.8030 (MSE: 0.7672, KLD: 0.0447) | Val Loss: 0.8243 (MSE: 0.7957, KLD: 0.0357)\n",
      "2025-05-26 03:55:12 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.786438|Current: 0.795749)\n",
      "2025-05-26 03:55:13 - INFO - 3473208690 - Fold 4 VAE Epoch 53/150 | β: 0.800 | Train Loss: 0.8014 (MSE: 0.7660, KLD: 0.0442) | Val Loss: 0.8178 (MSE: 0.7895, KLD: 0.0354)\n",
      "2025-05-26 03:55:13 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.786438|Current: 0.789468)\n",
      "2025-05-26 03:55:13 - INFO - 3473208690 - Fold 4 VAE Epoch 54/150 | β: 0.800 | Train Loss: 0.7947 (MSE: 0.7626, KLD: 0.0402) | Val Loss: 0.8159 (MSE: 0.7883, KLD: 0.0345)\n",
      "2025-05-26 03:55:13 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.786438|Current: 0.788326)\n",
      "2025-05-26 03:55:14 - INFO - 3473208690 - Fold 4 VAE Epoch 55/150 | β: 0.800 | Train Loss: 0.7953 (MSE: 0.7632, KLD: 0.0400) | Val Loss: 0.8177 (MSE: 0.7874, KLD: 0.0379)\n",
      "2025-05-26 03:55:14 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.786438|Current: 0.787409)\n",
      "2025-05-26 03:55:15 - INFO - 3473208690 - Fold 4 VAE Epoch 56/150 | β: 0.800 | Train Loss: 0.7906 (MSE: 0.7566, KLD: 0.0425) | Val Loss: 0.8081 (MSE: 0.7783, KLD: 0.0373)\n",
      "2025-05-26 03:55:15 - INFO - 3473208690 - Validation metric improved (0.778302 --> 0.778302). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:16 - INFO - 3473208690 - Fold 4 VAE Epoch 57/150 | β: 0.800 | Train Loss: 0.7917 (MSE: 0.7603, KLD: 0.0392) | Val Loss: 0.8086 (MSE: 0.7754, KLD: 0.0416)\n",
      "2025-05-26 03:55:16 - INFO - 3473208690 - Validation metric improved (0.775351 --> 0.775351). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:17 - INFO - 3473208690 - Fold 4 VAE Epoch 58/150 | β: 0.800 | Train Loss: 0.7903 (MSE: 0.7578, KLD: 0.0407) | Val Loss: 0.8090 (MSE: 0.7824, KLD: 0.0332)\n",
      "2025-05-26 03:55:17 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.775351|Current: 0.782404)\n",
      "2025-05-26 03:55:17 - INFO - 3473208690 - Fold 4 VAE Epoch 59/150 | β: 0.800 | Train Loss: 0.7918 (MSE: 0.7598, KLD: 0.0400) | Val Loss: 0.8154 (MSE: 0.7832, KLD: 0.0403)\n",
      "2025-05-26 03:55:17 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.775351|Current: 0.783224)\n",
      "2025-05-26 03:55:18 - INFO - 3473208690 - Fold 4 VAE Epoch 60/150 | β: 0.800 | Train Loss: 0.7891 (MSE: 0.7558, KLD: 0.0415) | Val Loss: 0.8172 (MSE: 0.7872, KLD: 0.0375)\n",
      "2025-05-26 03:55:18 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.775351|Current: 0.787245)\n",
      "2025-05-26 03:55:19 - INFO - 3473208690 - Fold 4 VAE Epoch 61/150 | β: 0.800 | Train Loss: 0.7900 (MSE: 0.7571, KLD: 0.0411) | Val Loss: 0.8151 (MSE: 0.7887, KLD: 0.0330)\n",
      "2025-05-26 03:55:19 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.775351|Current: 0.788674)\n",
      "2025-05-26 03:55:19 - INFO - 3473208690 - Fold 4 VAE Epoch 62/150 | β: 0.800 | Train Loss: 0.7862 (MSE: 0.7557, KLD: 0.0381) | Val Loss: 0.8066 (MSE: 0.7788, KLD: 0.0349)\n",
      "2025-05-26 03:55:19 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.775351|Current: 0.778763)\n",
      "2025-05-26 03:55:20 - INFO - 3473208690 - Fold 4 VAE Epoch 63/150 | β: 0.800 | Train Loss: 0.7869 (MSE: 0.7553, KLD: 0.0394) | Val Loss: 0.8047 (MSE: 0.7719, KLD: 0.0410)\n",
      "2025-05-26 03:55:20 - INFO - 3473208690 - Validation metric improved (0.771948 --> 0.771948). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:23 - INFO - 3473208690 - Fold 4 VAE Epoch 64/150 | β: 0.800 | Train Loss: 0.7844 (MSE: 0.7542, KLD: 0.0379) | Val Loss: 0.8054 (MSE: 0.7746, KLD: 0.0385)\n",
      "2025-05-26 03:55:23 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.771948|Current: 0.774627)\n",
      "2025-05-26 03:55:23 - INFO - 3473208690 - Fold 4 VAE Epoch 65/150 | β: 0.800 | Train Loss: 0.7825 (MSE: 0.7493, KLD: 0.0414) | Val Loss: 0.8059 (MSE: 0.7807, KLD: 0.0316)\n",
      "2025-05-26 03:55:23 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.771948|Current: 0.780670)\n",
      "2025-05-26 03:55:24 - INFO - 3473208690 - Fold 4 VAE Epoch 66/150 | β: 0.800 | Train Loss: 0.7820 (MSE: 0.7529, KLD: 0.0364) | Val Loss: 0.8051 (MSE: 0.7716, KLD: 0.0419)\n",
      "2025-05-26 03:55:24 - INFO - 3473208690 - Validation metric improved (0.771587 --> 0.771587). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:26 - INFO - 3473208690 - Fold 4 VAE Epoch 67/150 | β: 0.800 | Train Loss: 0.7840 (MSE: 0.7520, KLD: 0.0399) | Val Loss: 0.7980 (MSE: 0.7717, KLD: 0.0329)\n",
      "2025-05-26 03:55:26 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.771587|Current: 0.771680)\n",
      "2025-05-26 03:55:27 - INFO - 3473208690 - Fold 4 VAE Epoch 68/150 | β: 0.800 | Train Loss: 0.7831 (MSE: 0.7517, KLD: 0.0394) | Val Loss: 0.8028 (MSE: 0.7713, KLD: 0.0393)\n",
      "2025-05-26 03:55:27 - INFO - 3473208690 - Validation metric improved (0.771327 --> 0.771327). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:30 - INFO - 3473208690 - Fold 4 VAE Epoch 69/150 | β: 0.800 | Train Loss: 0.7789 (MSE: 0.7468, KLD: 0.0402) | Val Loss: 0.8121 (MSE: 0.7844, KLD: 0.0345)\n",
      "2025-05-26 03:55:30 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.771327|Current: 0.784433)\n",
      "2025-05-26 03:55:31 - INFO - 3473208690 - Fold 4 VAE Epoch 70/150 | β: 0.800 | Train Loss: 0.7826 (MSE: 0.7536, KLD: 0.0362) | Val Loss: 0.8038 (MSE: 0.7762, KLD: 0.0346)\n",
      "2025-05-26 03:55:31 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.771327|Current: 0.776164)\n",
      "2025-05-26 03:55:31 - INFO - 3473208690 - Fold 4 VAE Epoch 71/150 | β: 0.800 | Train Loss: 0.7786 (MSE: 0.7485, KLD: 0.0377) | Val Loss: 0.8069 (MSE: 0.7774, KLD: 0.0368)\n",
      "2025-05-26 03:55:31 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.771327|Current: 0.777423)\n",
      "2025-05-26 03:55:32 - INFO - 3473208690 - Fold 4 VAE Epoch 72/150 | β: 0.800 | Train Loss: 0.7835 (MSE: 0.7521, KLD: 0.0392) | Val Loss: 0.8093 (MSE: 0.7802, KLD: 0.0364)\n",
      "2025-05-26 03:55:32 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.771327|Current: 0.780208)\n",
      "2025-05-26 03:55:33 - INFO - 3473208690 - Fold 4 VAE Epoch 73/150 | β: 0.800 | Train Loss: 0.7816 (MSE: 0.7510, KLD: 0.0382) | Val Loss: 0.8011 (MSE: 0.7726, KLD: 0.0357)\n",
      "2025-05-26 03:55:33 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.771327|Current: 0.772550)\n",
      "2025-05-26 03:55:34 - INFO - 3473208690 - Fold 4 VAE Epoch 74/150 | β: 0.800 | Train Loss: 0.7789 (MSE: 0.7487, KLD: 0.0378) | Val Loss: 0.7979 (MSE: 0.7695, KLD: 0.0355)\n",
      "2025-05-26 03:55:34 - INFO - 3473208690 - Validation metric improved (0.769525 --> 0.769525). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:36 - INFO - 3473208690 - Fold 4 VAE Epoch 75/150 | β: 0.800 | Train Loss: 0.7865 (MSE: 0.7523, KLD: 0.0428) | Val Loss: 0.8034 (MSE: 0.7686, KLD: 0.0435)\n",
      "2025-05-26 03:55:36 - INFO - 3473208690 - Validation metric improved (0.768620 --> 0.768620). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:39 - INFO - 3473208690 - Fold 4 VAE Epoch 76/150 | β: 0.800 | Train Loss: 0.7856 (MSE: 0.7512, KLD: 0.0430) | Val Loss: 0.8080 (MSE: 0.7792, KLD: 0.0360)\n",
      "2025-05-26 03:55:39 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.768620|Current: 0.779229)\n",
      "2025-05-26 03:55:39 - INFO - 3473208690 - Fold 4 VAE Epoch 77/150 | β: 0.800 | Train Loss: 0.7845 (MSE: 0.7484, KLD: 0.0450) | Val Loss: 0.8060 (MSE: 0.7615, KLD: 0.0556)\n",
      "2025-05-26 03:55:39 - INFO - 3473208690 - Validation metric improved (0.761461 --> 0.761461). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:42 - INFO - 3473208690 - Fold 4 VAE Epoch 78/150 | β: 0.800 | Train Loss: 0.7848 (MSE: 0.7475, KLD: 0.0467) | Val Loss: 0.8129 (MSE: 0.7896, KLD: 0.0291)\n",
      "2025-05-26 03:55:42 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.761461|Current: 0.789563)\n",
      "2025-05-26 03:55:43 - INFO - 3473208690 - Fold 4 VAE Epoch 79/150 | β: 0.800 | Train Loss: 0.7865 (MSE: 0.7505, KLD: 0.0451) | Val Loss: 0.7965 (MSE: 0.7629, KLD: 0.0419)\n",
      "2025-05-26 03:55:43 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.761461|Current: 0.762946)\n",
      "2025-05-26 03:55:43 - INFO - 3473208690 - Fold 4 VAE Epoch 80/150 | β: 0.800 | Train Loss: 0.7780 (MSE: 0.7422, KLD: 0.0448) | Val Loss: 0.7968 (MSE: 0.7697, KLD: 0.0338)\n",
      "2025-05-26 03:55:43 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.761461|Current: 0.769738)\n",
      "2025-05-26 03:55:44 - INFO - 3473208690 - Fold 4 VAE Epoch 81/150 | β: 0.800 | Train Loss: 0.7740 (MSE: 0.7421, KLD: 0.0399) | Val Loss: 0.8057 (MSE: 0.7768, KLD: 0.0362)\n",
      "2025-05-26 03:55:44 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.761461|Current: 0.776806)\n",
      "2025-05-26 03:55:45 - INFO - 3473208690 - Fold 4 VAE Epoch 82/150 | β: 0.800 | Train Loss: 0.7814 (MSE: 0.7448, KLD: 0.0458) | Val Loss: 0.8017 (MSE: 0.7587, KLD: 0.0537)\n",
      "2025-05-26 03:55:45 - INFO - 3473208690 - Validation metric improved (0.758719 --> 0.758719). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:46 - INFO - 3473208690 - Fold 4 VAE Epoch 83/150 | β: 0.800 | Train Loss: 0.7723 (MSE: 0.7381, KLD: 0.0428) | Val Loss: 0.7960 (MSE: 0.7706, KLD: 0.0317)\n",
      "2025-05-26 03:55:46 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.758719|Current: 0.770599)\n",
      "2025-05-26 03:55:46 - INFO - 3473208690 - Fold 4 VAE Epoch 84/150 | β: 0.800 | Train Loss: 0.7729 (MSE: 0.7382, KLD: 0.0433) | Val Loss: 0.7924 (MSE: 0.7563, KLD: 0.0450)\n",
      "2025-05-26 03:55:46 - INFO - 3473208690 - Validation metric improved (0.756339 --> 0.756339). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:47 - INFO - 3473208690 - Fold 4 VAE Epoch 85/150 | β: 0.800 | Train Loss: 0.7717 (MSE: 0.7393, KLD: 0.0405) | Val Loss: 0.8085 (MSE: 0.7610, KLD: 0.0595)\n",
      "2025-05-26 03:55:47 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.756339|Current: 0.760964)\n",
      "2025-05-26 03:55:48 - INFO - 3473208690 - Fold 4 VAE Epoch 86/150 | β: 0.800 | Train Loss: 0.7726 (MSE: 0.7382, KLD: 0.0429) | Val Loss: 0.7929 (MSE: 0.7558, KLD: 0.0463)\n",
      "2025-05-26 03:55:48 - INFO - 3473208690 - Validation metric improved (0.755843 --> 0.755843). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:49 - INFO - 3473208690 - Fold 4 VAE Epoch 87/150 | β: 0.800 | Train Loss: 0.7759 (MSE: 0.7380, KLD: 0.0474) | Val Loss: 0.7927 (MSE: 0.7537, KLD: 0.0487)\n",
      "2025-05-26 03:55:49 - INFO - 3473208690 - Validation metric improved (0.753694 --> 0.753694). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:50 - INFO - 3473208690 - Fold 4 VAE Epoch 88/150 | β: 0.800 | Train Loss: 0.7679 (MSE: 0.7330, KLD: 0.0437) | Val Loss: 0.7904 (MSE: 0.7628, KLD: 0.0345)\n",
      "2025-05-26 03:55:50 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.753694|Current: 0.762785)\n",
      "2025-05-26 03:55:50 - INFO - 3473208690 - Fold 4 VAE Epoch 89/150 | β: 0.800 | Train Loss: 0.7681 (MSE: 0.7358, KLD: 0.0404) | Val Loss: 0.7822 (MSE: 0.7543, KLD: 0.0350)\n",
      "2025-05-26 03:55:50 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.753694|Current: 0.754270)\n",
      "2025-05-26 03:55:51 - INFO - 3473208690 - Fold 4 VAE Epoch 90/150 | β: 0.800 | Train Loss: 0.7644 (MSE: 0.7319, KLD: 0.0407) | Val Loss: 0.7890 (MSE: 0.7628, KLD: 0.0328)\n",
      "2025-05-26 03:55:51 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.753694|Current: 0.762791)\n",
      "2025-05-26 03:55:52 - INFO - 3473208690 - Fold 4 VAE Epoch 91/150 | β: 0.800 | Train Loss: 0.7613 (MSE: 0.7301, KLD: 0.0390) | Val Loss: 0.7823 (MSE: 0.7572, KLD: 0.0313)\n",
      "2025-05-26 03:55:52 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.753694|Current: 0.757210)\n",
      "2025-05-26 03:55:53 - INFO - 3473208690 - Fold 4 VAE Epoch 92/150 | β: 0.800 | Train Loss: 0.7622 (MSE: 0.7314, KLD: 0.0386) | Val Loss: 0.7845 (MSE: 0.7592, KLD: 0.0316)\n",
      "2025-05-26 03:55:53 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.753694|Current: 0.759189)\n",
      "2025-05-26 03:55:53 - INFO - 3473208690 - Fold 4 VAE Epoch 93/150 | β: 0.800 | Train Loss: 0.7638 (MSE: 0.7324, KLD: 0.0392) | Val Loss: 0.7846 (MSE: 0.7576, KLD: 0.0338)\n",
      "2025-05-26 03:55:53 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.753694|Current: 0.757625)\n",
      "2025-05-26 03:55:54 - INFO - 3473208690 - Fold 4 VAE Epoch 94/150 | β: 0.800 | Train Loss: 0.7613 (MSE: 0.7300, KLD: 0.0391) | Val Loss: 0.7821 (MSE: 0.7498, KLD: 0.0403)\n",
      "2025-05-26 03:55:54 - INFO - 3473208690 - Validation metric improved (0.749809 --> 0.749809). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:55 - INFO - 3473208690 - Fold 4 VAE Epoch 95/150 | β: 0.800 | Train Loss: 0.7582 (MSE: 0.7283, KLD: 0.0374) | Val Loss: 0.7806 (MSE: 0.7521, KLD: 0.0356)\n",
      "2025-05-26 03:55:55 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.749809|Current: 0.752133)\n",
      "2025-05-26 03:55:56 - INFO - 3473208690 - Fold 4 VAE Epoch 96/150 | β: 0.800 | Train Loss: 0.7605 (MSE: 0.7312, KLD: 0.0367) | Val Loss: 0.7775 (MSE: 0.7493, KLD: 0.0353)\n",
      "2025-05-26 03:55:56 - INFO - 3473208690 - Validation metric improved (0.749317 --> 0.749317). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:55:57 - INFO - 3473208690 - Fold 4 VAE Epoch 97/150 | β: 0.800 | Train Loss: 0.7590 (MSE: 0.7284, KLD: 0.0382) | Val Loss: 0.7825 (MSE: 0.7527, KLD: 0.0371)\n",
      "2025-05-26 03:55:57 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.749317|Current: 0.752742)\n",
      "2025-05-26 03:55:57 - INFO - 3473208690 - Fold 4 VAE Epoch 98/150 | β: 0.800 | Train Loss: 0.7578 (MSE: 0.7266, KLD: 0.0391) | Val Loss: 0.7803 (MSE: 0.7535, KLD: 0.0335)\n",
      "2025-05-26 03:55:57 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.749317|Current: 0.753503)\n",
      "2025-05-26 03:55:58 - INFO - 3473208690 - Fold 4 VAE Epoch 99/150 | β: 0.800 | Train Loss: 0.7621 (MSE: 0.7297, KLD: 0.0404) | Val Loss: 0.7821 (MSE: 0.7534, KLD: 0.0359)\n",
      "2025-05-26 03:55:58 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.749317|Current: 0.753380)\n",
      "2025-05-26 03:55:59 - INFO - 3473208690 - Fold 4 VAE Epoch 100/150 | β: 0.800 | Train Loss: 0.7554 (MSE: 0.7267, KLD: 0.0359) | Val Loss: 0.7871 (MSE: 0.7579, KLD: 0.0365)\n",
      "2025-05-26 03:55:59 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.749317|Current: 0.757938)\n",
      "2025-05-26 03:55:59 - INFO - 3473208690 - Fold 4 VAE Epoch 101/150 | β: 0.800 | Train Loss: 0.7562 (MSE: 0.7245, KLD: 0.0396) | Val Loss: 0.7865 (MSE: 0.7588, KLD: 0.0346)\n",
      "2025-05-26 03:55:59 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.749317|Current: 0.758792)\n",
      "2025-05-26 03:56:00 - INFO - 3473208690 - Fold 4 VAE Epoch 102/150 | β: 0.800 | Train Loss: 0.7562 (MSE: 0.7258, KLD: 0.0380) | Val Loss: 0.7775 (MSE: 0.7478, KLD: 0.0372)\n",
      "2025-05-26 03:56:00 - INFO - 3473208690 - Validation metric improved (0.747759 --> 0.747759). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:01 - INFO - 3473208690 - Fold 4 VAE Epoch 103/150 | β: 0.800 | Train Loss: 0.7529 (MSE: 0.7241, KLD: 0.0360) | Val Loss: 0.7810 (MSE: 0.7546, KLD: 0.0330)\n",
      "2025-05-26 03:56:01 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.747759|Current: 0.754615)\n",
      "2025-05-26 03:56:02 - INFO - 3473208690 - Fold 4 VAE Epoch 104/150 | β: 0.800 | Train Loss: 0.7576 (MSE: 0.7270, KLD: 0.0382) | Val Loss: 0.7853 (MSE: 0.7566, KLD: 0.0359)\n",
      "2025-05-26 03:56:02 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.747759|Current: 0.756603)\n",
      "2025-05-26 03:56:02 - INFO - 3473208690 - Fold 4 VAE Epoch 105/150 | β: 0.800 | Train Loss: 0.7544 (MSE: 0.7264, KLD: 0.0350) | Val Loss: 0.7748 (MSE: 0.7489, KLD: 0.0323)\n",
      "2025-05-26 03:56:02 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.747759|Current: 0.748944)\n",
      "2025-05-26 03:56:03 - INFO - 3473208690 - Fold 4 VAE Epoch 106/150 | β: 0.800 | Train Loss: 0.7541 (MSE: 0.7254, KLD: 0.0359) | Val Loss: 0.7747 (MSE: 0.7451, KLD: 0.0369)\n",
      "2025-05-26 03:56:03 - INFO - 3473208690 - Validation metric improved (0.745146 --> 0.745146). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:04 - INFO - 3473208690 - Fold 4 VAE Epoch 107/150 | β: 0.800 | Train Loss: 0.7538 (MSE: 0.7230, KLD: 0.0385) | Val Loss: 0.7743 (MSE: 0.7452, KLD: 0.0364)\n",
      "2025-05-26 03:56:04 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.745146|Current: 0.745162)\n",
      "2025-05-26 03:56:05 - INFO - 3473208690 - Fold 4 VAE Epoch 108/150 | β: 0.800 | Train Loss: 0.7531 (MSE: 0.7231, KLD: 0.0375) | Val Loss: 0.7824 (MSE: 0.7541, KLD: 0.0353)\n",
      "2025-05-26 03:56:05 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.745146|Current: 0.754128)\n",
      "2025-05-26 03:56:05 - INFO - 3473208690 - Fold 4 VAE Epoch 109/150 | β: 0.800 | Train Loss: 0.7529 (MSE: 0.7238, KLD: 0.0364) | Val Loss: 0.7788 (MSE: 0.7516, KLD: 0.0340)\n",
      "2025-05-26 03:56:05 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.745146|Current: 0.751588)\n",
      "2025-05-26 03:56:06 - INFO - 3473208690 - Fold 4 VAE Epoch 110/150 | β: 0.800 | Train Loss: 0.7538 (MSE: 0.7254, KLD: 0.0355) | Val Loss: 0.7820 (MSE: 0.7552, KLD: 0.0336)\n",
      "2025-05-26 03:56:06 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.745146|Current: 0.755174)\n",
      "2025-05-26 03:56:07 - INFO - 3473208690 - Fold 4 VAE Epoch 111/150 | β: 0.800 | Train Loss: 0.7507 (MSE: 0.7225, KLD: 0.0352) | Val Loss: 0.7805 (MSE: 0.7537, KLD: 0.0335)\n",
      "2025-05-26 03:56:07 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.745146|Current: 0.753691)\n",
      "2025-05-26 03:56:07 - INFO - 3473208690 - Fold 4 VAE Epoch 112/150 | β: 0.800 | Train Loss: 0.7621 (MSE: 0.7271, KLD: 0.0437) | Val Loss: 0.7878 (MSE: 0.7554, KLD: 0.0404)\n",
      "2025-05-26 03:56:07 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.745146|Current: 0.755413)\n",
      "2025-05-26 03:56:08 - INFO - 3473208690 - Fold 4 VAE Epoch 113/150 | β: 0.800 | Train Loss: 0.7554 (MSE: 0.7241, KLD: 0.0391) | Val Loss: 0.8128 (MSE: 0.7900, KLD: 0.0285)\n",
      "2025-05-26 03:56:08 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.745146|Current: 0.789978)\n",
      "2025-05-26 03:56:09 - INFO - 3473208690 - Fold 4 VAE Epoch 114/150 | β: 0.800 | Train Loss: 0.7640 (MSE: 0.7294, KLD: 0.0433) | Val Loss: 0.7978 (MSE: 0.7553, KLD: 0.0532)\n",
      "2025-05-26 03:56:09 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.745146|Current: 0.755303)\n",
      "2025-05-26 03:56:10 - INFO - 3473208690 - Fold 4 VAE Epoch 115/150 | β: 0.800 | Train Loss: 0.7622 (MSE: 0.7240, KLD: 0.0478) | Val Loss: 0.7909 (MSE: 0.7519, KLD: 0.0488)\n",
      "2025-05-26 03:56:10 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.745146|Current: 0.751882)\n",
      "2025-05-26 03:56:10 - INFO - 3473208690 - Fold 4 VAE Epoch 116/150 | β: 0.800 | Train Loss: 0.7584 (MSE: 0.7248, KLD: 0.0420) | Val Loss: 0.7828 (MSE: 0.7562, KLD: 0.0332)\n",
      "2025-05-26 03:56:10 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.745146|Current: 0.756227)\n",
      "2025-05-26 03:56:11 - INFO - 3473208690 - Fold 4 VAE Epoch 117/150 | β: 0.800 | Train Loss: 0.7541 (MSE: 0.7237, KLD: 0.0380) | Val Loss: 0.7838 (MSE: 0.7563, KLD: 0.0343)\n",
      "2025-05-26 03:56:11 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.745146|Current: 0.756313)\n",
      "2025-05-26 03:56:12 - INFO - 3473208690 - Fold 4 VAE Epoch 118/150 | β: 0.800 | Train Loss: 0.7599 (MSE: 0.7259, KLD: 0.0425) | Val Loss: 0.7860 (MSE: 0.7425, KLD: 0.0543)\n",
      "2025-05-26 03:56:12 - INFO - 3473208690 - Validation metric improved (0.742542 --> 0.742542). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:14 - INFO - 3473208690 - Fold 4 VAE Epoch 119/150 | β: 0.800 | Train Loss: 0.7583 (MSE: 0.7223, KLD: 0.0450) | Val Loss: 0.7976 (MSE: 0.7562, KLD: 0.0518)\n",
      "2025-05-26 03:56:14 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.742542|Current: 0.756201)\n",
      "2025-05-26 03:56:15 - INFO - 3473208690 - Fold 4 VAE Epoch 120/150 | β: 0.800 | Train Loss: 0.7550 (MSE: 0.7210, KLD: 0.0424) | Val Loss: 0.7812 (MSE: 0.7494, KLD: 0.0398)\n",
      "2025-05-26 03:56:15 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.742542|Current: 0.749421)\n",
      "2025-05-26 03:56:15 - INFO - 3473208690 - Fold 4 VAE Epoch 121/150 | β: 0.800 | Train Loss: 0.7475 (MSE: 0.7159, KLD: 0.0395) | Val Loss: 0.7802 (MSE: 0.7530, KLD: 0.0340)\n",
      "2025-05-26 03:56:15 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.742542|Current: 0.752993)\n",
      "2025-05-26 03:56:16 - INFO - 3473208690 - Fold 4 VAE Epoch 122/150 | β: 0.800 | Train Loss: 0.7510 (MSE: 0.7213, KLD: 0.0371) | Val Loss: 0.7773 (MSE: 0.7508, KLD: 0.0331)\n",
      "2025-05-26 03:56:16 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.742542|Current: 0.750805)\n",
      "2025-05-26 03:56:17 - INFO - 3473208690 - Fold 4 VAE Epoch 123/150 | β: 0.800 | Train Loss: 0.7493 (MSE: 0.7174, KLD: 0.0400) | Val Loss: 0.7720 (MSE: 0.7435, KLD: 0.0357)\n",
      "2025-05-26 03:56:17 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.742542|Current: 0.743483)\n",
      "2025-05-26 03:56:17 - INFO - 3473208690 - Fold 4 VAE Epoch 124/150 | β: 0.800 | Train Loss: 0.7467 (MSE: 0.7156, KLD: 0.0388) | Val Loss: 0.7712 (MSE: 0.7388, KLD: 0.0405)\n",
      "2025-05-26 03:56:17 - INFO - 3473208690 - Validation metric improved (0.738835 --> 0.738835). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:20 - INFO - 3473208690 - Fold 4 VAE Epoch 125/150 | β: 0.800 | Train Loss: 0.7487 (MSE: 0.7179, KLD: 0.0384) | Val Loss: 0.7857 (MSE: 0.7456, KLD: 0.0501)\n",
      "2025-05-26 03:56:20 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.738835|Current: 0.745575)\n",
      "2025-05-26 03:56:20 - INFO - 3473208690 - Fold 4 VAE Epoch 126/150 | β: 0.800 | Train Loss: 0.7492 (MSE: 0.7148, KLD: 0.0429) | Val Loss: 0.7750 (MSE: 0.7451, KLD: 0.0374)\n",
      "2025-05-26 03:56:20 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.738835|Current: 0.745122)\n",
      "2025-05-26 03:56:21 - INFO - 3473208690 - Fold 4 VAE Epoch 127/150 | β: 0.800 | Train Loss: 0.7462 (MSE: 0.7168, KLD: 0.0368) | Val Loss: 0.7724 (MSE: 0.7486, KLD: 0.0298)\n",
      "2025-05-26 03:56:21 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.738835|Current: 0.748558)\n",
      "2025-05-26 03:56:22 - INFO - 3473208690 - Fold 4 VAE Epoch 128/150 | β: 0.800 | Train Loss: 0.7462 (MSE: 0.7187, KLD: 0.0344) | Val Loss: 0.7736 (MSE: 0.7470, KLD: 0.0333)\n",
      "2025-05-26 03:56:22 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.738835|Current: 0.747021)\n",
      "2025-05-26 03:56:23 - INFO - 3473208690 - Fold 4 VAE Epoch 129/150 | β: 0.800 | Train Loss: 0.7421 (MSE: 0.7122, KLD: 0.0374) | Val Loss: 0.7699 (MSE: 0.7403, KLD: 0.0370)\n",
      "2025-05-26 03:56:23 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.738835|Current: 0.740307)\n",
      "2025-05-26 03:56:23 - INFO - 3473208690 - Fold 4 VAE Epoch 130/150 | β: 0.800 | Train Loss: 0.7451 (MSE: 0.7143, KLD: 0.0385) | Val Loss: 0.7718 (MSE: 0.7441, KLD: 0.0347)\n",
      "2025-05-26 03:56:23 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.738835|Current: 0.744074)\n",
      "2025-05-26 03:56:24 - INFO - 3473208690 - Fold 4 VAE Epoch 131/150 | β: 0.800 | Train Loss: 0.7456 (MSE: 0.7160, KLD: 0.0370) | Val Loss: 0.7680 (MSE: 0.7398, KLD: 0.0352)\n",
      "2025-05-26 03:56:24 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.738835|Current: 0.739846)\n",
      "2025-05-26 03:56:25 - INFO - 3473208690 - Fold 4 VAE Epoch 132/150 | β: 0.800 | Train Loss: 0.7380 (MSE: 0.7083, KLD: 0.0370) | Val Loss: 0.7737 (MSE: 0.7448, KLD: 0.0361)\n",
      "2025-05-26 03:56:25 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.738835|Current: 0.744822)\n",
      "2025-05-26 03:56:25 - INFO - 3473208690 - Fold 4 VAE Epoch 133/150 | β: 0.800 | Train Loss: 0.7410 (MSE: 0.7122, KLD: 0.0360) | Val Loss: 0.7672 (MSE: 0.7392, KLD: 0.0351)\n",
      "2025-05-26 03:56:25 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.738835|Current: 0.739191)\n",
      "2025-05-26 03:56:26 - INFO - 3473208690 - Fold 4 VAE Epoch 134/150 | β: 0.800 | Train Loss: 0.7462 (MSE: 0.7175, KLD: 0.0358) | Val Loss: 0.7748 (MSE: 0.7404, KLD: 0.0430)\n",
      "2025-05-26 03:56:26 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.738835|Current: 0.740358)\n",
      "2025-05-26 03:56:27 - INFO - 3473208690 - Fold 4 VAE Epoch 135/150 | β: 0.800 | Train Loss: 0.7460 (MSE: 0.7163, KLD: 0.0371) | Val Loss: 0.7653 (MSE: 0.7385, KLD: 0.0335)\n",
      "2025-05-26 03:56:27 - INFO - 3473208690 - Validation metric improved (0.738534 --> 0.738534). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:29 - INFO - 3473208690 - Fold 4 VAE Epoch 136/150 | β: 0.800 | Train Loss: 0.7414 (MSE: 0.7102, KLD: 0.0390) | Val Loss: 0.7722 (MSE: 0.7447, KLD: 0.0343)\n",
      "2025-05-26 03:56:29 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.738534|Current: 0.744718)\n",
      "2025-05-26 03:56:30 - INFO - 3473208690 - Fold 4 VAE Epoch 137/150 | β: 0.800 | Train Loss: 0.7406 (MSE: 0.7096, KLD: 0.0387) | Val Loss: 0.7666 (MSE: 0.7362, KLD: 0.0379)\n",
      "2025-05-26 03:56:30 - INFO - 3473208690 - Validation metric improved (0.736250 --> 0.736250). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:31 - INFO - 3473208690 - Fold 4 VAE Epoch 138/150 | β: 0.800 | Train Loss: 0.7402 (MSE: 0.7114, KLD: 0.0360) | Val Loss: 0.7704 (MSE: 0.7433, KLD: 0.0339)\n",
      "2025-05-26 03:56:31 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.736250|Current: 0.743323)\n",
      "2025-05-26 03:56:32 - INFO - 3473208690 - Fold 4 VAE Epoch 139/150 | β: 0.800 | Train Loss: 0.7402 (MSE: 0.7113, KLD: 0.0362) | Val Loss: 0.7715 (MSE: 0.7426, KLD: 0.0361)\n",
      "2025-05-26 03:56:32 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.736250|Current: 0.742582)\n",
      "2025-05-26 03:56:33 - INFO - 3473208690 - Fold 4 VAE Epoch 140/150 | β: 0.800 | Train Loss: 0.7391 (MSE: 0.7103, KLD: 0.0360) | Val Loss: 0.7628 (MSE: 0.7376, KLD: 0.0315)\n",
      "2025-05-26 03:56:33 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.736250|Current: 0.737618)\n",
      "2025-05-26 03:56:33 - INFO - 3473208690 - Fold 4 VAE Epoch 141/150 | β: 0.800 | Train Loss: 0.7431 (MSE: 0.7159, KLD: 0.0341) | Val Loss: 0.7678 (MSE: 0.7395, KLD: 0.0354)\n",
      "2025-05-26 03:56:33 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.736250|Current: 0.739511)\n",
      "2025-05-26 03:56:34 - INFO - 3473208690 - Fold 4 VAE Epoch 142/150 | β: 0.800 | Train Loss: 0.7420 (MSE: 0.7111, KLD: 0.0386) | Val Loss: 0.7644 (MSE: 0.7367, KLD: 0.0346)\n",
      "2025-05-26 03:56:34 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.736250|Current: 0.736658)\n",
      "2025-05-26 03:56:35 - INFO - 3473208690 - Fold 4 VAE Epoch 143/150 | β: 0.800 | Train Loss: 0.7415 (MSE: 0.7136, KLD: 0.0348) | Val Loss: 0.7618 (MSE: 0.7360, KLD: 0.0322)\n",
      "2025-05-26 03:56:35 - INFO - 3473208690 - Validation metric improved (0.736049 --> 0.736049). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:36 - INFO - 3473208690 - Fold 4 VAE Epoch 144/150 | β: 0.800 | Train Loss: 0.7381 (MSE: 0.7106, KLD: 0.0344) | Val Loss: 0.7687 (MSE: 0.7430, KLD: 0.0320)\n",
      "2025-05-26 03:56:36 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.736049|Current: 0.743027)\n",
      "2025-05-26 03:56:37 - INFO - 3473208690 - Fold 4 VAE Epoch 145/150 | β: 0.800 | Train Loss: 0.7418 (MSE: 0.7144, KLD: 0.0343) | Val Loss: 0.7597 (MSE: 0.7330, KLD: 0.0334)\n",
      "2025-05-26 03:56:37 - INFO - 3473208690 - Validation metric improved (0.733037 --> 0.733037). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt ...\n",
      "2025-05-26 03:56:38 - INFO - 3473208690 - Fold 4 VAE Epoch 146/150 | β: 0.800 | Train Loss: 0.7410 (MSE: 0.7120, KLD: 0.0362) | Val Loss: 0.7625 (MSE: 0.7344, KLD: 0.0352)\n",
      "2025-05-26 03:56:38 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.733037|Current: 0.734360)\n",
      "2025-05-26 03:56:38 - INFO - 3473208690 - Fold 4 VAE Epoch 147/150 | β: 0.800 | Train Loss: 0.7383 (MSE: 0.7085, KLD: 0.0373) | Val Loss: 0.7645 (MSE: 0.7362, KLD: 0.0354)\n",
      "2025-05-26 03:56:38 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.733037|Current: 0.736190)\n",
      "2025-05-26 03:56:39 - INFO - 3473208690 - Fold 4 VAE Epoch 148/150 | β: 0.800 | Train Loss: 0.7412 (MSE: 0.7114, KLD: 0.0373) | Val Loss: 0.7627 (MSE: 0.7345, KLD: 0.0352)\n",
      "2025-05-26 03:56:39 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.733037|Current: 0.734525)\n",
      "2025-05-26 03:56:40 - INFO - 3473208690 - Fold 4 VAE Epoch 149/150 | β: 0.800 | Train Loss: 0.7475 (MSE: 0.7161, KLD: 0.0392) | Val Loss: 0.7735 (MSE: 0.7462, KLD: 0.0341)\n",
      "2025-05-26 03:56:40 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.733037|Current: 0.746192)\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - Fold 4 VAE Epoch 150/150 | β: 0.800 | Train Loss: 0.7426 (MSE: 0.7118, KLD: 0.0385) | Val Loss: 0.7757 (MSE: 0.7431, KLD: 0.0408)\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.733037|Current: 0.743070)\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - Loaded best VAE model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_vae_model.pt\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - --- Extracting Latent Features (mu only) for Train, Val, Test ---\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_3/fold_3_preprocessed_data.pt for test split.\n",
      "2025-05-26 03:56:41 - WARNING - 3473208690 - Test split keys not found in preprocessed_connectomes_for_dl/fold_3/fold_3_preprocessed_data.pt. Test set will be empty.\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - Loaded 0 samples for test split.\n",
      "2025-05-26 03:56:41 - WARNING - 3473208690 - Fold 4: Test dataset is empty. Skipping test set evaluation for this fold.\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - --- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\n",
      "2025-05-26 03:56:41 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha: [1.0352112  0.96710527]\n",
      "2025-05-26 03:56:42 - INFO - 3473208690 - Validation metric improved (0.728070 --> 0.728070). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:56:42 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.728070|Current: 0.682749)\n",
      "2025-05-26 03:56:43 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.728070|Current: 0.656433)\n",
      "2025-05-26 03:56:43 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.728070|Current: 0.640351)\n",
      "2025-05-26 03:56:44 - INFO - 3473208690 - EarlyStopping counter: 4 out of 10 (Best: 0.728070|Current: 0.643275)\n",
      "2025-05-26 03:56:44 - INFO - 3473208690 - EarlyStopping counter: 5 out of 10 (Best: 0.728070|Current: 0.635965)\n",
      "2025-05-26 03:56:45 - INFO - 3473208690 - EarlyStopping counter: 6 out of 10 (Best: 0.728070|Current: 0.657895)\n",
      "2025-05-26 03:56:46 - INFO - 3473208690 - EarlyStopping counter: 7 out of 10 (Best: 0.728070|Current: 0.678363)\n",
      "2025-05-26 03:56:46 - INFO - 3473208690 - EarlyStopping counter: 8 out of 10 (Best: 0.728070|Current: 0.672515)\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - EarlyStopping counter: 9 out of 10 (Best: 0.728070|Current: 0.697368)\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - EarlyStopping counter: 10 out of 10 (Best: 0.728070|Current: 0.709064)\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - Early stopping initial classifier training.\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - Loaded best initial classifier model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/best_initial_classifier_model.pt.\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - Fold 4 Initial Best Classifier Val Metrics: Acc: 0.5135, AUC: 0.7281, F1: 0.6786\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - --- Classifier Re-training Phase (CN vs AD) on Train+Val ---\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha for retraining: [1.0337079 0.9684211]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:56:47 - INFO - 3473208690 - Re-training classifier on combined train+val data for 30 epochs.\n",
      "2025-05-26 03:56:49 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 5/30 | Train Loss: 0.2295, Acc: 0.5435\n",
      "2025-05-26 03:56:50 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 10/30 | Train Loss: 0.1970, Acc: 0.5652\n",
      "2025-05-26 03:56:51 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 15/30 | Train Loss: 0.2158, Acc: 0.5109\n",
      "2025-05-26 03:56:53 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 20/30 | Train Loss: 0.1934, Acc: 0.5543\n",
      "2025-05-26 03:56:54 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 25/30 | Train Loss: 0.1746, Acc: 0.6359\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Fold 4 CLF Re-train Epoch 30/30 | Train Loss: 0.1817, Acc: 0.6359\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Saved final classifier model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_3/final_classifier_model.pt\n",
      "2025-05-26 03:56:56 - WARNING - 3473208690 - Fold 4: Test data latent features are empty. Skipping test set evaluation.\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - --- Processing Fold 5/51 ---\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_4/fold_4_preprocessed_data.pt for train split.\n",
      "/tmp/ipykernel_830700/3473208690.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file, map_location='cpu')\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Loaded 282 samples for train split.\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_4/fold_4_preprocessed_data.pt for val split.\n",
      "2025-05-26 03:56:56 - INFO - 3473208690 - Loaded 70 samples for val split.\n",
      "2025-05-26 03:56:57 - INFO - 3473208690 - Fold 5 VAE Epoch 1/150 | β: 0.000 | Train Loss: 1.2720 (MSE: 1.2720, KLD: 2.0270) | Val Loss: 1.1039 (MSE: 1.1039, KLD: 5.8653)\n",
      "2025-05-26 03:56:57 - INFO - 3473208690 - Validation metric improved (1.103867 --> 1.103867). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:56:58 - INFO - 3473208690 - Fold 5 VAE Epoch 2/150 | β: 0.016 | Train Loss: 1.1449 (MSE: 1.0889, KLD: 3.4968) | Val Loss: 1.0501 (MSE: 1.0387, KLD: 0.7143)\n",
      "2025-05-26 03:56:58 - INFO - 3473208690 - Validation metric improved (1.038653 --> 1.038653). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:56:59 - INFO - 3473208690 - Fold 5 VAE Epoch 3/150 | β: 0.032 | Train Loss: 1.0624 (MSE: 1.0420, KLD: 0.6388) | Val Loss: 1.0144 (MSE: 0.9912, KLD: 0.7235)\n",
      "2025-05-26 03:56:59 - INFO - 3473208690 - Validation metric improved (0.991223 --> 0.991223). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:56:59 - INFO - 3473208690 - Fold 5 VAE Epoch 4/150 | β: 0.048 | Train Loss: 1.0335 (MSE: 1.0112, KLD: 0.4644) | Val Loss: 0.9928 (MSE: 0.9715, KLD: 0.4444)\n",
      "2025-05-26 03:56:59 - INFO - 3473208690 - Validation metric improved (0.971458 --> 0.971458). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:00 - INFO - 3473208690 - Fold 5 VAE Epoch 5/150 | β: 0.064 | Train Loss: 1.0112 (MSE: 0.9904, KLD: 0.3255) | Val Loss: 0.9773 (MSE: 0.9563, KLD: 0.3284)\n",
      "2025-05-26 03:57:00 - INFO - 3473208690 - Validation metric improved (0.956257 --> 0.956257). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:01 - INFO - 3473208690 - Fold 5 VAE Epoch 6/150 | β: 0.080 | Train Loss: 0.9966 (MSE: 0.9769, KLD: 0.2464) | Val Loss: 0.9636 (MSE: 0.9441, KLD: 0.2437)\n",
      "2025-05-26 03:57:01 - INFO - 3473208690 - Validation metric improved (0.944127 --> 0.944127). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:02 - INFO - 3473208690 - Fold 5 VAE Epoch 7/150 | β: 0.096 | Train Loss: 0.9849 (MSE: 0.9664, KLD: 0.1936) | Val Loss: 0.9529 (MSE: 0.9375, KLD: 0.1600)\n",
      "2025-05-26 03:57:02 - INFO - 3473208690 - Validation metric improved (0.937499 --> 0.937499). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:03 - INFO - 3473208690 - Fold 5 VAE Epoch 8/150 | β: 0.112 | Train Loss: 0.9746 (MSE: 0.9574, KLD: 0.1536) | Val Loss: 0.9444 (MSE: 0.9290, KLD: 0.1372)\n",
      "2025-05-26 03:57:03 - INFO - 3473208690 - Validation metric improved (0.929038 --> 0.929038). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:04 - INFO - 3473208690 - Fold 5 VAE Epoch 9/150 | β: 0.128 | Train Loss: 0.9646 (MSE: 0.9476, KLD: 0.1326) | Val Loss: 0.9323 (MSE: 0.9152, KLD: 0.1333)\n",
      "2025-05-26 03:57:04 - INFO - 3473208690 - Validation metric improved (0.915201 --> 0.915201). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:05 - INFO - 3473208690 - Fold 5 VAE Epoch 10/150 | β: 0.144 | Train Loss: 0.9560 (MSE: 0.9398, KLD: 0.1123) | Val Loss: 0.9242 (MSE: 0.9089, KLD: 0.1066)\n",
      "2025-05-26 03:57:05 - INFO - 3473208690 - Validation metric improved (0.908894 --> 0.908894). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:06 - INFO - 3473208690 - Fold 5 VAE Epoch 11/150 | β: 0.160 | Train Loss: 0.9470 (MSE: 0.9309, KLD: 0.1010) | Val Loss: 0.9163 (MSE: 0.9011, KLD: 0.0945)\n",
      "2025-05-26 03:57:06 - INFO - 3473208690 - Validation metric improved (0.901129 --> 0.901129). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:07 - INFO - 3473208690 - Fold 5 VAE Epoch 12/150 | β: 0.176 | Train Loss: 0.9419 (MSE: 0.9261, KLD: 0.0900) | Val Loss: 0.9096 (MSE: 0.8928, KLD: 0.0955)\n",
      "2025-05-26 03:57:07 - INFO - 3473208690 - Validation metric improved (0.892795 --> 0.892795). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:07 - INFO - 3473208690 - Fold 5 VAE Epoch 13/150 | β: 0.192 | Train Loss: 0.9348 (MSE: 0.9193, KLD: 0.0809) | Val Loss: 0.9052 (MSE: 0.8874, KLD: 0.0927)\n",
      "2025-05-26 03:57:07 - INFO - 3473208690 - Validation metric improved (0.887429 --> 0.887429). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:08 - INFO - 3473208690 - Fold 5 VAE Epoch 14/150 | β: 0.208 | Train Loss: 0.9303 (MSE: 0.9147, KLD: 0.0754) | Val Loss: 0.8984 (MSE: 0.8816, KLD: 0.0807)\n",
      "2025-05-26 03:57:08 - INFO - 3473208690 - Validation metric improved (0.881615 --> 0.881615). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:09 - INFO - 3473208690 - Fold 5 VAE Epoch 15/150 | β: 0.224 | Train Loss: 0.9248 (MSE: 0.9077, KLD: 0.0766) | Val Loss: 0.8942 (MSE: 0.8821, KLD: 0.0541)\n",
      "2025-05-26 03:57:09 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.881615|Current: 0.882132)\n",
      "2025-05-26 03:57:10 - INFO - 3473208690 - Fold 5 VAE Epoch 16/150 | β: 0.240 | Train Loss: 0.9262 (MSE: 0.9091, KLD: 0.0712) | Val Loss: 0.8879 (MSE: 0.8715, KLD: 0.0681)\n",
      "2025-05-26 03:57:10 - INFO - 3473208690 - Validation metric improved (0.871546 --> 0.871546). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:13 - INFO - 3473208690 - Fold 5 VAE Epoch 17/150 | β: 0.256 | Train Loss: 0.9158 (MSE: 0.8989, KLD: 0.0662) | Val Loss: 0.8851 (MSE: 0.8642, KLD: 0.0819)\n",
      "2025-05-26 03:57:13 - INFO - 3473208690 - Validation metric improved (0.864160 --> 0.864160). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:16 - INFO - 3473208690 - Fold 5 VAE Epoch 18/150 | β: 0.272 | Train Loss: 0.9100 (MSE: 0.8913, KLD: 0.0685) | Val Loss: 0.8810 (MSE: 0.8651, KLD: 0.0584)\n",
      "2025-05-26 03:57:16 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.864160|Current: 0.865130)\n",
      "2025-05-26 03:57:17 - INFO - 3473208690 - Fold 5 VAE Epoch 19/150 | β: 0.288 | Train Loss: 0.9065 (MSE: 0.8881, KLD: 0.0638) | Val Loss: 0.8781 (MSE: 0.8564, KLD: 0.0752)\n",
      "2025-05-26 03:57:17 - INFO - 3473208690 - Validation metric improved (0.856400 --> 0.856400). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:20 - INFO - 3473208690 - Fold 5 VAE Epoch 20/150 | β: 0.304 | Train Loss: 0.9011 (MSE: 0.8810, KLD: 0.0660) | Val Loss: 0.8726 (MSE: 0.8562, KLD: 0.0541)\n",
      "2025-05-26 03:57:20 - INFO - 3473208690 - Validation metric improved (0.856201 --> 0.856201). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:22 - INFO - 3473208690 - Fold 5 VAE Epoch 21/150 | β: 0.320 | Train Loss: 0.8967 (MSE: 0.8767, KLD: 0.0625) | Val Loss: 0.8705 (MSE: 0.8487, KLD: 0.0683)\n",
      "2025-05-26 03:57:22 - INFO - 3473208690 - Validation metric improved (0.848699 --> 0.848699). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:25 - INFO - 3473208690 - Fold 5 VAE Epoch 22/150 | β: 0.336 | Train Loss: 0.8932 (MSE: 0.8706, KLD: 0.0673) | Val Loss: 0.8677 (MSE: 0.8490, KLD: 0.0558)\n",
      "2025-05-26 03:57:25 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.848699|Current: 0.848978)\n",
      "2025-05-26 03:57:26 - INFO - 3473208690 - Fold 5 VAE Epoch 23/150 | β: 0.352 | Train Loss: 0.8876 (MSE: 0.8658, KLD: 0.0620) | Val Loss: 0.8650 (MSE: 0.8411, KLD: 0.0680)\n",
      "2025-05-26 03:57:26 - INFO - 3473208690 - Validation metric improved (0.841074 --> 0.841074). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:29 - INFO - 3473208690 - Fold 5 VAE Epoch 24/150 | β: 0.368 | Train Loss: 0.8859 (MSE: 0.8638, KLD: 0.0601) | Val Loss: 0.8604 (MSE: 0.8379, KLD: 0.0611)\n",
      "2025-05-26 03:57:29 - INFO - 3473208690 - Validation metric improved (0.837879 --> 0.837879). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:31 - INFO - 3473208690 - Fold 5 VAE Epoch 25/150 | β: 0.384 | Train Loss: 0.8834 (MSE: 0.8598, KLD: 0.0615) | Val Loss: 0.8571 (MSE: 0.8353, KLD: 0.0568)\n",
      "2025-05-26 03:57:31 - INFO - 3473208690 - Validation metric improved (0.835284 --> 0.835284). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:34 - INFO - 3473208690 - Fold 5 VAE Epoch 26/150 | β: 0.400 | Train Loss: 0.8788 (MSE: 0.8549, KLD: 0.0597) | Val Loss: 0.8589 (MSE: 0.8364, KLD: 0.0561)\n",
      "2025-05-26 03:57:34 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.835284|Current: 0.836424)\n",
      "2025-05-26 03:57:35 - INFO - 3473208690 - Fold 5 VAE Epoch 27/150 | β: 0.416 | Train Loss: 0.8753 (MSE: 0.8512, KLD: 0.0579) | Val Loss: 0.8568 (MSE: 0.8352, KLD: 0.0519)\n",
      "2025-05-26 03:57:35 - INFO - 3473208690 - Validation metric improved (0.835213 --> 0.835213). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:38 - INFO - 3473208690 - Fold 5 VAE Epoch 28/150 | β: 0.432 | Train Loss: 0.8749 (MSE: 0.8513, KLD: 0.0544) | Val Loss: 0.8555 (MSE: 0.8294, KLD: 0.0603)\n",
      "2025-05-26 03:57:38 - INFO - 3473208690 - Validation metric improved (0.829426 --> 0.829426). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:39 - INFO - 3473208690 - Fold 5 VAE Epoch 29/150 | β: 0.448 | Train Loss: 0.8740 (MSE: 0.8494, KLD: 0.0549) | Val Loss: 0.8569 (MSE: 0.8301, KLD: 0.0599)\n",
      "2025-05-26 03:57:39 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.829426|Current: 0.830101)\n",
      "2025-05-26 03:57:40 - INFO - 3473208690 - Fold 5 VAE Epoch 30/150 | β: 0.464 | Train Loss: 0.8722 (MSE: 0.8465, KLD: 0.0555) | Val Loss: 0.8533 (MSE: 0.8295, KLD: 0.0512)\n",
      "2025-05-26 03:57:40 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.829426|Current: 0.829543)\n",
      "2025-05-26 03:57:41 - INFO - 3473208690 - Fold 5 VAE Epoch 31/150 | β: 0.480 | Train Loss: 0.8685 (MSE: 0.8430, KLD: 0.0530) | Val Loss: 0.8518 (MSE: 0.8288, KLD: 0.0479)\n",
      "2025-05-26 03:57:41 - INFO - 3473208690 - Validation metric improved (0.828824 --> 0.828824). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:43 - INFO - 3473208690 - Fold 5 VAE Epoch 32/150 | β: 0.496 | Train Loss: 0.8736 (MSE: 0.8472, KLD: 0.0531) | Val Loss: 0.8542 (MSE: 0.8297, KLD: 0.0493)\n",
      "2025-05-26 03:57:43 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.828824|Current: 0.829716)\n",
      "2025-05-26 03:57:44 - INFO - 3473208690 - Fold 5 VAE Epoch 33/150 | β: 0.512 | Train Loss: 0.8701 (MSE: 0.8453, KLD: 0.0483) | Val Loss: 0.8555 (MSE: 0.8295, KLD: 0.0507)\n",
      "2025-05-26 03:57:44 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.828824|Current: 0.829548)\n",
      "2025-05-26 03:57:44 - INFO - 3473208690 - Fold 5 VAE Epoch 34/150 | β: 0.528 | Train Loss: 0.8718 (MSE: 0.8444, KLD: 0.0518) | Val Loss: 0.8549 (MSE: 0.8291, KLD: 0.0490)\n",
      "2025-05-26 03:57:44 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.828824|Current: 0.829079)\n",
      "2025-05-26 03:57:45 - INFO - 3473208690 - Fold 5 VAE Epoch 35/150 | β: 0.544 | Train Loss: 0.8723 (MSE: 0.8456, KLD: 0.0492) | Val Loss: 0.8516 (MSE: 0.8254, KLD: 0.0481)\n",
      "2025-05-26 03:57:45 - INFO - 3473208690 - Validation metric improved (0.825434 --> 0.825434). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:48 - INFO - 3473208690 - Fold 5 VAE Epoch 36/150 | β: 0.560 | Train Loss: 0.8719 (MSE: 0.8441, KLD: 0.0495) | Val Loss: 0.8545 (MSE: 0.8278, KLD: 0.0476)\n",
      "2025-05-26 03:57:48 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.825434|Current: 0.827802)\n",
      "2025-05-26 03:57:49 - INFO - 3473208690 - Fold 5 VAE Epoch 37/150 | β: 0.576 | Train Loss: 0.8735 (MSE: 0.8454, KLD: 0.0487) | Val Loss: 0.8575 (MSE: 0.8304, KLD: 0.0472)\n",
      "2025-05-26 03:57:49 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.825434|Current: 0.830375)\n",
      "2025-05-26 03:57:49 - INFO - 3473208690 - Fold 5 VAE Epoch 38/150 | β: 0.592 | Train Loss: 0.8920 (MSE: 0.8517, KLD: 0.0681) | Val Loss: 0.8572 (MSE: 0.8161, KLD: 0.0693)\n",
      "2025-05-26 03:57:49 - INFO - 3473208690 - Validation metric improved (0.816140 --> 0.816140). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:52 - INFO - 3473208690 - Fold 5 VAE Epoch 39/150 | β: 0.608 | Train Loss: 0.8755 (MSE: 0.8405, KLD: 0.0575) | Val Loss: 0.8572 (MSE: 0.8262, KLD: 0.0511)\n",
      "2025-05-26 03:57:52 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.816140|Current: 0.826164)\n",
      "2025-05-26 03:57:53 - INFO - 3473208690 - Fold 5 VAE Epoch 40/150 | β: 0.624 | Train Loss: 0.8658 (MSE: 0.8308, KLD: 0.0562) | Val Loss: 0.8426 (MSE: 0.8087, KLD: 0.0543)\n",
      "2025-05-26 03:57:53 - INFO - 3473208690 - Validation metric improved (0.808677 --> 0.808677). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:57:55 - INFO - 3473208690 - Fold 5 VAE Epoch 41/150 | β: 0.640 | Train Loss: 0.8578 (MSE: 0.8230, KLD: 0.0543) | Val Loss: 0.8405 (MSE: 0.8140, KLD: 0.0415)\n",
      "2025-05-26 03:57:55 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.808677|Current: 0.813956)\n",
      "2025-05-26 03:57:56 - INFO - 3473208690 - Fold 5 VAE Epoch 42/150 | β: 0.656 | Train Loss: 0.8486 (MSE: 0.8147, KLD: 0.0518) | Val Loss: 0.8454 (MSE: 0.8178, KLD: 0.0422)\n",
      "2025-05-26 03:57:56 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.808677|Current: 0.817761)\n",
      "2025-05-26 03:57:57 - INFO - 3473208690 - Fold 5 VAE Epoch 43/150 | β: 0.672 | Train Loss: 0.8447 (MSE: 0.8101, KLD: 0.0514) | Val Loss: 0.8237 (MSE: 0.7911, KLD: 0.0485)\n",
      "2025-05-26 03:57:57 - INFO - 3473208690 - Validation metric improved (0.791114 --> 0.791114). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:00 - INFO - 3473208690 - Fold 5 VAE Epoch 44/150 | β: 0.688 | Train Loss: 0.8358 (MSE: 0.8051, KLD: 0.0446) | Val Loss: 0.8240 (MSE: 0.7853, KLD: 0.0562)\n",
      "2025-05-26 03:58:00 - INFO - 3473208690 - Validation metric improved (0.785320 --> 0.785320). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:03 - INFO - 3473208690 - Fold 5 VAE Epoch 45/150 | β: 0.704 | Train Loss: 0.8330 (MSE: 0.7994, KLD: 0.0477) | Val Loss: 0.8324 (MSE: 0.8001, KLD: 0.0458)\n",
      "2025-05-26 03:58:03 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.785320|Current: 0.800138)\n",
      "2025-05-26 03:58:03 - INFO - 3473208690 - Fold 5 VAE Epoch 46/150 | β: 0.720 | Train Loss: 0.8297 (MSE: 0.7951, KLD: 0.0480) | Val Loss: 0.8278 (MSE: 0.7955, KLD: 0.0449)\n",
      "2025-05-26 03:58:03 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.785320|Current: 0.795453)\n",
      "2025-05-26 03:58:04 - INFO - 3473208690 - Fold 5 VAE Epoch 47/150 | β: 0.736 | Train Loss: 0.8315 (MSE: 0.7989, KLD: 0.0443) | Val Loss: 0.8102 (MSE: 0.7697, KLD: 0.0550)\n",
      "2025-05-26 03:58:04 - INFO - 3473208690 - Validation metric improved (0.769683 --> 0.769683). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:08 - INFO - 3473208690 - Fold 5 VAE Epoch 48/150 | β: 0.752 | Train Loss: 0.8258 (MSE: 0.7880, KLD: 0.0503) | Val Loss: 0.8119 (MSE: 0.7811, KLD: 0.0410)\n",
      "2025-05-26 03:58:08 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.769683|Current: 0.781097)\n",
      "2025-05-26 03:58:08 - INFO - 3473208690 - Fold 5 VAE Epoch 49/150 | β: 0.768 | Train Loss: 0.8182 (MSE: 0.7876, KLD: 0.0398) | Val Loss: 0.8049 (MSE: 0.7720, KLD: 0.0428)\n",
      "2025-05-26 03:58:08 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.769683|Current: 0.772013)\n",
      "2025-05-26 03:58:09 - INFO - 3473208690 - Fold 5 VAE Epoch 50/150 | β: 0.784 | Train Loss: 0.8164 (MSE: 0.7843, KLD: 0.0410) | Val Loss: 0.8120 (MSE: 0.7835, KLD: 0.0364)\n",
      "2025-05-26 03:58:09 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.769683|Current: 0.783482)\n",
      "2025-05-26 03:58:10 - INFO - 3473208690 - Fold 5 VAE Epoch 51/150 | β: 0.800 | Train Loss: 0.8150 (MSE: 0.7836, KLD: 0.0392) | Val Loss: 0.8120 (MSE: 0.7655, KLD: 0.0582)\n",
      "2025-05-26 03:58:10 - INFO - 3473208690 - Validation metric improved (0.765494 --> 0.765494). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:11 - INFO - 3473208690 - Fold 5 VAE Epoch 52/150 | β: 0.800 | Train Loss: 0.8181 (MSE: 0.7812, KLD: 0.0461) | Val Loss: 0.8027 (MSE: 0.7715, KLD: 0.0391)\n",
      "2025-05-26 03:58:11 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.765494|Current: 0.771454)\n",
      "2025-05-26 03:58:11 - INFO - 3473208690 - Fold 5 VAE Epoch 53/150 | β: 0.800 | Train Loss: 0.8104 (MSE: 0.7770, KLD: 0.0417) | Val Loss: 0.7939 (MSE: 0.7634, KLD: 0.0381)\n",
      "2025-05-26 03:58:11 - INFO - 3473208690 - Validation metric improved (0.763386 --> 0.763386). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:12 - INFO - 3473208690 - Fold 5 VAE Epoch 54/150 | β: 0.800 | Train Loss: 0.8119 (MSE: 0.7780, KLD: 0.0424) | Val Loss: 0.7937 (MSE: 0.7663, KLD: 0.0343)\n",
      "2025-05-26 03:58:12 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.763386|Current: 0.766260)\n",
      "2025-05-26 03:58:13 - INFO - 3473208690 - Fold 5 VAE Epoch 55/150 | β: 0.800 | Train Loss: 0.8058 (MSE: 0.7743, KLD: 0.0394) | Val Loss: 0.7975 (MSE: 0.7676, KLD: 0.0373)\n",
      "2025-05-26 03:58:13 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.763386|Current: 0.767642)\n",
      "2025-05-26 03:58:14 - INFO - 3473208690 - Fold 5 VAE Epoch 56/150 | β: 0.800 | Train Loss: 0.7992 (MSE: 0.7687, KLD: 0.0382) | Val Loss: 0.7892 (MSE: 0.7614, KLD: 0.0348)\n",
      "2025-05-26 03:58:14 - INFO - 3473208690 - Validation metric improved (0.761370 --> 0.761370). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:15 - INFO - 3473208690 - Fold 5 VAE Epoch 57/150 | β: 0.800 | Train Loss: 0.7992 (MSE: 0.7693, KLD: 0.0375) | Val Loss: 0.7932 (MSE: 0.7672, KLD: 0.0325)\n",
      "2025-05-26 03:58:15 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.761370|Current: 0.767184)\n",
      "2025-05-26 03:58:15 - INFO - 3473208690 - Fold 5 VAE Epoch 58/150 | β: 0.800 | Train Loss: 0.7986 (MSE: 0.7682, KLD: 0.0380) | Val Loss: 0.7909 (MSE: 0.7642, KLD: 0.0333)\n",
      "2025-05-26 03:58:15 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.761370|Current: 0.764240)\n",
      "2025-05-26 03:58:16 - INFO - 3473208690 - Fold 5 VAE Epoch 59/150 | β: 0.800 | Train Loss: 0.8003 (MSE: 0.7701, KLD: 0.0378) | Val Loss: 0.7892 (MSE: 0.7559, KLD: 0.0416)\n",
      "2025-05-26 03:58:16 - INFO - 3473208690 - Validation metric improved (0.755885 --> 0.755885). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:17 - INFO - 3473208690 - Fold 5 VAE Epoch 60/150 | β: 0.800 | Train Loss: 0.8001 (MSE: 0.7674, KLD: 0.0408) | Val Loss: 0.7868 (MSE: 0.7573, KLD: 0.0368)\n",
      "2025-05-26 03:58:17 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.755885|Current: 0.757319)\n",
      "2025-05-26 03:58:18 - INFO - 3473208690 - Fold 5 VAE Epoch 61/150 | β: 0.800 | Train Loss: 0.7975 (MSE: 0.7654, KLD: 0.0402) | Val Loss: 0.7933 (MSE: 0.7689, KLD: 0.0305)\n",
      "2025-05-26 03:58:18 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.755885|Current: 0.768925)\n",
      "2025-05-26 03:58:19 - INFO - 3473208690 - Fold 5 VAE Epoch 62/150 | β: 0.800 | Train Loss: 0.8005 (MSE: 0.7670, KLD: 0.0418) | Val Loss: 0.7890 (MSE: 0.7632, KLD: 0.0323)\n",
      "2025-05-26 03:58:19 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.755885|Current: 0.763245)\n",
      "2025-05-26 03:58:19 - INFO - 3473208690 - Fold 5 VAE Epoch 63/150 | β: 0.800 | Train Loss: 0.7917 (MSE: 0.7612, KLD: 0.0381) | Val Loss: 0.7830 (MSE: 0.7514, KLD: 0.0395)\n",
      "2025-05-26 03:58:19 - INFO - 3473208690 - Validation metric improved (0.751390 --> 0.751390). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:20 - INFO - 3473208690 - Fold 5 VAE Epoch 64/150 | β: 0.800 | Train Loss: 0.7928 (MSE: 0.7664, KLD: 0.0330) | Val Loss: 0.7836 (MSE: 0.7554, KLD: 0.0352)\n",
      "2025-05-26 03:58:20 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.751390|Current: 0.755438)\n",
      "2025-05-26 03:58:21 - INFO - 3473208690 - Fold 5 VAE Epoch 65/150 | β: 0.800 | Train Loss: 0.7930 (MSE: 0.7620, KLD: 0.0388) | Val Loss: 0.7800 (MSE: 0.7503, KLD: 0.0371)\n",
      "2025-05-26 03:58:21 - INFO - 3473208690 - Validation metric improved (0.750349 --> 0.750349). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:22 - INFO - 3473208690 - Fold 5 VAE Epoch 66/150 | β: 0.800 | Train Loss: 0.7904 (MSE: 0.7615, KLD: 0.0360) | Val Loss: 0.7770 (MSE: 0.7487, KLD: 0.0353)\n",
      "2025-05-26 03:58:22 - INFO - 3473208690 - Validation metric improved (0.748725 --> 0.748725). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:23 - INFO - 3473208690 - Fold 5 VAE Epoch 67/150 | β: 0.800 | Train Loss: 0.7906 (MSE: 0.7601, KLD: 0.0381) | Val Loss: 0.7852 (MSE: 0.7542, KLD: 0.0388)\n",
      "2025-05-26 03:58:23 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.748725|Current: 0.754178)\n",
      "2025-05-26 03:58:24 - INFO - 3473208690 - Fold 5 VAE Epoch 68/150 | β: 0.800 | Train Loss: 0.7878 (MSE: 0.7593, KLD: 0.0356) | Val Loss: 0.7794 (MSE: 0.7548, KLD: 0.0307)\n",
      "2025-05-26 03:58:24 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.748725|Current: 0.754836)\n",
      "2025-05-26 03:58:24 - INFO - 3473208690 - Fold 5 VAE Epoch 69/150 | β: 0.800 | Train Loss: 0.7924 (MSE: 0.7651, KLD: 0.0342) | Val Loss: 0.7781 (MSE: 0.7469, KLD: 0.0390)\n",
      "2025-05-26 03:58:24 - INFO - 3473208690 - Validation metric improved (0.746906 --> 0.746906). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:26 - INFO - 3473208690 - Fold 5 VAE Epoch 70/150 | β: 0.800 | Train Loss: 0.7907 (MSE: 0.7594, KLD: 0.0391) | Val Loss: 0.7748 (MSE: 0.7461, KLD: 0.0358)\n",
      "2025-05-26 03:58:26 - INFO - 3473208690 - Validation metric improved (0.746132 --> 0.746132). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:29 - INFO - 3473208690 - Fold 5 VAE Epoch 71/150 | β: 0.800 | Train Loss: 0.7909 (MSE: 0.7623, KLD: 0.0358) | Val Loss: 0.7850 (MSE: 0.7576, KLD: 0.0342)\n",
      "2025-05-26 03:58:29 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.746132|Current: 0.757632)\n",
      "2025-05-26 03:58:29 - INFO - 3473208690 - Fold 5 VAE Epoch 72/150 | β: 0.800 | Train Loss: 0.7903 (MSE: 0.7626, KLD: 0.0346) | Val Loss: 0.7773 (MSE: 0.7501, KLD: 0.0340)\n",
      "2025-05-26 03:58:29 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.746132|Current: 0.750117)\n",
      "2025-05-26 03:58:30 - INFO - 3473208690 - Fold 5 VAE Epoch 73/150 | β: 0.800 | Train Loss: 0.7923 (MSE: 0.7642, KLD: 0.0351) | Val Loss: 0.7841 (MSE: 0.7563, KLD: 0.0347)\n",
      "2025-05-26 03:58:30 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.746132|Current: 0.756319)\n",
      "2025-05-26 03:58:31 - INFO - 3473208690 - Fold 5 VAE Epoch 74/150 | β: 0.800 | Train Loss: 0.7901 (MSE: 0.7617, KLD: 0.0355) | Val Loss: 0.7809 (MSE: 0.7529, KLD: 0.0351)\n",
      "2025-05-26 03:58:31 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.746132|Current: 0.752864)\n",
      "2025-05-26 03:58:32 - INFO - 3473208690 - Fold 5 VAE Epoch 75/150 | β: 0.800 | Train Loss: 0.8008 (MSE: 0.7652, KLD: 0.0445) | Val Loss: 0.7883 (MSE: 0.7478, KLD: 0.0506)\n",
      "2025-05-26 03:58:32 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.746132|Current: 0.747837)\n",
      "2025-05-26 03:58:32 - INFO - 3473208690 - Fold 5 VAE Epoch 76/150 | β: 0.800 | Train Loss: 0.7978 (MSE: 0.7640, KLD: 0.0422) | Val Loss: 0.8041 (MSE: 0.7762, KLD: 0.0349)\n",
      "2025-05-26 03:58:32 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.746132|Current: 0.776170)\n",
      "2025-05-26 03:58:33 - INFO - 3473208690 - Fold 5 VAE Epoch 77/150 | β: 0.800 | Train Loss: 0.8023 (MSE: 0.7637, KLD: 0.0483) | Val Loss: 0.7976 (MSE: 0.7545, KLD: 0.0539)\n",
      "2025-05-26 03:58:33 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.746132|Current: 0.754494)\n",
      "2025-05-26 03:58:34 - INFO - 3473208690 - Fold 5 VAE Epoch 78/150 | β: 0.800 | Train Loss: 0.8011 (MSE: 0.7619, KLD: 0.0490) | Val Loss: 0.8071 (MSE: 0.7511, KLD: 0.0700)\n",
      "2025-05-26 03:58:34 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.746132|Current: 0.751075)\n",
      "2025-05-26 03:58:34 - INFO - 3473208690 - Fold 5 VAE Epoch 79/150 | β: 0.800 | Train Loss: 0.8009 (MSE: 0.7620, KLD: 0.0486) | Val Loss: 0.7739 (MSE: 0.7370, KLD: 0.0462)\n",
      "2025-05-26 03:58:34 - INFO - 3473208690 - Validation metric improved (0.737000 --> 0.737000). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:37 - INFO - 3473208690 - Fold 5 VAE Epoch 80/150 | β: 0.800 | Train Loss: 0.7857 (MSE: 0.7520, KLD: 0.0420) | Val Loss: 0.7777 (MSE: 0.7474, KLD: 0.0378)\n",
      "2025-05-26 03:58:37 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.737000|Current: 0.747416)\n",
      "2025-05-26 03:58:38 - INFO - 3473208690 - Fold 5 VAE Epoch 81/150 | β: 0.800 | Train Loss: 0.7850 (MSE: 0.7530, KLD: 0.0399) | Val Loss: 0.7736 (MSE: 0.7442, KLD: 0.0367)\n",
      "2025-05-26 03:58:38 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.737000|Current: 0.744182)\n",
      "2025-05-26 03:58:38 - INFO - 3473208690 - Fold 5 VAE Epoch 82/150 | β: 0.800 | Train Loss: 0.7925 (MSE: 0.7602, KLD: 0.0403) | Val Loss: 0.7688 (MSE: 0.7340, KLD: 0.0434)\n",
      "2025-05-26 03:58:38 - INFO - 3473208690 - Validation metric improved (0.734047 --> 0.734047). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:41 - INFO - 3473208690 - Fold 5 VAE Epoch 83/150 | β: 0.800 | Train Loss: 0.7848 (MSE: 0.7467, KLD: 0.0477) | Val Loss: 0.7816 (MSE: 0.7351, KLD: 0.0581)\n",
      "2025-05-26 03:58:41 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.734047|Current: 0.735124)\n",
      "2025-05-26 03:58:41 - INFO - 3473208690 - Fold 5 VAE Epoch 84/150 | β: 0.800 | Train Loss: 0.7826 (MSE: 0.7483, KLD: 0.0428) | Val Loss: 0.7768 (MSE: 0.7454, KLD: 0.0392)\n",
      "2025-05-26 03:58:41 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.734047|Current: 0.745444)\n",
      "2025-05-26 03:58:42 - INFO - 3473208690 - Fold 5 VAE Epoch 85/150 | β: 0.800 | Train Loss: 0.7810 (MSE: 0.7471, KLD: 0.0424) | Val Loss: 0.7675 (MSE: 0.7438, KLD: 0.0297)\n",
      "2025-05-26 03:58:42 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.734047|Current: 0.743775)\n",
      "2025-05-26 03:58:43 - INFO - 3473208690 - Fold 5 VAE Epoch 86/150 | β: 0.800 | Train Loss: 0.7781 (MSE: 0.7467, KLD: 0.0393) | Val Loss: 0.7608 (MSE: 0.7297, KLD: 0.0389)\n",
      "2025-05-26 03:58:43 - INFO - 3473208690 - Validation metric improved (0.729661 --> 0.729661). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:45 - INFO - 3473208690 - Fold 5 VAE Epoch 87/150 | β: 0.800 | Train Loss: 0.7770 (MSE: 0.7450, KLD: 0.0400) | Val Loss: 0.7664 (MSE: 0.7323, KLD: 0.0425)\n",
      "2025-05-26 03:58:45 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.729661|Current: 0.732330)\n",
      "2025-05-26 03:58:46 - INFO - 3473208690 - Fold 5 VAE Epoch 88/150 | β: 0.800 | Train Loss: 0.7735 (MSE: 0.7391, KLD: 0.0430) | Val Loss: 0.7632 (MSE: 0.7308, KLD: 0.0405)\n",
      "2025-05-26 03:58:46 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.729661|Current: 0.730828)\n",
      "2025-05-26 03:58:47 - INFO - 3473208690 - Fold 5 VAE Epoch 89/150 | β: 0.800 | Train Loss: 0.7752 (MSE: 0.7424, KLD: 0.0410) | Val Loss: 0.7633 (MSE: 0.7334, KLD: 0.0373)\n",
      "2025-05-26 03:58:47 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.729661|Current: 0.733429)\n",
      "2025-05-26 03:58:48 - INFO - 3473208690 - Fold 5 VAE Epoch 90/150 | β: 0.800 | Train Loss: 0.7696 (MSE: 0.7378, KLD: 0.0397) | Val Loss: 0.7610 (MSE: 0.7341, KLD: 0.0336)\n",
      "2025-05-26 03:58:48 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.729661|Current: 0.734116)\n",
      "2025-05-26 03:58:48 - INFO - 3473208690 - Fold 5 VAE Epoch 91/150 | β: 0.800 | Train Loss: 0.7702 (MSE: 0.7401, KLD: 0.0377) | Val Loss: 0.7563 (MSE: 0.7274, KLD: 0.0362)\n",
      "2025-05-26 03:58:48 - INFO - 3473208690 - Validation metric improved (0.727373 --> 0.727373). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:50 - INFO - 3473208690 - Fold 5 VAE Epoch 92/150 | β: 0.800 | Train Loss: 0.7678 (MSE: 0.7362, KLD: 0.0394) | Val Loss: 0.7601 (MSE: 0.7350, KLD: 0.0314)\n",
      "2025-05-26 03:58:50 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.727373|Current: 0.734990)\n",
      "2025-05-26 03:58:51 - INFO - 3473208690 - Fold 5 VAE Epoch 93/150 | β: 0.800 | Train Loss: 0.7662 (MSE: 0.7382, KLD: 0.0350) | Val Loss: 0.7634 (MSE: 0.7339, KLD: 0.0369)\n",
      "2025-05-26 03:58:51 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.727373|Current: 0.733871)\n",
      "2025-05-26 03:58:52 - INFO - 3473208690 - Fold 5 VAE Epoch 94/150 | β: 0.800 | Train Loss: 0.7698 (MSE: 0.7402, KLD: 0.0370) | Val Loss: 0.7533 (MSE: 0.7249, KLD: 0.0355)\n",
      "2025-05-26 03:58:52 - INFO - 3473208690 - Validation metric improved (0.724912 --> 0.724912). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:52 - INFO - 3473208690 - Fold 5 VAE Epoch 95/150 | β: 0.800 | Train Loss: 0.7681 (MSE: 0.7354, KLD: 0.0408) | Val Loss: 0.7540 (MSE: 0.7228, KLD: 0.0389)\n",
      "2025-05-26 03:58:52 - INFO - 3473208690 - Validation metric improved (0.722836 --> 0.722836). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt ...\n",
      "2025-05-26 03:58:53 - INFO - 3473208690 - Fold 5 VAE Epoch 96/150 | β: 0.800 | Train Loss: 0.7640 (MSE: 0.7322, KLD: 0.0397) | Val Loss: 0.7554 (MSE: 0.7261, KLD: 0.0366)\n",
      "2025-05-26 03:58:53 - INFO - 3473208690 - EarlyStopping counter: 1 out of 15 (Best: 0.722836|Current: 0.726100)\n",
      "2025-05-26 03:58:54 - INFO - 3473208690 - Fold 5 VAE Epoch 97/150 | β: 0.800 | Train Loss: 0.7599 (MSE: 0.7330, KLD: 0.0336) | Val Loss: 0.7544 (MSE: 0.7265, KLD: 0.0348)\n",
      "2025-05-26 03:58:54 - INFO - 3473208690 - EarlyStopping counter: 2 out of 15 (Best: 0.722836|Current: 0.726516)\n",
      "2025-05-26 03:58:55 - INFO - 3473208690 - Fold 5 VAE Epoch 98/150 | β: 0.800 | Train Loss: 0.7609 (MSE: 0.7307, KLD: 0.0379) | Val Loss: 0.7596 (MSE: 0.7340, KLD: 0.0320)\n",
      "2025-05-26 03:58:55 - INFO - 3473208690 - EarlyStopping counter: 3 out of 15 (Best: 0.722836|Current: 0.734007)\n",
      "2025-05-26 03:58:55 - INFO - 3473208690 - Fold 5 VAE Epoch 99/150 | β: 0.800 | Train Loss: 0.7627 (MSE: 0.7352, KLD: 0.0344) | Val Loss: 0.7527 (MSE: 0.7251, KLD: 0.0345)\n",
      "2025-05-26 03:58:55 - INFO - 3473208690 - EarlyStopping counter: 4 out of 15 (Best: 0.722836|Current: 0.725102)\n",
      "2025-05-26 03:58:56 - INFO - 3473208690 - Fold 5 VAE Epoch 100/150 | β: 0.800 | Train Loss: 0.7615 (MSE: 0.7333, KLD: 0.0353) | Val Loss: 0.7511 (MSE: 0.7237, KLD: 0.0342)\n",
      "2025-05-26 03:58:56 - INFO - 3473208690 - EarlyStopping counter: 5 out of 15 (Best: 0.722836|Current: 0.723678)\n",
      "2025-05-26 03:58:57 - INFO - 3473208690 - Fold 5 VAE Epoch 101/150 | β: 0.800 | Train Loss: 0.7579 (MSE: 0.7312, KLD: 0.0334) | Val Loss: 0.7485 (MSE: 0.7231, KLD: 0.0318)\n",
      "2025-05-26 03:58:57 - INFO - 3473208690 - EarlyStopping counter: 6 out of 15 (Best: 0.722836|Current: 0.723051)\n",
      "2025-05-26 03:58:58 - INFO - 3473208690 - Fold 5 VAE Epoch 102/150 | β: 0.800 | Train Loss: 0.7589 (MSE: 0.7308, KLD: 0.0352) | Val Loss: 0.7558 (MSE: 0.7287, KLD: 0.0339)\n",
      "2025-05-26 03:58:58 - INFO - 3473208690 - EarlyStopping counter: 7 out of 15 (Best: 0.722836|Current: 0.728675)\n",
      "2025-05-26 03:58:58 - INFO - 3473208690 - Fold 5 VAE Epoch 103/150 | β: 0.800 | Train Loss: 0.7590 (MSE: 0.7307, KLD: 0.0354) | Val Loss: 0.7567 (MSE: 0.7275, KLD: 0.0366)\n",
      "2025-05-26 03:58:58 - INFO - 3473208690 - EarlyStopping counter: 8 out of 15 (Best: 0.722836|Current: 0.727471)\n",
      "2025-05-26 03:58:59 - INFO - 3473208690 - Fold 5 VAE Epoch 104/150 | β: 0.800 | Train Loss: 0.7604 (MSE: 0.7307, KLD: 0.0371) | Val Loss: 0.7520 (MSE: 0.7240, KLD: 0.0350)\n",
      "2025-05-26 03:58:59 - INFO - 3473208690 - EarlyStopping counter: 9 out of 15 (Best: 0.722836|Current: 0.724008)\n",
      "2025-05-26 03:59:00 - INFO - 3473208690 - Fold 5 VAE Epoch 105/150 | β: 0.800 | Train Loss: 0.7583 (MSE: 0.7300, KLD: 0.0354) | Val Loss: 0.7540 (MSE: 0.7273, KLD: 0.0334)\n",
      "2025-05-26 03:59:00 - INFO - 3473208690 - EarlyStopping counter: 10 out of 15 (Best: 0.722836|Current: 0.727277)\n",
      "2025-05-26 03:59:01 - INFO - 3473208690 - Fold 5 VAE Epoch 106/150 | β: 0.800 | Train Loss: 0.7588 (MSE: 0.7311, KLD: 0.0347) | Val Loss: 0.7554 (MSE: 0.7290, KLD: 0.0331)\n",
      "2025-05-26 03:59:01 - INFO - 3473208690 - EarlyStopping counter: 11 out of 15 (Best: 0.722836|Current: 0.728980)\n",
      "2025-05-26 03:59:01 - INFO - 3473208690 - Fold 5 VAE Epoch 107/150 | β: 0.800 | Train Loss: 0.7591 (MSE: 0.7319, KLD: 0.0341) | Val Loss: 0.7501 (MSE: 0.7233, KLD: 0.0335)\n",
      "2025-05-26 03:59:01 - INFO - 3473208690 - EarlyStopping counter: 12 out of 15 (Best: 0.722836|Current: 0.723330)\n",
      "2025-05-26 03:59:02 - INFO - 3473208690 - Fold 5 VAE Epoch 108/150 | β: 0.800 | Train Loss: 0.7594 (MSE: 0.7318, KLD: 0.0345) | Val Loss: 0.7532 (MSE: 0.7264, KLD: 0.0335)\n",
      "2025-05-26 03:59:02 - INFO - 3473208690 - EarlyStopping counter: 13 out of 15 (Best: 0.722836|Current: 0.726368)\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - Fold 5 VAE Epoch 109/150 | β: 0.800 | Train Loss: 0.7593 (MSE: 0.7319, KLD: 0.0342) | Val Loss: 0.7510 (MSE: 0.7243, KLD: 0.0334)\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - EarlyStopping counter: 14 out of 15 (Best: 0.722836|Current: 0.724267)\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - Fold 5 VAE Epoch 110/150 | β: 0.800 | Train Loss: 0.7609 (MSE: 0.7334, KLD: 0.0343) | Val Loss: 0.7521 (MSE: 0.7253, KLD: 0.0336)\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - EarlyStopping counter: 15 out of 15 (Best: 0.722836|Current: 0.725273)\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - Early stopping VAE training.\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - Loaded best VAE model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_vae_model.pt\n",
      "2025-05-26 03:59:03 - INFO - 3473208690 - --- Extracting Latent Features (mu only) for Train, Val, Test ---\n",
      "2025-05-26 03:59:04 - INFO - 3473208690 - Loading data from preprocessed_connectomes_for_dl/fold_4/fold_4_preprocessed_data.pt for test split.\n",
      "2025-05-26 03:59:04 - WARNING - 3473208690 - Test split keys not found in preprocessed_connectomes_for_dl/fold_4/fold_4_preprocessed_data.pt. Test set will be empty.\n",
      "2025-05-26 03:59:04 - INFO - 3473208690 - Loaded 0 samples for test split.\n",
      "2025-05-26 03:59:04 - WARNING - 3473208690 - Fold 5: Test dataset is empty. Skipping test set evaluation for this fold.\n",
      "2025-05-26 03:59:04 - INFO - 3473208690 - --- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\n",
      "2025-05-26 03:59:04 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha: [1.0277778 0.9736842]\n",
      "2025-05-26 03:59:05 - INFO - 3473208690 - Validation metric improved (0.413313 --> 0.413313). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:05 - INFO - 3473208690 - Validation metric improved (0.442724 --> 0.442724). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:06 - INFO - 3473208690 - Validation metric improved (0.450464 --> 0.450464). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:06 - INFO - 3473208690 - Validation metric improved (0.492260 --> 0.492260). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:07 - INFO - 3473208690 - Validation metric improved (0.493808 --> 0.493808). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:07 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.493808|Current: 0.493808)\n",
      "2025-05-26 03:59:08 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.493808|Current: 0.482972)\n",
      "2025-05-26 03:59:08 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.493808|Current: 0.493808)\n",
      "2025-05-26 03:59:09 - INFO - 3473208690 - Validation metric improved (0.518576 --> 0.518576). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:09 - INFO - 3473208690 - Validation metric improved (0.537152 --> 0.537152). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:10 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.537152|Current: 0.529412)\n",
      "2025-05-26 03:59:10 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.537152|Current: 0.535604)\n",
      "2025-05-26 03:59:11 - INFO - 3473208690 - Validation metric improved (0.541796 --> 0.541796). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:11 - INFO - 3473208690 - Validation metric improved (0.551084 --> 0.551084). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:12 - INFO - 3473208690 - Validation metric improved (0.563467 --> 0.563467). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:12 - INFO - 3473208690 - Validation metric improved (0.578947 --> 0.578947). Saving model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt ...\n",
      "2025-05-26 03:59:13 - INFO - 3473208690 - EarlyStopping counter: 1 out of 10 (Best: 0.578947|Current: 0.575851)\n",
      "2025-05-26 03:59:13 - INFO - 3473208690 - EarlyStopping counter: 2 out of 10 (Best: 0.578947|Current: 0.572755)\n",
      "2025-05-26 03:59:14 - INFO - 3473208690 - EarlyStopping counter: 3 out of 10 (Best: 0.578947|Current: 0.568111)\n",
      "2025-05-26 03:59:14 - INFO - 3473208690 - EarlyStopping counter: 4 out of 10 (Best: 0.578947|Current: 0.561920)\n",
      "2025-05-26 03:59:15 - INFO - 3473208690 - EarlyStopping counter: 5 out of 10 (Best: 0.578947|Current: 0.575851)\n",
      "2025-05-26 03:59:15 - INFO - 3473208690 - EarlyStopping counter: 6 out of 10 (Best: 0.578947|Current: 0.574303)\n",
      "2025-05-26 03:59:16 - INFO - 3473208690 - EarlyStopping counter: 7 out of 10 (Best: 0.578947|Current: 0.551084)\n",
      "2025-05-26 03:59:16 - INFO - 3473208690 - EarlyStopping counter: 8 out of 10 (Best: 0.578947|Current: 0.563467)\n",
      "2025-05-26 03:59:17 - INFO - 3473208690 - EarlyStopping counter: 9 out of 10 (Best: 0.578947|Current: 0.532508)\n",
      "2025-05-26 03:59:17 - INFO - 3473208690 - EarlyStopping counter: 10 out of 10 (Best: 0.578947|Current: 0.529412)\n",
      "2025-05-26 03:59:17 - INFO - 3473208690 - Early stopping initial classifier training.\n",
      "2025-05-26 03:59:17 - INFO - 3473208690 - Loaded best initial classifier model from training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/best_initial_classifier_model.pt.\n",
      "2025-05-26 03:59:18 - INFO - 3473208690 - Fold 5 Initial Best Classifier Val Metrics: Acc: 0.5556, AUC: 0.5789, F1: 0.5556\n",
      "2025-05-26 03:59:18 - INFO - 3473208690 - --- Classifier Re-training Phase (CN vs AD) on Train+Val ---\n",
      "2025-05-26 03:59:18 - INFO - 3473208690 - Using DYNAMIC FocalLoss alpha for retraining: [1.0337079 0.9684211]\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-05-26 03:59:18 - INFO - 3473208690 - Re-training classifier on combined train+val data for 30 epochs.\n",
      "2025-05-26 03:59:19 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 5/30 | Train Loss: 0.2368, Acc: 0.5109\n",
      "2025-05-26 03:59:21 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 10/30 | Train Loss: 0.2168, Acc: 0.5543\n",
      "2025-05-26 03:59:22 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 15/30 | Train Loss: 0.2311, Acc: 0.5924\n",
      "2025-05-26 03:59:23 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 20/30 | Train Loss: 0.2133, Acc: 0.5598\n",
      "2025-05-26 03:59:25 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 25/30 | Train Loss: 0.1764, Acc: 0.6250\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - Fold 5 CLF Re-train Epoch 30/30 | Train Loss: 0.2051, Acc: 0.5707\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - Saved final classifier model to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/fold_4/final_classifier_model.pt\n",
      "2025-05-26 03:59:26 - WARNING - 3473208690 - Fold 5: Test data latent features are empty. Skipping test set evaluation.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 6/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 5 not found at preprocessed_connectomes_for_dl/fold_5/fold_5_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 7/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 6 not found at preprocessed_connectomes_for_dl/fold_6/fold_6_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 8/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 7 not found at preprocessed_connectomes_for_dl/fold_7/fold_7_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 9/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 8 not found at preprocessed_connectomes_for_dl/fold_8/fold_8_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 10/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 9 not found at preprocessed_connectomes_for_dl/fold_9/fold_9_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 11/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 10 not found at preprocessed_connectomes_for_dl/fold_10/fold_10_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 12/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 11 not found at preprocessed_connectomes_for_dl/fold_11/fold_11_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 13/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 12 not found at preprocessed_connectomes_for_dl/fold_12/fold_12_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 14/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 13 not found at preprocessed_connectomes_for_dl/fold_13/fold_13_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 15/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 14 not found at preprocessed_connectomes_for_dl/fold_14/fold_14_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 16/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 15 not found at preprocessed_connectomes_for_dl/fold_15/fold_15_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 17/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 16 not found at preprocessed_connectomes_for_dl/fold_16/fold_16_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 18/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 17 not found at preprocessed_connectomes_for_dl/fold_17/fold_17_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 19/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 18 not found at preprocessed_connectomes_for_dl/fold_18/fold_18_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- Processing Fold 20/51 ---\n",
      "2025-05-26 03:59:26 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:26 - ERROR - 3473208690 - Preprocessed data for fold 19 not found at preprocessed_connectomes_for_dl/fold_19/fold_19_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 21/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 20 not found at preprocessed_connectomes_for_dl/fold_20/fold_20_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 22/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 21 not found at preprocessed_connectomes_for_dl/fold_21/fold_21_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 23/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 22 not found at preprocessed_connectomes_for_dl/fold_22/fold_22_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 24/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 23 not found at preprocessed_connectomes_for_dl/fold_23/fold_23_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 25/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 24 not found at preprocessed_connectomes_for_dl/fold_24/fold_24_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 26/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 25 not found at preprocessed_connectomes_for_dl/fold_25/fold_25_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 27/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 26 not found at preprocessed_connectomes_for_dl/fold_26/fold_26_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 28/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 27 not found at preprocessed_connectomes_for_dl/fold_27/fold_27_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 29/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 28 not found at preprocessed_connectomes_for_dl/fold_28/fold_28_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 30/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 29 not found at preprocessed_connectomes_for_dl/fold_29/fold_29_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 31/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 30 not found at preprocessed_connectomes_for_dl/fold_30/fold_30_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 32/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 31 not found at preprocessed_connectomes_for_dl/fold_31/fold_31_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 33/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 32 not found at preprocessed_connectomes_for_dl/fold_32/fold_32_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 34/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 33 not found at preprocessed_connectomes_for_dl/fold_33/fold_33_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 35/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 34 not found at preprocessed_connectomes_for_dl/fold_34/fold_34_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 36/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 35 not found at preprocessed_connectomes_for_dl/fold_35/fold_35_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 37/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 36 not found at preprocessed_connectomes_for_dl/fold_36/fold_36_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 38/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 37 not found at preprocessed_connectomes_for_dl/fold_37/fold_37_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 39/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 38 not found at preprocessed_connectomes_for_dl/fold_38/fold_38_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 40/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 39 not found at preprocessed_connectomes_for_dl/fold_39/fold_39_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 41/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 40 not found at preprocessed_connectomes_for_dl/fold_40/fold_40_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 42/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 41 not found at preprocessed_connectomes_for_dl/fold_41/fold_41_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 43/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 42 not found at preprocessed_connectomes_for_dl/fold_42/fold_42_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 44/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 43 not found at preprocessed_connectomes_for_dl/fold_43/fold_43_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 45/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 44 not found at preprocessed_connectomes_for_dl/fold_44/fold_44_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 46/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 45 not found at preprocessed_connectomes_for_dl/fold_45/fold_45_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 47/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 46 not found at preprocessed_connectomes_for_dl/fold_46/fold_46_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 48/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 47 not found at preprocessed_connectomes_for_dl/fold_47/fold_47_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 49/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 48 not found at preprocessed_connectomes_for_dl/fold_48/fold_48_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 50/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 49 not found at preprocessed_connectomes_for_dl/fold_49/fold_49_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Processing Fold 51/51 ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- VAE Training Phase ---\n",
      "2025-05-26 03:59:27 - ERROR - 3473208690 - Preprocessed data for fold 50 not found at preprocessed_connectomes_for_dl/fold_50/fold_50_preprocessed_data.pt. Skipping fold.\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - --- Overall Cross-Validation Results (Validation Set - Initial Classifier) ---\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - Average Validation Accuracy: 0.5165 +/- 0.0221\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - Average Validation AUC:      0.6553 +/- 0.1015\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - Average Validation F1-score: 0.5293 +/- 0.1469\n",
      "2025-05-26 03:59:27 - INFO - 3473208690 - Saved cross-validation summary to training_results_vae_classifier/vae_connectome_clf_run_7_quick_wins/cross_validation_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math \n",
    "\n",
    "# --- 0. Global Configuration and Constants ---\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(module)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Script Configuration ---\n",
    "PREPROCESSED_DATA_BASE_DIR = Path('./preprocessed_connectomes_for_dl')\n",
    "BASE_OUTPUT_DIR = Path('./training_results_vae_classifier')\n",
    "RUN_NAME = \"vae_connectome_clf_run_7_quick_wins\" \n",
    "\n",
    "N_FOLDS = 51\n",
    "RANDOM_STATE = 42\n",
    "LABEL_MAPPING = {'CN': 0, 'MCI': 1, 'LMCI': 1, 'EMCI': 1, 'AD': 2}\n",
    "CLASSIFIER_LABEL_MAPPING = {0: 0, 2: 1} # CN:0, AD:1 for classifier\n",
    "\n",
    "# VAE Hyperparameters\n",
    "VAE_LATENT_DIM = 256\n",
    "VAE_BETA_MAX = 0.8 \n",
    "VAE_BETA_ANNEAL_EPOCHS = 50 # Linear ramp-up, then fixed\n",
    "VAE_LR = 1e-4\n",
    "VAE_WEIGHT_DECAY = 1e-6 \n",
    "VAE_EPOCHS = 150 \n",
    "VAE_BATCH_SIZE = 32\n",
    "VAE_EARLY_STOPPING_PATIENCE = 15 \n",
    "VAE_ENCODER_DROPOUT_RATE = 0.0 # Dropout removed from VAE encoder\n",
    "\n",
    "# Classifier Hyperparameters\n",
    "CLASSIFIER_INPUT_DIM_MULTIPLIER = 1 # Using only mu\n",
    "CLASSIFIER_HIDDEN_DIMS = [128, 64, 32] \n",
    "CLASSIFIER_DROPOUT = 0.2 \n",
    "CLASSIFIER_LR = 1e-4\n",
    "CLASSIFIER_EPOCHS = 150 \n",
    "CLASSIFIER_FINAL_RETRAIN_EPOCHS = 30 \n",
    "CLASSIFIER_BATCH_SIZE = 32\n",
    "CLASSIFIER_EARLY_STOPPING_PATIENCE = 10 \n",
    "# CLASSIFIER_CLASS_WEIGHTS will be calculated dynamically per fold\n",
    "FOCAL_LOSS_GAMMA = 2.0 \n",
    "\n",
    "# Scheduler T0 for CosineAnnealingWarmRestarts\n",
    "VAE_SCHEDULER_T_0 = VAE_EPOCHS // 4 # Approx 4 cycles, can be tuned\n",
    "CLASSIFIER_SCHEDULER_T_0 = 10 # Short cycle for classifier\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "NUM_WORKERS = os.cpu_count() // 2 if os.cpu_count() else 1\n",
    "\n",
    "# --- Reproducibility Utilities ---\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    logger.info(f\"Seeded everything with seed {seed}\")\n",
    "\n",
    "def worker_init_fn(worker_id: int):\n",
    "    worker_seed = RANDOM_STATE + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# --- EarlyStopping Class ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int = 7, verbose: bool = False, delta: float = 0, path: str = 'checkpoint.pt', trace_func=logger.info, mode: str = 'min'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_metric_min_delta = delta\n",
    "        self.path = Path(path)\n",
    "        self.trace_func = trace_func\n",
    "        self.mode = mode.lower()\n",
    "        if self.mode not in ['min', 'max']:\n",
    "            raise ValueError(\"Mode should be 'min' or 'max'.\")\n",
    "        if self.mode == 'min':\n",
    "            self.best_score = np.Inf\n",
    "        else:\n",
    "            self.best_score = -np.Inf\n",
    "\n",
    "    def __call__(self, current_metric_val, model):\n",
    "        score_improved = False\n",
    "        if self.mode == 'min':\n",
    "            if current_metric_val < self.best_score - self.val_metric_min_delta:\n",
    "                self.best_score = current_metric_val\n",
    "                score_improved = True\n",
    "        else: # mode == 'max'\n",
    "            if current_metric_val > self.best_score + self.val_metric_min_delta:\n",
    "                self.best_score = current_metric_val\n",
    "                score_improved = True\n",
    "\n",
    "        if score_improved:\n",
    "            self.save_checkpoint(current_metric_val, model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience} (Best: {self.best_score:.6f}|Current: {current_metric_val:.6f})')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_metric, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation metric improved ({self.best_score:.6f} --> {val_metric:.6f}). Saving model to {self.path} ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "\n",
    "# --- Focal Loss Class ---\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: Optional[torch.Tensor] = None, gamma: float = 2.0, reduction: str = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = nn.functional.cross_entropy(logits, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else: \n",
    "            return focal_loss\n",
    "\n",
    "# --- 1. ConnectomeDataset class ---\n",
    "class ConnectomeDataset(Dataset):\n",
    "    def __init__(self, pt_file: str, split: str = 'train', subject_ids_to_load: Optional[np.ndarray] = None):\n",
    "        logger.info(f\"Loading data from {pt_file} for {split} split.\")\n",
    "        try:\n",
    "            data = torch.load(pt_file, map_location='cpu') \n",
    "            if split == 'test':\n",
    "                required_keys = [f'X_{split}', f'y_{split}', f'{split}_subject_ids']\n",
    "                if not all(key in data for key in required_keys):\n",
    "                    logger.warning(f\"Test split keys not found in {pt_file}. Test set will be empty.\")\n",
    "                    self.X_all = torch.empty(0,4,116,116) # Ensure correct empty tensor shape\n",
    "                    self.y_all = torch.empty(0)\n",
    "                    self.sids_all = np.array([])\n",
    "                else:\n",
    "                    self.X_all = data[f'X_{split}']\n",
    "                    self.y_all = data[f'y_{split}']\n",
    "                    self.sids_all = data[f'{split}_subject_ids']\n",
    "            else:\n",
    "                self.X_all = data[f'X_{split}']\n",
    "                self.y_all = data[f'y_{split}']\n",
    "                self.sids_all = data[f'{split}_subject_ids']\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"File not found: {pt_file}\")\n",
    "            raise\n",
    "        except KeyError as e:\n",
    "            if not (split == 'test' and not all(key in data for key in [f'X_{split}', f'y_{split}', f'{split}_subject_ids'])):\n",
    "                 logger.error(f\"Key error {e} in file {pt_file}. Ensure X_{split}, y_{split}, {split}_subject_ids exist.\")\n",
    "                 raise\n",
    "            \n",
    "        if subject_ids_to_load is not None and len(self.sids_all) > 0:\n",
    "            logger.info(f\"Filtering dataset for {len(subject_ids_to_load)} specific subject IDs.\")\n",
    "            indices_to_keep = np.isin(self.sids_all, subject_ids_to_load)\n",
    "            self.X = self.X_all[indices_to_keep]\n",
    "            self.y = self.y_all[indices_to_keep]\n",
    "            self.sids = self.sids_all[indices_to_keep]\n",
    "            if len(self.X) != len(subject_ids_to_load):\n",
    "                logger.warning(f\"Could not find all requested subject IDs. Found {len(self.X)} out of {len(subject_ids_to_load)}.\")\n",
    "        else:\n",
    "            self.X = self.X_all\n",
    "            self.y = self.y_all\n",
    "            self.sids = self.sids_all\n",
    "        logger.info(f\"Loaded {len(self.X)} samples for {split} split.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0] if isinstance(self.X, torch.Tensor) and self.X.nelement() > 0 else 0\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.sids[idx]\n",
    "\n",
    "class LatentFeatureDataset(Dataset):\n",
    "    def __init__(self, features: torch.Tensor, labels: torch.Tensor, subject_ids: np.ndarray):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.subject_ids = subject_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx], self.subject_ids[idx]\n",
    "\n",
    "# --- 2. VAE Model (ConvVAE for Connectomes) ---\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, input_channels=4, latent_dim=VAE_LATENT_DIM, dropout_rate=VAE_ENCODER_DROPOUT_RATE):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.GroupNorm(8, 32), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout_rate) if dropout_rate > 0 else nn.Identity(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.GroupNorm(16, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout_rate) if dropout_rate > 0 else nn.Identity(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.GroupNorm(32, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout_rate) if dropout_rate > 0 else nn.Identity(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.GroupNorm(64, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout_rate) if dropout_rate > 0 else nn.Identity()\n",
    "        )\n",
    "        self.flatten_size = 256 * 8 * 8\n",
    "        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flatten_size, latent_dim)\n",
    "\n",
    "        self.decoder_fc = nn.Linear(latent_dim, self.flatten_size)\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=0),\n",
    "            nn.GroupNorm(32, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=0),\n",
    "            nn.GroupNorm(16, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.GroupNorm(8, 32), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, input_channels, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "        )\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.encoder_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.decoder_fc(z)\n",
    "        x = x.view(x.size(0), 256, 8, 8)\n",
    "        x_recon = self.decoder_conv(x)\n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar, z\n",
    "\n",
    "# --- 3. VAE Loss Function ---\n",
    "def vae_loss_function(recon_x: torch.Tensor, x: torch.Tensor, mu: torch.Tensor, logvar: torch.Tensor, beta: float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    MSE = nn.functional.mse_loss(recon_x, x, reduction='mean') \n",
    "    KLD = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).mean()\n",
    "    return MSE + beta * KLD, MSE, KLD\n",
    "\n",
    "# --- 4. Classifier Model (SimpleMLP) ---\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int], output_dim: int, dropout_rate: float):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for i, h_dim in enumerate(hidden_dims):\n",
    "            layers.append(torch.nn.utils.weight_norm(nn.Linear(prev_dim, h_dim)))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = h_dim\n",
    "        layers.append(torch.nn.utils.weight_norm(nn.Linear(prev_dim, output_dim)))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)\n",
    "\n",
    "# --- 5. Training and Evaluation Utilities ---\n",
    "def train_vae_epoch(model: ConvVAE, loader: DataLoader, optimizer: optim.Optimizer, device: torch.device, current_beta: float, epoch_num: int, total_epochs: int):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_mse = 0\n",
    "    total_kld = 0\n",
    "    scaler = torch.amp.GradScaler(enabled=(USE_AMP and device.type == 'cuda'))\n",
    "    progress_bar = tqdm(loader, desc=f\"VAE Train Epoch {epoch_num+1}/{total_epochs} (β={current_beta:.3f})\", leave=False)\n",
    "    for batch_idx, (data, _, _) in enumerate(progress_bar):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(USE_AMP and device.type == 'cuda')):\n",
    "            recon_batch, mu, logvar, _ = model(data)\n",
    "            loss, loss_mse, loss_kld = vae_loss_function(recon_batch, data, mu, logvar, current_beta)\n",
    "        if USE_AMP and device.type == 'cuda':\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item()\n",
    "        total_kld += loss_kld.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item(), 'mse': loss_mse.item(), 'kld': loss_kld.item()})\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_mse = total_mse / len(loader)\n",
    "    avg_kld = total_kld / len(loader)\n",
    "    return avg_loss, avg_mse, avg_kld\n",
    "\n",
    "def evaluate_vae_epoch(model: ConvVAE, loader: DataLoader, device: torch.device, current_beta: float, epoch_num: int, total_epochs: int):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mse = 0\n",
    "    total_kld = 0\n",
    "    progress_bar = tqdm(loader, desc=f\"VAE Eval Epoch {epoch_num+1}/{total_epochs}\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for data, _, _ in progress_bar:\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(USE_AMP and device.type == 'cuda')):\n",
    "                recon_batch, mu, logvar, _ = model(data)\n",
    "                loss, loss_mse, loss_kld = vae_loss_function(recon_batch, data, mu, logvar, current_beta)\n",
    "            total_loss += loss.item()\n",
    "            total_mse += loss_mse.item()\n",
    "            total_kld += loss_kld.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item(), 'mse': loss_mse.item(), 'kld': loss_kld.item()})\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_mse = total_mse / len(loader)\n",
    "    avg_kld = total_kld / len(loader)\n",
    "    return avg_loss, avg_mse, avg_kld\n",
    "\n",
    "def extract_latent_features(vae_model: ConvVAE, data_loader: DataLoader, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, np.ndarray]:\n",
    "    vae_model.eval()\n",
    "    all_mu = []\n",
    "    all_logvar = [] # Keep for potential future use, though classifier only uses mu now\n",
    "    all_labels = []\n",
    "    all_sids = []\n",
    "    if len(data_loader.dataset) == 0: \n",
    "        logger.warning(\"extract_latent_features called with an empty DataLoader.\")\n",
    "        return torch.empty(0, VAE_LATENT_DIM), torch.empty(0, VAE_LATENT_DIM), torch.empty(0), np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels, sids in tqdm(data_loader, desc=\"Extracting Latent Features\", leave=False):\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(USE_AMP and device.type == 'cuda')):\n",
    "                mu, logvar = vae_model.encode(data)\n",
    "            all_mu.append(mu.cpu())\n",
    "            all_logvar.append(logvar.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_sids.extend(list(sids)) \n",
    "    return torch.cat(all_mu), torch.cat(all_logvar), torch.cat(all_labels), np.array(all_sids)\n",
    "\n",
    "def train_classifier_epoch(model: SimpleMLP, loader: DataLoader, optimizer: optim.Optimizer, criterion, device: torch.device, epoch_num: int, total_epochs: int, use_scheduler: bool, scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    scaler = torch.amp.GradScaler(enabled=(USE_AMP and device.type == 'cuda'))\n",
    "    progress_bar = tqdm(loader, desc=f\"CLF Train Epoch {epoch_num+1}/{total_epochs}\", leave=False)\n",
    "    for features, labels, _ in progress_bar:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(USE_AMP and device.type == 'cuda')):\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "        if USE_AMP and device.type == 'cuda':\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if use_scheduler and scheduler is not None and not isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "             scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        progress_bar.set_postfix({'loss': loss.item(), 'acc': (predicted == labels).sum().item()/labels.size(0)})\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else 0\n",
    "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_classifier(model: SimpleMLP, loader: DataLoader, criterion, device: torch.device, desc_prefix: str = \"Evaluating\") -> Dict:\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probabilities = [] \n",
    "    if len(loader.dataset) == 0:\n",
    "        logger.warning(f\"{desc_prefix} Classifier called with an empty DataLoader.\")\n",
    "        return {\"loss\": 0, \"accuracy\": 0, \"auc\": 0, \"f1\": 0, \"labels\": [], \"predictions\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels, _ in tqdm(loader, desc=f\"{desc_prefix} Classifier\", leave=False):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(USE_AMP and device.type == 'cuda')):\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probabilities.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else 0\n",
    "    accuracy = accuracy_score(all_labels, all_predictions) if len(all_labels) > 0 else 0\n",
    "    auc = 0.0\n",
    "    if len(np.unique(all_labels)) < 2:\n",
    "        if len(all_labels) > 0: logger.warning(f\"{desc_prefix} AUC calculation skipped: only one class present in evaluation.\")\n",
    "    elif len(all_probabilities) == 0:\n",
    "         logger.warning(f\"{desc_prefix} AUC calculation skipped: no probabilities to evaluate.\")\n",
    "    else:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_labels, np.array(all_probabilities)[:, 1])\n",
    "        except ValueError as e:\n",
    "            logger.warning(f\"{desc_prefix} Could not calculate AUC: {e}.\")\n",
    "            auc = 0.0\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary', zero_division=0) if len(all_labels) > 0 else 0\n",
    "    return {\"loss\": avg_loss, \"accuracy\": accuracy, \"auc\": auc, \"f1\": f1, \"labels\": all_labels, \"predictions\": all_predictions}\n",
    "\n",
    "# --- 6. Main Script Logic ---\n",
    "def main():\n",
    "    seed_everything(RANDOM_STATE)\n",
    "    logger.info(f\"Device: {DEVICE}\")\n",
    "    logger.info(f\"Using AMP: {USE_AMP}\")\n",
    "    logger.info(f\"Number of workers for DataLoader: {NUM_WORKERS}\")\n",
    "\n",
    "    run_output_dir = BASE_OUTPUT_DIR / RUN_NAME\n",
    "    run_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Outputs will be saved to: {run_output_dir}\")\n",
    "\n",
    "    config_summary = {k: v for k, v in globals().items() if k.isupper() and isinstance(v, (int, float, str, list, tuple, bool, dict))}\n",
    "    config_summary[\"DEVICE\"] = str(DEVICE)\n",
    "    with open(run_output_dir / \"config_summary.txt\", 'w') as f:\n",
    "        for key, value in config_summary.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    logger.info(f\"Saved run configuration to {run_output_dir / 'config_summary.txt'}\")\n",
    "    logger.warning(\"Stratification by sex/age should be handled during the preprocessing step that creates the .pt files.\")\n",
    "\n",
    "    overall_fold_val_metrics = []\n",
    "    overall_fold_test_metrics = []\n",
    "\n",
    "    for fold_idx in range(N_FOLDS):\n",
    "        logger.info(f\"--- Processing Fold {fold_idx + 1}/{N_FOLDS} ---\")\n",
    "        fold_output_dir = run_output_dir / f\"fold_{fold_idx}\"\n",
    "        fold_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        tb_writer_fold = SummaryWriter(log_dir=str(fold_output_dir / \"tensorboard\"))\n",
    "\n",
    "        logger.info(\"--- VAE Training Phase ---\")\n",
    "        preprocessed_fold_file = PREPROCESSED_DATA_BASE_DIR / f\"fold_{fold_idx}\" / f\"fold_{fold_idx}_preprocessed_data.pt\"\n",
    "        if not preprocessed_fold_file.exists():\n",
    "            logger.error(f\"Preprocessed data for fold {fold_idx} not found at {preprocessed_fold_file}. Skipping fold.\")\n",
    "            continue\n",
    "\n",
    "        vae_train_dataset = ConnectomeDataset(str(preprocessed_fold_file), 'train')\n",
    "        vae_val_dataset = ConnectomeDataset(str(preprocessed_fold_file), 'val')\n",
    "        _worker_init_fn = worker_init_fn if NUM_WORKERS > 0 else None\n",
    "        vae_train_loader = DataLoader(vae_train_dataset, batch_size=VAE_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, worker_init_fn=_worker_init_fn)\n",
    "        vae_val_loader = DataLoader(vae_val_dataset, batch_size=VAE_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, worker_init_fn=_worker_init_fn)\n",
    "\n",
    "        vae_model = ConvVAE(input_channels=4, latent_dim=VAE_LATENT_DIM, dropout_rate=VAE_ENCODER_DROPOUT_RATE).to(DEVICE)\n",
    "        vae_optimizer = optim.AdamW(vae_model.parameters(), lr=VAE_LR, weight_decay=VAE_WEIGHT_DECAY)\n",
    "        vae_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(vae_optimizer, T_0=VAE_SCHEDULER_T_0, T_mult=1, eta_min=1e-7, verbose=False)\n",
    "        \n",
    "        vae_model_path = fold_output_dir / \"best_vae_model.pt\"\n",
    "        vae_early_stopper = EarlyStopping(patience=VAE_EARLY_STOPPING_PATIENCE, verbose=True, path=vae_model_path, mode='min') # Monitor val_mse\n",
    "\n",
    "        for epoch in range(VAE_EPOCHS):\n",
    "            # Linear ramp-up for beta then fixed\n",
    "            if epoch < VAE_BETA_ANNEAL_EPOCHS:\n",
    "                current_beta = VAE_BETA_MAX * (epoch / VAE_BETA_ANNEAL_EPOCHS)\n",
    "            else:\n",
    "                current_beta = VAE_BETA_MAX\n",
    "            \n",
    "            train_loss, train_mse, train_kld = train_vae_epoch(vae_model, vae_train_loader, vae_optimizer, DEVICE, current_beta, epoch, VAE_EPOCHS)\n",
    "            val_loss, val_mse, val_kld = evaluate_vae_epoch(vae_model, vae_val_loader, DEVICE, current_beta, epoch, VAE_EPOCHS)\n",
    "            logger.info(f\"Fold {fold_idx+1} VAE Epoch {epoch+1}/{VAE_EPOCHS} | β: {current_beta:.3f} | Train Loss: {train_loss:.4f} (MSE: {train_mse:.4f}, KLD: {train_kld:.4f}) | Val Loss: {val_loss:.4f} (MSE: {val_mse:.4f}, KLD: {val_kld:.4f})\")\n",
    "            tb_writer_fold.add_scalar(\"VAE/Train_Loss\", train_loss, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Train_MSE\", train_mse, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Train_KLD\", train_kld, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Val_Loss\", val_loss, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Val_MSE\", val_mse, epoch) \n",
    "            tb_writer_fold.add_scalar(\"VAE/Val_KLD\", val_kld, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Beta\", current_beta, epoch)\n",
    "            tb_writer_fold.add_scalar(\"VAE/Learning_Rate\", vae_optimizer.param_groups[0]['lr'], epoch)\n",
    "            \n",
    "            vae_scheduler.step() \n",
    "            vae_early_stopper(val_mse, vae_model) \n",
    "            if vae_early_stopper.early_stop:\n",
    "                logger.info(\"Early stopping VAE training.\")\n",
    "                break\n",
    "        \n",
    "        vae_model.load_state_dict(torch.load(vae_model_path, map_location=DEVICE, weights_only=True))\n",
    "        logger.info(f\"Loaded best VAE model from {vae_model_path}\")\n",
    "\n",
    "        logger.info(\"--- Extracting Latent Features (mu only) for Train, Val, Test ---\")\n",
    "        # Prepare extraction loaders\n",
    "        extract_train_loader = DataLoader(\n",
    "            vae_train_dataset,\n",
    "            batch_size=VAE_BATCH_SIZE * 2,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=_worker_init_fn\n",
    "        )\n",
    "        extract_val_loader = DataLoader(\n",
    "            vae_val_dataset,\n",
    "            batch_size=VAE_BATCH_SIZE * 2,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=_worker_init_fn\n",
    "        )\n",
    "\n",
    "        train_mu, _, train_orig_labels, train_sids = extract_latent_features(\n",
    "            vae_model, extract_train_loader, DEVICE\n",
    "        )\n",
    "        val_mu,   _, val_orig_labels,   val_sids   = extract_latent_features(\n",
    "            vae_model, extract_val_loader,   DEVICE\n",
    "        )\n",
    "\n",
    "        \n",
    "        vae_test_dataset = ConnectomeDataset(str(preprocessed_fold_file), 'test')\n",
    "        test_mu, _, test_orig_labels, test_sids = torch.empty(0, VAE_LATENT_DIM), torch.empty(0, VAE_LATENT_DIM), torch.empty(0), np.array([])\n",
    "        if len(vae_test_dataset) > 0:\n",
    "            extract_test_loader = DataLoader(vae_test_dataset, batch_size=VAE_BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, worker_init_fn=_worker_init_fn)\n",
    "            test_mu, _, test_orig_labels, test_sids = extract_latent_features(vae_model, extract_test_loader, DEVICE)\n",
    "        else:\n",
    "            logger.warning(f\"Fold {fold_idx+1}: Test dataset is empty. Skipping test set evaluation for this fold.\")\n",
    "\n",
    "        # Use only mu for classifier features\n",
    "        train_clf_latent_features = train_mu\n",
    "        val_clf_latent_features = val_mu\n",
    "        test_clf_latent_features = test_mu if test_mu.nelement() > 0 else torch.empty(0, VAE_LATENT_DIM)\n",
    "\n",
    "\n",
    "        logger.info(\"--- Initial Classifier Training Phase (CN vs AD) on Train, Validate on Val ---\")\n",
    "        train_cn_ad_mask = (train_orig_labels == LABEL_MAPPING['CN']) | (train_orig_labels == LABEL_MAPPING['AD'])\n",
    "        clf_train_features_filtered = train_clf_latent_features[train_cn_ad_mask]\n",
    "        clf_train_sids_initial = train_sids[train_cn_ad_mask]\n",
    "        clf_train_labels_initial = torch.tensor([CLASSIFIER_LABEL_MAPPING[l.item()] for l in train_orig_labels[train_cn_ad_mask]], dtype=torch.long)\n",
    "        \n",
    "        val_cn_ad_mask = (val_orig_labels == LABEL_MAPPING['CN']) | (val_orig_labels == LABEL_MAPPING['AD'])\n",
    "        clf_val_features_filtered = val_clf_latent_features[val_cn_ad_mask]\n",
    "        clf_val_sids_initial = val_sids[val_cn_ad_mask]\n",
    "        clf_val_labels_initial = torch.tensor([CLASSIFIER_LABEL_MAPPING[l.item()] for l in val_orig_labels[val_cn_ad_mask]], dtype=torch.long)\n",
    "\n",
    "        if len(clf_train_features_filtered) == 0 or len(clf_val_features_filtered) == 0:\n",
    "            logger.warning(f\"Fold {fold_idx+1}: Not enough CN/AD samples for initial classifier training. Skipping classifier steps for this fold.\")\n",
    "            overall_fold_test_metrics.append({\"accuracy\": 0, \"auc\": 0, \"f1\": 0}) \n",
    "            overall_fold_val_metrics.append({\"accuracy\": 0, \"auc\": 0, \"f1\": 0}) \n",
    "            tb_writer_fold.close()\n",
    "            gc.collect()\n",
    "            if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "            continue \n",
    "        \n",
    "        clf_train_dataset_initial = LatentFeatureDataset(clf_train_features_filtered, clf_train_labels_initial, clf_train_sids_initial)\n",
    "        clf_val_dataset_initial = LatentFeatureDataset(clf_val_features_filtered, clf_val_labels_initial, clf_val_sids_initial)\n",
    "        \n",
    "        # WeightedRandomSampler for initial classifier training\n",
    "        class_counts = np.bincount(clf_train_labels_initial.numpy())\n",
    "        if len(class_counts) < 2 : # Handle cases where one class might be missing after filtering\n",
    "            logger.warning(f\"Fold {fold_idx+1}: Only one class present in initial classifier training data. Sampler not used.\")\n",
    "            sampler = None\n",
    "            # Calculate dynamic class weights for FocalLoss, or use default if issues\n",
    "            if len(class_counts) == 1 and class_counts[0] == len(clf_train_labels_initial): # Only one class\n",
    "                 class_weights_tensor_alpha = None # No weights if only one class\n",
    "                 logger.warning(\"Only one class for classifier, FocalLoss alpha will be None.\")\n",
    "            else: # Should not happen if bincount < 2 but not 1. Defaulting.\n",
    "                 class_weights_tensor_alpha = torch.tensor(CLASSIFIER_CLASS_WEIGHTS, dtype=torch.float).to(DEVICE)\n",
    "                 logger.warning(\"Issue with class counts for FocalLoss, using default weights.\")\n",
    "\n",
    "        else:\n",
    "            weights_sampler = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "            sample_weights = weights_sampler[clf_train_labels_initial]\n",
    "            sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "            \n",
    "            # Dynamic class weights for FocalLoss alpha\n",
    "            class_weights_tensor_alpha = (len(clf_train_labels_initial) / (2 * torch.tensor(class_counts, dtype=torch.float))).to(DEVICE)\n",
    "            logger.info(f\"Using DYNAMIC FocalLoss alpha: {class_weights_tensor_alpha.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "        clf_train_loader_initial = DataLoader(clf_train_dataset_initial, batch_size=CLASSIFIER_BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, worker_init_fn=_worker_init_fn) # shuffle=False if sampler is used\n",
    "        clf_val_loader_initial = DataLoader(clf_val_dataset_initial, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, worker_init_fn=_worker_init_fn)\n",
    "\n",
    "        initial_classifier_model = SimpleMLP(\n",
    "            input_dim=VAE_LATENT_DIM * CLASSIFIER_INPUT_DIM_MULTIPLIER,\n",
    "            hidden_dims=CLASSIFIER_HIDDEN_DIMS, output_dim=2, dropout_rate=CLASSIFIER_DROPOUT\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        clf_criterion_initial = FocalLoss(alpha=class_weights_tensor_alpha, gamma=FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        clf_optimizer_initial = optim.AdamW(initial_classifier_model.parameters(), lr=CLASSIFIER_LR)\n",
    "        clf_scheduler_initial = optim.lr_scheduler.CosineAnnealingWarmRestarts(clf_optimizer_initial, T_0=CLASSIFIER_SCHEDULER_T_0, T_mult=1, eta_min=1e-7, verbose=False)\n",
    "        \n",
    "        clf_model_path_initial = fold_output_dir / \"best_initial_classifier_model.pt\"\n",
    "        clf_early_stopper_initial = EarlyStopping(patience=CLASSIFIER_EARLY_STOPPING_PATIENCE, verbose=True, path=clf_model_path_initial, mode='max')\n",
    "\n",
    "        for epoch in range(CLASSIFIER_EPOCHS):\n",
    "            train_clf_loss, train_clf_acc = train_classifier_epoch(initial_classifier_model, clf_train_loader_initial, clf_optimizer_initial, clf_criterion_initial, DEVICE, epoch, CLASSIFIER_EPOCHS, True, clf_scheduler_initial)\n",
    "            val_metrics = evaluate_classifier(initial_classifier_model, clf_val_loader_initial, clf_criterion_initial, DEVICE, desc_prefix=\"Initial Val\")\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Train_Loss\", train_clf_loss, epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Train_Acc\", train_clf_acc, epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Val_Loss\", val_metrics['loss'], epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Val_Acc\", val_metrics['accuracy'], epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Val_AUC\", val_metrics['auc'], epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Val_F1\", val_metrics['f1'], epoch)\n",
    "            tb_writer_fold.add_scalar(\"Initial_Classifier/Learning_Rate\", clf_optimizer_initial.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            clf_early_stopper_initial(val_metrics['auc'], initial_classifier_model)\n",
    "            if clf_early_stopper_initial.early_stop:\n",
    "                logger.info(\"Early stopping initial classifier training.\")\n",
    "                break\n",
    "        \n",
    "        initial_classifier_model.load_state_dict(torch.load(clf_model_path_initial, map_location=DEVICE, weights_only=True))\n",
    "        logger.info(f\"Loaded best initial classifier model from {clf_model_path_initial}.\")\n",
    "        fold_val_metrics = evaluate_classifier(initial_classifier_model, clf_val_loader_initial, clf_criterion_initial, DEVICE, desc_prefix=\"Final Val (from initial train)\")\n",
    "        overall_fold_val_metrics.append(fold_val_metrics)\n",
    "        logger.info(f\"Fold {fold_idx+1} Initial Best Classifier Val Metrics: Acc: {fold_val_metrics['accuracy']:.4f}, AUC: {fold_val_metrics['auc']:.4f}, F1: {fold_val_metrics['f1']:.4f}\")\n",
    "\n",
    "        logger.info(\"--- Classifier Re-training Phase (CN vs AD) on Train+Val ---\")\n",
    "        all_train_val_features = torch.cat((clf_train_features_filtered, clf_val_features_filtered), dim=0)\n",
    "        all_train_val_labels = torch.cat((clf_train_labels_initial, clf_val_labels_initial), dim=0)\n",
    "        all_train_val_sids = np.concatenate((clf_train_sids_initial, clf_val_sids_initial))\n",
    "\n",
    "        clf_train_val_dataset = LatentFeatureDataset(all_train_val_features, all_train_val_labels, all_train_val_sids)\n",
    "        \n",
    "        # Re-calculate sampler and weights for combined train+val dataset for FocalLoss alpha\n",
    "        class_counts_retrain = np.bincount(all_train_val_labels.numpy())\n",
    "        if len(class_counts_retrain) < 2:\n",
    "            logger.warning(f\"Fold {fold_idx+1}: Only one class present in combined train+val data. Sampler not used for retraining.\")\n",
    "            sampler_retrain = None\n",
    "            if len(class_counts_retrain) == 1 and class_counts_retrain[0] == len(all_train_val_labels):\n",
    "                 class_weights_tensor_alpha_retrain = None\n",
    "                 logger.warning(\"Only one class for retrain classifier, FocalLoss alpha will be None.\")\n",
    "            else:\n",
    "                 class_weights_tensor_alpha_retrain = torch.tensor(CLASSIFIER_CLASS_WEIGHTS, dtype=torch.float).to(DEVICE) # Fallback\n",
    "                 logger.warning(\"Issue with class counts for retrain FocalLoss, using default weights.\")\n",
    "        else:\n",
    "            weights_sampler_retrain = 1. / torch.tensor(class_counts_retrain, dtype=torch.float)\n",
    "            sample_weights_retrain = weights_sampler_retrain[all_train_val_labels]\n",
    "            sampler_retrain = WeightedRandomSampler(sample_weights_retrain, len(sample_weights_retrain), replacement=True)\n",
    "            class_weights_tensor_alpha_retrain = (len(all_train_val_labels) / (2 * torch.tensor(class_counts_retrain, dtype=torch.float))).to(DEVICE)\n",
    "            logger.info(f\"Using DYNAMIC FocalLoss alpha for retraining: {class_weights_tensor_alpha_retrain.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "        clf_train_val_loader = DataLoader(clf_train_val_dataset, batch_size=CLASSIFIER_BATCH_SIZE, sampler=sampler_retrain, num_workers=NUM_WORKERS, worker_init_fn=_worker_init_fn)\n",
    "\n",
    "        final_classifier_model = SimpleMLP(\n",
    "            input_dim=VAE_LATENT_DIM * CLASSIFIER_INPUT_DIM_MULTIPLIER,\n",
    "            hidden_dims=CLASSIFIER_HIDDEN_DIMS, output_dim=2, dropout_rate=CLASSIFIER_DROPOUT\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        clf_criterion_final = FocalLoss(alpha=class_weights_tensor_alpha_retrain, gamma=FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        clf_optimizer_final = optim.AdamW(final_classifier_model.parameters(), lr=CLASSIFIER_LR)\n",
    "        clf_scheduler_final = optim.lr_scheduler.CosineAnnealingWarmRestarts(clf_optimizer_final, T_0=CLASSIFIER_FINAL_RETRAIN_EPOCHS, T_mult=1, eta_min=1e-7, verbose=False)\n",
    "\n",
    "        logger.info(f\"Re-training classifier on combined train+val data for {CLASSIFIER_FINAL_RETRAIN_EPOCHS} epochs.\")\n",
    "        for epoch in range(CLASSIFIER_FINAL_RETRAIN_EPOCHS):\n",
    "            train_loss, train_acc = train_classifier_epoch(final_classifier_model, clf_train_val_loader, clf_optimizer_final, clf_criterion_final, DEVICE, epoch, CLASSIFIER_FINAL_RETRAIN_EPOCHS, True, clf_scheduler_final)\n",
    "            tb_writer_fold.add_scalar(\"Final_Classifier/Train_Loss\", train_loss, epoch)\n",
    "            tb_writer_fold.add_scalar(\"Final_Classifier/Train_Acc\", train_acc, epoch)\n",
    "            tb_writer_fold.add_scalar(\"Final_Classifier/Learning_Rate\", clf_optimizer_final.param_groups[0]['lr'], epoch)\n",
    "            if (epoch + 1) % 5 == 0 or epoch == CLASSIFIER_FINAL_RETRAIN_EPOCHS -1 :\n",
    "                 logger.info(f\"Fold {fold_idx+1} CLF Re-train Epoch {epoch+1}/{CLASSIFIER_FINAL_RETRAIN_EPOCHS} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        \n",
    "        torch.save(final_classifier_model.state_dict(), fold_output_dir / \"final_classifier_model.pt\")\n",
    "        logger.info(f\"Saved final classifier model to {fold_output_dir / 'final_classifier_model.pt'}\")\n",
    "\n",
    "        if len(test_clf_latent_features) > 0 and test_clf_latent_features.nelement() > 0 and len(test_orig_labels) > 0:\n",
    "            logger.info(\"--- Evaluating Final Classifier on Test Set ---\")\n",
    "            test_cn_ad_mask = (test_orig_labels == LABEL_MAPPING['CN']) | (test_orig_labels == LABEL_MAPPING['AD'])\n",
    "            clf_test_features_filtered = test_clf_latent_features[test_cn_ad_mask]\n",
    "            clf_test_sids_filtered = test_sids[test_cn_ad_mask]\n",
    "            clf_test_labels_filtered = torch.tensor([CLASSIFIER_LABEL_MAPPING[l.item()] for l in test_orig_labels[test_cn_ad_mask] if l.item() in CLASSIFIER_LABEL_MAPPING], dtype=torch.long)\n",
    "\n",
    "            if len(clf_test_features_filtered) > 0 and len(clf_test_labels_filtered) > 0:\n",
    "                clf_test_dataset = LatentFeatureDataset(clf_test_features_filtered, clf_test_labels_filtered, clf_test_sids_filtered)\n",
    "                clf_test_loader = DataLoader(clf_test_dataset, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, worker_init_fn=_worker_init_fn)\n",
    "                \n",
    "                test_metrics = evaluate_classifier(final_classifier_model, clf_test_loader, clf_criterion_final, DEVICE, desc_prefix=\"Test Set\")\n",
    "                logger.info(f\"Fold {fold_idx+1} TEST SET METRICS: Acc: {test_metrics['accuracy']:.4f}, AUC: {test_metrics['auc']:.4f}, F1: {test_metrics['f1']:.4f}\")\n",
    "                overall_fold_test_metrics.append(test_metrics)\n",
    "                \n",
    "                tb_writer_fold.add_scalar(\"Test_Set/Accuracy\", test_metrics['accuracy'])\n",
    "                tb_writer_fold.add_scalar(\"Test_Set/AUC\", test_metrics['auc'])\n",
    "                tb_writer_fold.add_scalar(\"Test_Set/F1\", test_metrics['f1'])\n",
    "                cm_test = confusion_matrix(test_metrics['labels'], test_metrics['predictions'])\n",
    "                logger.info(f\"Fold {fold_idx+1} Test Set Confusion Matrix (CN vs AD):\\n{cm_test}\")\n",
    "            else:\n",
    "                logger.warning(f\"Fold {fold_idx+1}: No CN/AD samples in the test set after filtering. Skipping test evaluation.\")\n",
    "                overall_fold_test_metrics.append({\"accuracy\": 0, \"auc\": 0, \"f1\": 0}) \n",
    "        else:\n",
    "            logger.warning(f\"Fold {fold_idx+1}: Test data latent features are empty. Skipping test set evaluation.\")\n",
    "            overall_fold_test_metrics.append({\"accuracy\": 0, \"auc\": 0, \"f1\": 0}) \n",
    "\n",
    "        tb_writer_fold.close()\n",
    "        gc.collect()\n",
    "        if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "    \n",
    "    if not overall_fold_val_metrics:\n",
    "        logger.error(\"No folds completed initial classifier training. Cannot aggregate validation results.\")\n",
    "    else:\n",
    "        avg_val_acc = np.mean([m['accuracy'] for m in overall_fold_val_metrics])\n",
    "        avg_val_auc = np.mean([m['auc'] for m in overall_fold_val_metrics])\n",
    "        avg_val_f1 = np.mean([m['f1'] for m in overall_fold_val_metrics])\n",
    "        std_val_acc = np.std([m['accuracy'] for m in overall_fold_val_metrics])\n",
    "        std_val_auc = np.std([m['auc'] for m in overall_fold_val_metrics])\n",
    "        std_val_f1 = np.std([m['f1'] for m in overall_fold_val_metrics])\n",
    "\n",
    "        logger.info(\"--- Overall Cross-Validation Results (Validation Set - Initial Classifier) ---\")\n",
    "        logger.info(f\"Average Validation Accuracy: {avg_val_acc:.4f} +/- {std_val_acc:.4f}\")\n",
    "        logger.info(f\"Average Validation AUC:      {avg_val_auc:.4f} +/- {std_val_auc:.4f}\")\n",
    "        logger.info(f\"Average Validation F1-score: {avg_val_f1:.4f} +/- {std_val_f1:.4f}\")\n",
    "\n",
    "        results_summary_path = run_output_dir / \"cross_validation_summary.txt\"\n",
    "        with open(results_summary_path, 'w') as f:\n",
    "            f.write(\"--- Overall Cross-Validation Results (Validation Set - Initial Classifier) ---\\n\")\n",
    "            f.write(f\"Average Validation Accuracy: {avg_val_acc:.4f} +/- {std_val_acc:.4f}\\n\")\n",
    "            f.write(f\"Average Validation AUC:      {avg_val_auc:.4f} +/- {std_val_auc:.4f}\\n\")\n",
    "            f.write(f\"Average Validation F1-score: {avg_val_f1:.4f} +/- {std_val_f1:.4f}\\n\\n\")\n",
    "            f.write(\"Individual Fold Validation Metrics (Initial Classifier):\\n\")\n",
    "            for i, metrics in enumerate(overall_fold_val_metrics):\n",
    "                f.write(f\"Fold {i+1}: Acc={metrics['accuracy']:.4f}, AUC={metrics['auc']:.4f}, F1={metrics['f1']:.4f}\\n\")\n",
    "            \n",
    "            if overall_fold_test_metrics and any(m['auc'] > 0 or m['accuracy'] > 0 for m in overall_fold_test_metrics):\n",
    "                # Filter out placeholder metrics before calculating mean/std for test\n",
    "                valid_test_metrics = [m for m in overall_fold_test_metrics if m['auc'] > 0 or m['accuracy'] > 0]\n",
    "                if valid_test_metrics:\n",
    "                    avg_test_acc = np.mean([m['accuracy'] for m in valid_test_metrics])\n",
    "                    avg_test_auc = np.mean([m['auc'] for m in valid_test_metrics])\n",
    "                    avg_test_f1 = np.mean([m['f1'] for m in valid_test_metrics])\n",
    "                    std_test_acc = np.std([m['accuracy'] for m in valid_test_metrics])\n",
    "                    std_test_auc = np.std([m['auc'] for m in valid_test_metrics])\n",
    "                    std_test_f1 = np.std([m['f1'] for m in valid_test_metrics])\n",
    "                    \n",
    "                    f.write(\"\\n--- Overall Cross-Validation Results (Test Set - Final Classifier) ---\\n\")\n",
    "                    f.write(f\"Average Test Accuracy: {avg_test_acc:.4f} +/- {std_test_acc:.4f}\\n\")\n",
    "                    f.write(f\"Average Test AUC:      {avg_test_auc:.4f} +/- {std_test_auc:.4f}\\n\")\n",
    "                    f.write(f\"Average Test F1-score: {avg_test_f1:.4f} +/- {std_test_f1:.4f}\\n\\n\")\n",
    "                    f.write(\"Individual Fold Test Metrics (Final Classifier):\\n\")\n",
    "                    for i, metrics in enumerate(overall_fold_test_metrics): # Log all, including placeholders\n",
    "                         f.write(f\"Fold {i+1}: Acc={metrics['accuracy']:.4f}, AUC={metrics['auc']:.4f}, F1={metrics['f1']:.4f}\\n\")\n",
    "                else:\n",
    "                    f.write(\"\\n--- No Valid Test Set Results to Report ---\\n\")\n",
    "            else:\n",
    "                f.write(\"\\n--- No Test Set Results to Report ---\\n\")\n",
    "        logger.info(f\"Saved cross-validation summary to {results_summary_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        import torch\n",
    "        logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "    except ImportError:\n",
    "        logger.critical(\"PyTorch is not installed. Please install PyTorch to run this script.\")\n",
    "        exit()\n",
    "    \n",
    "    if not PREPROCESSED_DATA_BASE_DIR.exists():\n",
    "        logger.critical(f\"Preprocessed data directory not found: {PREPROCESSED_DATA_BASE_DIR}\")\n",
    "        logger.critical(\"Please run the preprocessing script first.\")\n",
    "        exit()\n",
    "\n",
    "    found_any_fold_data = any(\n",
    "        (PREPROCESSED_DATA_BASE_DIR / f\"fold_{i}\" / f\"fold_{i}_preprocessed_data.pt\").exists()\n",
    "        for i in range(N_FOLDS)\n",
    "    )\n",
    "    if not found_any_fold_data and N_FOLDS > 0 :\n",
    "         logger.critical(f\"No preprocessed fold data found in subdirectories under {PREPROCESSED_DATA_BASE_DIR} for the configured N_FOLDS={N_FOLDS}\")\n",
    "         logger.critical(\"Example expected path for fold 0: preprocessed_connectomes_for_dl/fold_0/fold_0_preprocessed_data.pt\")\n",
    "         exit()\n",
    "    elif N_FOLDS == 0:\n",
    "        logger.warning(\"N_FOLDS is set to 0. No training will occur.\")\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
